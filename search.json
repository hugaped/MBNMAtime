[{"path":"/articles/MBNMAtime.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"vignette demonstrates use MBNMAtime perform meta-analysis studies multiple follow-measurements order account time-course relationships within single multiple treatment comparisons. can performed conducting Model-Based (Network) Meta-Analysis (MBNMA) pool relative treatment effects. MBNMA models therefore estimate treatment effects time (e.g. days, weeks, months). Including available follow-measurements within study makes use available evidence way maintains connectivity treatments explains response treatment changes time, thus accounting heterogeneity inconsistency may present “lumping” together different time points standard Network Meta-Analysis (NMA). models analyses implemented Bayesian framework, following extension standard NMA methodology presented (Lu Ades 2004) run JAGS (version 4.3.0 later required) (JAGS Computer Program 2017). full details time-course MBNMA methodology see Pedder et al. (2019), simulation study exploring statistical properties method reported Pedder et al. (2020). package developed alongside MBNMAdose, package allows users perform dose-response MBNMA allow modelling dose-response relationships different agents within network. However, loaded R time number functions shared names perform similar tasks yet specific dealing either time-course dose-response data. Within vignette, models evaluated, run fewer iterations necessary achieve convergence produce valid results practice. done speed computation rendering vignette.","code":""},{"path":"/articles/MBNMAtime.html","id":"workflow-within-the-package","dir":"Articles","previous_headings":"Introduction","what":"Workflow within the package","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Functions within MBNMAtime follow clear pattern use: Load data correct format using mb.network() Specify suitable time-course function analyse data using mb.run() Test consistency using functions like mb.nodesplit() Examine model results using forest plots treatment rankings Use model predict responses estimate treatment effects specific time-points using predict() stages number informative graphs can generated help understand data make decisions regarding model fitting.","code":""},{"path":[]},{"path":"/articles/MBNMAtime.html","id":"pain-relief-in-osteoarthritis","dir":"Articles","previous_headings":"Datasets Included in the Package","what":"Pain relief in osteoarthritis","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"osteopain systematic review treatments pain osteoarthritis, used previously Pedder et al. (2019). outcome pain measured continuous scale, aggregate data responses correspond mean WOMAC pain score different follow-times. dataset includes 30 Randomised-Controlled Trials (RCTs), comparing 29 different treatments (including placebo). osteopain data frame long format (one row per time point, arm study), variables studyID, time, y, se, treatment arm.","code":""},{"path":"/articles/MBNMAtime.html","id":"alogliptin-for-lowering-blood-glucose-concentration-in-type-ii-diabetes","dir":"Articles","previous_headings":"Datasets Included in the Package","what":"Alogliptin for lowering blood glucose concentration in type II diabetes","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"alog_pcfb systematic review Randomised-Controlled Trials (RCTs) comparing different doses alogliptin placebo (Langford et al. 2016). systematic review simply performed intended provide data illustrate statistical methodology rather clinical inference. Alogliptin treatment aimed reducing blood glucose concentration type II diabetes. outcome continuous, aggregate data responses correspond mean change HbA1c baseline follow-studies least 12 weeks follow-. dataset includes 14 Randomised-Controlled Trials (RCTs), comparing 5 different doses alogliptin placebo (6 different treatments total). alog_pcfb data frame long format (one row per time point, arm study), variables studyID, clinicaltrialGov_ID, agent, dose, treatment, time, y, se, N.","code":""},{"path":"/articles/MBNMAtime.html","id":"tiotropium-aclidinium-and-placebo-for-maintenance-treatment-of-moderate-to-severe-chronic-obstructive-pulmonary-disease","dir":"Articles","previous_headings":"Datasets Included in the Package","what":"Tiotropium, Aclidinium and Placebo for maintenance treatment of moderate to severe chronic obstructive pulmonary disease","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"dataset systematic review Randomised-Controlled Trials (RCTs) maintenance treatment moderate severe chronic obstructive pulmonary disease (COPD) (Karabis et al. 2013). Data extracted (Tallarita, De lorio, Baio 2019). SEs imputed three studies, number patients randomised imputed one study (LAS 39) missing, using median standard deviation calculated studies dataset. outcome trough Forced Expiratory Volume 1 second (FEV1), measured litres reported study arm mean change baseline follow-. dataset includes 13 RCTs, comparing 2 treatments (Tiotropium Aclidinium) placebo. copd data frame long format (one row per observation, arm study), variables studyID, time, y, se, treatment, n.","code":""},{"path":"/articles/MBNMAtime.html","id":"body-weight-reduction-in-obesity-patients","dir":"Articles","previous_headings":"Datasets Included in the Package","what":"Body weight reduction in obesity patients","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"obesityBW_CFB systematic review pharmacological treatments obesity. outcome measured change baseline body weight (kg) different follow-times. 35 RCTs included investigate 26 different treatments (16 agents/agent combinations compared different doses). obesityBW_CFB dataset long format (one row per time point, arm study), variables studyID, time, y, se, N, treatment, arm, treatname, agent class. class class particular agent (e.g. Lipase inhibitor)","code":""},{"path":"/articles/MBNMAtime.html","id":"serum-uric-acid-concentration-in-gout","dir":"Articles","previous_headings":"Datasets Included in the Package","what":"Serum uric acid concentration in gout","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"goutSUA_CFB systematic review interventions lowering Serum Uric Acid (SUA) concentration patients gout [published previously]. outcome continuous, aggregate data responses correspond mean change baseline SUA mg/dL different follow-times. dataset includes 28 RCTs, comparing 41 treatments (8 agents compared different doses). goutSUA_CFB data frame long format (one row per arm study), variables studyID, time, y, se, treatment, arm, class treatname.","code":""},{"path":"/articles/MBNMAtime.html","id":"inspecting-the-data","dir":"Articles","previous_headings":"","what":"Inspecting the data","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"embarking analysis, first step look raw data. Two features (network connectivity time-course relationship) particularly important MBNMA. investigate must first get dataset right format package. can using mb.network(). requires specifying desired treatment use network reference treatment, though one automatically specified given. takes dataset columns: studyID Study identifiers time Numeric data indicating continuous follow-times (e.g. days, weeks, months) y Numeric data indicating mean response given observation se Numeric data indicating standard error given observation treatment Treatment identifiers (can numeric, factor character) class optional column indicating particular class may shared several treatments. N optional column indicating number participants used calculate response given observation. Additional columns can included dataset. simply added mb.network object, though affect classification data. mb.network performs following checks data: dataset required column names missing values standard errors (SE) positive Observations made time points arms study (.e. data balanced) Class labels consistent within treatment Studies least two arms Unless otherwise specified, mb.network() automatically determine whether study dataset reported change baseline absolute - studies include measurement time=0 assumed report absolute values, whilst measurement time=0 assumed change baseline. can also explicitly specified user including logical vector argument cfb mb.network() - TRUE indicates study reports change baseline, FALSE indicates reports absolute values. Finally, mb.network() converts data object class(\"mb.network\"), contains indices study arms follow-measurements, generates numeric values treatments classes. convention, treatments numbered alphabetically, though original data treatments provided factor factor codes used. contains necessary information subsequent MBNMAtime functions.","code":"# Using the pain dataset network.pain <- mb.network(osteopain, reference = \"Pl_0\") #> Studies reporting change from baseline automatically identified from the data print(network.pain) #> description : #> [1] \"Network\" #>  #> data.ab : #>             studyID time treatment narm arm     y        se     treatname #> 1 Gottesdiener 2002    0         1    6   1 7.062 0.2221675     Placebo_0 #> 2 Gottesdiener 2002    0         6    6   2 7.009 0.1605568 Etoricoxib_10 #> 3 Gottesdiener 2002    0         7    6   3 6.756 0.1696070 Etoricoxib_30 #> 4 Gottesdiener 2002    0         8    6   4 6.873 0.1584104  Etoricoxib_5 #> 5 Gottesdiener 2002    0         9    6   5 6.686 0.1619320 Etoricoxib_60 #> 6 Gottesdiener 2002    0        10    6   6 6.854 0.1620282 Etoricoxib_90 #>   fupcount fups #> 1        1    5 #> 2        1    5 #> 3        1    5 #> 4        1    5 #> 5        1    5 #> 6        1    5 #>  [ reached 'max' / getOption(\"max.print\") -- omitted 411 rows ] #>  #> studyID : #>  [1] \"Gottesdiener 2002\" \"Schnitzer 2005_2\"  \"Bensen 1999\"       #>  [4] \"DeLemos 2011\"      \"Gana 2006\"         \"Kivitz 2001\"       #>  [7] \"Kivitz 2002\"       \"Fishman 2007\"      \"Fleischmann 2005\"  #> [10] \"Lehmann 2005\"      \"Schnitzer 2010\"    \"Sheldon 2005\"      #> [13] \"Tannenbaum 2004\"   \"Baerwald 2010\"     \"Bingham 2007a\"     #> [16] \"Bingham 2007b\"     \"Birbara 2006_1\"    \"Birbara 2006_2\"    #> [19] \"Enrich 1999\"       \"Leung 2002\"        \"Schnitzer 2011LUM\" #> [22] \"Sowers 2005\"       \"Chappell 2009\"     \"Chappell 2011\"     #> [25] \"Clegg 2006\"        \"Markenson 2005\"    \"McKenna 2001\"      #> [28] \"Puopolo 2007\"      \"Sawitzke 2010\"     \"Williams 2001\"     #>  #> cfb : #>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [25] FALSE FALSE FALSE FALSE FALSE FALSE #>  #> treatments : #>  [1] \"Pl_0\"    \"Ce_100\"  \"Ce_200\"  \"Ce_400\"  \"Du_90\"   \"Et_10\"   \"Et_30\"   #>  [8] \"Et_5\"    \"Et_60\"   \"Et_90\"   \"Lu_100\"  \"Lu_200\"  \"Lu_400\"  \"Lu_NA\"   #> [15] \"Na_1000\" \"Na_1500\" \"Na_250\"  \"Na_750\"  \"Ox_44\"   \"Ro_12\"   \"Ro_125\"  #> [22] \"Ro_25\"   \"Tr_100\"  \"Tr_200\"  \"Tr_300\"  \"Tr_400\"  \"Va_10\"   \"Va_20\"   #> [29] \"Va_5\""},{"path":"/articles/MBNMAtime.html","id":"network-connectivity","dir":"Articles","previous_headings":"Inspecting the data","what":"Network connectivity","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Looking evidence network connected identifying studies compare treatments helps understand treatment effects can estimated information helping inform estimates. network plot can generated shows treatments compared head--head trials. Typically thickness connecting lines (“edges”) proportional number studies make particular comparison size treatment nodes (“vertices”) proportional total number patients network randomised given treatment (provided N included variable original dataset mb.network()). MBNMAtime plots generated using igraph, can plotted calling plot(). generated plots objects class(\"igraph\") meaning , addition options specified plot(), various igraph functions can used make detailed edits .  Within network plots, treatments automatically aligned circle (default) can tidied shifting label distance away nodes.  command returns warning stating treatments connected network reference treatment pathway head--head evidence. nodes coloured white represent treatments. means possible estimate relative effects treatments versus network reference treatment (treatments connected ). Several options exist allow inclusion treatments analysis discuss detail later, one approach assume shared effect among treatments within class/agent. can generate network plot class level examine closely, can see network connected class level.  also possible plot network treatment level colour treatments class belong .","code":"# Prepare data using the alogliptin dataset network.alog <- mb.network(alog_pcfb, reference = \"placebo\") #> Studies reporting change from baseline automatically identified from the data  # Plot network plot(network.alog) # Draw network plot in a star layout using the gout dataset network.gout <- mb.network(goutSUA_CFB, reference = \"Plac\") plot(network.gout, layout=igraph::as_star(), label.distance = 5) #> Studies reporting change from baseline automatically identified from the data plot(network.gout, level = \"class\", remove.loops = TRUE, label.distance = 5) plot(network.gout, level = \"treatment\", v.color = \"class\", label.distance = 5)"},{"path":"/articles/MBNMAtime.html","id":"examining-the-time-course-relationship","dir":"Articles","previous_headings":"Inspecting the data","what":"Examining the time-course relationship","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"order consider functional forms may appropriate modeling time-course relationship, important look responses arm plotted time. can easily done using timeplot() function object class(\"mb.network\")  mean response treatments shows rapid reduction pain score followed levelling 2-5 weeks, Integrated Two-component Prediction (ITP) time-course function might reasonable fit dataset. complex alternatives Emax models (without Hill parameter), fractional polynomials spline function. Responses can also plotted grouped class rather treatment, relative effects treatment/class can plotted instead absolute treatment responses. Since MBNMA framework models time-course relative effects (Pedder et al. 2019) can fact make interpretation plots easier regards identifying best-fitting time-course function.  Many profiles appear quite different within class, suggest modelling class effects may inappropriate dataset. Another approach investigate time-course relationship perform several standard “lumped” NMAs different time “bins”, time periods within assuming treatment effects constant time. means , purposes plot, rather considering time continuous variable chunked segments. can within single plot using binplot() specifying boundaries multiple time bins. Separate NMAs performed within time bin data points studies fall within time bin (single follow-time taken study avoid double counting). \"fixed\" \"random\" effects can specified NMA. Note wider time bin boundaries specified user, larger potential range included follow-times can introduce heterogeneity inconsistency.  Results plotted versus network reference plotted relevant scale depending function specified link (case \"identity\" - .e. mean differences versus Pl_0 shown). time bin window marked plot vertical dashed lines. NMA estimates within time bin plotted horizontal solid black line (posterior median) shaded region indicating 95% credible interval (prediction intervals can instead plotted). width shaded regions equal range study time-points included NMA performed within time-bin, may therefore narrow time bin specified binplot() command due follow-times data available included studies. example, time bin 10-15 weeks, studies dataset included time bin follow-ups 12-13 weeks. plot can see , whilst clearly rapid onset treatment efficacy within first 5 weeks, indicated treatment effect <0 treatments. treatment effect persists remains less constant treatments within later time bins, though others (e.g. Ce_200, Ro_25, Na_1000, Na_1500, Va_10) appears loss efficacy later time bins, suggesting complex time-course function may required fully capture relationship.","code":"# Prepare data using the pain dataset network.pain <- mb.network(osteopain, reference=\"Pl_0\") #> Studies reporting change from baseline automatically identified from the data  # Draw plot of raw study responses over time timeplot(network.pain) # Draw plot of within-study relative effects over time grouped by class network.gout <- mb.network(goutSUA_CFBcomb) timeplot(network.gout, level=\"class\", plotby=\"rel\") # Plot results for NMAs performed between 0-5, 5-10, 10-15 and 15-26 weeks binplot(network.pain, overlay.nma=c(0,5,10,15,26)) #> Running overlay.nma for time=0 and time=5 #> module glm loaded #> Running overlay.nma for time=5 and time=10 #> Running overlay.nma for time=10 and time=15 #> Running overlay.nma for time=15 and time=26"},{"path":"/articles/MBNMAtime.html","id":"analysis-using-mb-run","dir":"Articles","previous_headings":"","what":"Analysis using mb.run()","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"MBNMA models fitted using mb.run() model treatment effects time (e.g. days, weeks, months). can just easily performed datasets many different treatments (network meta-analysis) can datasets comparing two treatments (pairwise meta-analysis) - syntax . object class(\"mb.network\") must provided data mb.run(). key arguments within mb.run() involve specifying functional form used model time-course, time-course parameters comprise functional form.","code":""},{"path":"/articles/MBNMAtime.html","id":"time-course-functions","dir":"Articles","previous_headings":"Analysis using mb.run()","what":"Time-course functions","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"number different time-course functions can fitted within MBNMAtime specific forms time-course parameters defined arguments within functions, allows wide variety parameterizations time-course shapes. details check help files function (e.g. ?tloglin()). functions, used inputs fun argument mb.run(). tloglin() - Log-linear function titp() - Integrated Two-Component Prediction (ITP) function temax() - Emax function tpoly() - Polynomial function (e.g. linear, quadratic) tfpoly() - Fractional polynomial function, proposed previously time-course NMA Jansen (2015). tspline() - Spline functions (includes B-splines, restricted cubic splines, natural splines piecewise linear splines) tuser() - time-course function can explicitly defined user Time-course parameters within time-course functions defined two arguments: pool used define approach used pooling given time-course parameter can either : \"rel\" indicates relative effects (mean differences) pooled time-course parameter. preserves randomisation within included studies, likely vary less studies (due effect modification), allow testing consistency direct indirect evidence. Pooling follows general approach Network Meta-Analysis proposed Lu Ades (2004). \"abs\" indicates study arms pooled across whole network time-course parameter independently assigned treatment. implies using single absolute value across network time-course parameter, may therefore making strong assumptions similarity studies. method used define model used meta-analysis given time-course parameter can take either : \"common\" implies studies estimate true effect (sometimes called “fixed effect” meta-analysis) \"random\" implies studies estimate separate true effect, true effects vary randomly around true mean effect. approach allows modelling -study heterogeneity. Specifying pooling relative effects time-course parameters imply performing contrast-based synthesis, whereas specifying pooling absolute effects imply performing arm-based synthesis. substantial discussion literature regarding strengths limitations approaches (Dias Ades 2016; Hong et al. 2016; Karahalios et al. 2017). Additional arguments within function may also used specify degree (e.g. polynomials) number knots knot placement splines.","code":""},{"path":"/articles/MBNMAtime.html","id":"choosing-a-time-course-function","dir":"Articles","previous_headings":"Analysis using mb.run() > Time-course functions","what":"Choosing a time-course function","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Choice time-course function involves combination data-driven, statistical information (plots, model fit statistics) clinical/biological plausibility. timeplot() binplot() functions can used observe data differs different time-points. can help understand, example, whether data monotonically increases decreases, whether turning point multiple turning-points within time-course, follow-time(s) might occur. can also guided clinical/biological knowledge/expectation shape time-course outside range time-points data available. However, several potential candidate time-course functions identified, selection (specific specification time-course parameters terms absolute relative effects) best achieved using model fit statistics (e.g. Deviance Information Criterion (DIC), residual deviance).","code":""},{"path":"/articles/MBNMAtime.html","id":"output","dir":"Articles","previous_headings":"Analysis using mb.run()","what":"Output","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"mb.run() returns object class(c(\"mbnma\", \"rjags\")). summary() provides summary estimates posterior densities different parameters model, explanation regarding way model defined. Estimates automatically reported parameters interest depending model specification (unless otherwise specified parameters..save). Nodes automatically monitored (present model) following interpretation:","code":""},{"path":"/articles/MBNMAtime.html","id":"parameters-modelled-using-relative-effects","dir":"Articles","previous_headings":"Analysis using mb.run() > Output","what":"Parameters modelled using relative effects","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"pooling relative (e.g. pool.1=\"rel\") given parameter named parameter (e.g. emax) numbered d parameter (e.g. d.1) corresponds pooled relative effect (mean difference) given treatment compared network reference treatment time-course parameter. sd. followed named (e.g. emax, beta.1) -study SD (heterogeneity) relative effects, reported pooling time-course parameter relative (e.g. pool.1=\"rel\") method synthesis random (e.g. method.1=\"random). class effects modelled, parameters classes represented upper case name time-course parameter correspond . example class.effect=list(emax=\"random\"), relative class effects represented EMAX. SD class effect (e.g. sd.EMAX, sd.BETA.1) SD treatments within class time-course parameter correspond .","code":""},{"path":"/articles/MBNMAtime.html","id":"parameters-modelled-using-absolute-effects","dir":"Articles","previous_headings":"Analysis using mb.run() > Output","what":"Parameters modelled using absolute effects","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"pooling absolute (e.g. pool.1=\"abs\") given parameter named parameter (e.g. emax) numbered beta parameter (e.g. beta.1) corresponds estimated absolute effect time-course parameter. absolute time-course parameter corresponding method common (e.g. method.1=\"common\") parameter corresponds single common parameter estimated across studies treatments. corresponding method random (e.g. method.1=\"random\") parameter mean effect around study-level absolute effects vary SD corresponding sd. followed named parameter (e.g. sd.emax, sd.beta.1).","code":""},{"path":"/articles/MBNMAtime.html","id":"other-model-parameters","dir":"Articles","previous_headings":"Analysis using mb.run() > Output","what":"Other model parameters","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"rho correlation coefficient correlation time-points. interpretation differ depending covariance structure specified covar. totresdev residual deviance model deviance deviance model. Model fit statistics pD (effective number parameters) DIC (Deviance Information Criterion) also reported, explanation calculated.","code":""},{"path":"/articles/MBNMAtime.html","id":"examples","dir":"Articles","previous_headings":"Analysis using mb.run() > Output","what":"Examples","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"example MBNMA alogliptin dataset using linear time-course function common treatment effects pool relative effects assumes consistency direct indirect evidence can performed follows: model, d.1 parameters correspond 1st polynomial coefficient, therefore linear gradient response time treatment versus placebo - .e. mean difference change efficacy treatment versus placebo. However, note residual deviance model high, suggesting (might expect) linear time-course function poor fit. may want fit complex time-course function two time-course parameters, Emax function, yet limitations data might require make assumption one parameters vary treatment. can specify setting pool equal \"abs\" parameters choose. case, parameters named following Emax function specification. emax corresponds maximum effect treatment versus placebo (interpretable mean difference versus placebo), whereas et50 log time 50% maximum response achieved, across treatments network. assumes conditional constancy absolute effects time-course parameter, typically strong assumption. However, limited data inform parameter (e.g. earlier time-points) assumption might necessary, caveat interpolation response time-points informed parameter may susceptible bias. exploration degree data required reliable estimation time-course parameters given Pedder et al. (2020).","code":"# Run a linear time-course MBNMA mbnma <- mb.run(network.alog, fun=tpoly(degree=1, pool.1=\"rel\", method.1=\"common\")) #> Change from version 0.2.2 onwards: corparam=FALSE as default summary(mbnma) #> ======================================== #> Time-course MBNMA #> ======================================== #>  #> Time-course function: poly (degree = 1) #> Data modelled without intercept (change from baseline data assumed) #>  #> beta.1 parameter #> Pooling: relative effects #> Method: common treatment effects #>  #> |Treatment |Parameter |  Median|    2.5%|   97.5%| #> |:---------|:---------|-------:|-------:|-------:| #> |placebo   |d.1[1]    |  0.0000|  0.0000|  0.0000| #> |alog_6.25 |d.1[2]    | -0.0346| -0.0375| -0.0319| #> |alog_12.5 |d.1[3]    | -0.0422| -0.0440| -0.0405| #> |alog_25   |d.1[4]    | -0.0449| -0.0467| -0.0432| #> |alog_50   |d.1[5]    | -0.0512| -0.0539| -0.0483| #> |alog_100  |d.1[6]    | -0.0481| -0.0658| -0.0296| #>  #>  #>  #> Correlation between time points #> Covariance structure: varadj  #> Rho assigned a numeric value: 0 #>  #> #### Model Fit Statistics #### #>  #> Effective number of parameters: #> pD (pV) calculated using the rule, pD = var(deviance)/2 = 18 #> Deviance = 4502 #> Residual deviance = 5449 #> Deviance Information Criterion (DIC) = 4520 # Run an Emax time-course MBNMA with two parameters mbnma <- mb.run(network.alog, fun=temax(   pool.emax = \"rel\", method.emax=\"common\",   pool.et50 = \"abs\", method.et50=\"common\" )) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default summary(mbnma) #> ======================================== #> Time-course MBNMA #> ======================================== #>  #> Time-course function: emax #> Data modelled without intercept (change from baseline data assumed) #>  #> emax parameter #> Pooling: relative effects #> Method: common treatment effects #>  #> |Treatment |Parameter |  Median|    2.5%|   97.5%| #> |:---------|:---------|-------:|-------:|-------:| #> |placebo   |emax[1]   |  0.0000|  0.0000|  0.0000| #> |alog_6.25 |emax[2]   | -0.5879| -0.6516| -0.5233| #> |alog_12.5 |emax[3]   | -0.7768| -0.8203| -0.7385| #> |alog_25   |emax[4]   | -0.8466| -0.8880| -0.8053| #> |alog_50   |emax[5]   | -0.9679| -1.0375| -0.8993| #> |alog_100  |emax[6]   | -0.8358| -1.1047| -0.5646| #>  #>  #> et50 parameter #> Pooling: absolute effects #> Method: common treatment effects #>  #> |Treatment |Parameter | Median|   2.5%|  97.5%| #> |:---------|:---------|------:|------:|------:| #> |placebo   |et50      | 5.2039| 4.8191| 5.6154| #> |alog_6.25 |et50      | 5.2039| 4.8191| 5.6154| #> |alog_12.5 |et50      | 5.2039| 4.8191| 5.6154| #> |alog_25   |et50      | 5.2039| 4.8191| 5.6154| #> |alog_50   |et50      | 5.2039| 4.8191| 5.6154| #> |alog_100  |et50      | 5.2039| 4.8191| 5.6154| #>  #>  #>  #> Correlation between time points #> Covariance structure: varadj  #> Rho assigned a numeric value: 0 #>  #> #### Model Fit Statistics #### #>  #> Effective number of parameters: #> pD (pV) calculated using the rule, pD = var(deviance)/2 = 21 #> Deviance = 87 #> Residual deviance = 1034 #> Deviance Information Criterion (DIC) = 109"},{"path":[]},{"path":"/articles/MBNMAtime.html","id":"correlation-between-time-points","dir":"Articles","previous_headings":"Analysis using mb.run() > Additional model specification with mb.run()","what":"Correlation between time points","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Within-study correlation time points can easily modeled using mb.run(), though requires additional considerations. simplest approach incorporate correlation using variance adjustment (Jansen, Vieira, Cope 2015). avoids need use multivariate normal likelihood (slow run), assumes common correlation neighbouring time-points. achieved using argument covar=\"varadj\", default mb.run(). two alternative covariance structures can modelled, though require fitting multivariate normal likelihood therefore take longer run. covar=\"CS\" specifies fitting Compound Symmetry covariance structure, whilst covar=\"AR1\" specifies fitting autoregressive AR1 covariance structure multivariate normal likelihood used modelling correlation multiple time points within study (Kincaid 2005). However, addition , ’s also necessary specify value rho, can assigned one two ways: Given string representing JAGS prior distribution (Plummer 2017), indicates correlation estimated data. example, specify prior correlation time-points 0 1 equal probability set rho=\"dunif(0,1)\". Given single numeric value, indicates correlation fixed value. example, value estimated externally another study using Individual Participant Data. also used run deterministic sensitivity analysis using different fixed values rho. important note covariance matrix must positive semi-definite. may mean order satisfy requirement particular covariance matrix structures, values rho can take limited. rho must always bounded -1 1, even within range negative values rho can result non positive matrix, can lead error evaluation multivariate likelihood. , may necessary restrict prior distribution.","code":"# Using the COPD dataset network.copd <- mb.network(copd)  # Run an log-linear time-course MBNMA  # that accounts for correlation between time points using variance adjustment mbnma <- mb.run(network.copd,                  fun=tloglin(pool.rate=\"rel\", method.rate=\"random\"),                 rho=\"dunif(0,1)\", covar=\"varadj\")"},{"path":"/articles/MBNMAtime.html","id":"link-function","dir":"Articles","previous_headings":"Analysis using mb.run()","what":"Link function","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Time-course MBNMA can used continuous outcomes can summarised continuous outcomes (e.g. binary data can converted log-odds inclusion model). Typically means users analyse data using identity link function, default given link argument mb.run()m assumes additive treatment effect (e.g. mean difference). However, specifying link=\"log\" user can model log link therefore assume multiplicative treatment effect. continuous data models treatment effect Ratio Means (RoM) (Friedrich, Adhikari, Beyene 2011). also provides advantage treatment effect scale independent (.e. studies measuring outcome using different measurement scales can analysed simultaneously). However, within-study treatment effects must direction (either positive negative), change baseline measures must adjusted also expressed RoMs (log(follow-) - log(baseline)) avoid combining additive multiplicative assumptions within analysis. alternative approach modeling measurement scale-independent treatment effect whilst still assuming additive treatment effects perform analysis using Standardised Mean Differences (SMD). Whilst strictly different link function, can specified using link=\"smd\". Currently, MBNMAtime standardises treatment effects using pooled baseline standard deviation (SD) study, limit bias effect treatment might SD. resulting treatment effects reported units SD SMDs. robust approach minimise bias estimation within-study SD use single reference SD standardisation scale included dataset. something MBNMAtime incorporate future. details analysis continuous data include discussion RoM SMD see (Daly et al. 2021).","code":""},{"path":"/articles/MBNMAtime.html","id":"class-effects","dir":"Articles","previous_headings":"Analysis using mb.run()","what":"Class effects","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Shared effects treatments within network can modelled using class effects. requires assuming different treatments sort shared class effect, perhaps due different (yet clinically similar) doses agent different treatments similar mechanism action. One advantage class effects can used connect relative effects treatments network disconnected treatment level, can connected via classes class level. However, important ensure effect clinically justifiable, making assumptions risks introducing heterogeneity/inconsistency. Class effects can applied time-course parameters vary treatment (pool=\"rel\"), class effects modelled separately time-course parameter. mb.run() class effects specified list, element named time-course parameter modelled. class effect time-course parameter can either \"common\", effects treatment within class constrained common class effect, \"random\", effects treatment within class assumed randomly distributed around shared class mean. Mean class effects given output D.2 parameters. can interpreted relative effect class versus Plac (Placebo), 2nd spline coefficient (beta.2). Note number D.2 parameters therefore equal number classes defined dataset.","code":"# Run a B-spline time-course MBNMA with a knot at 0.2 times the max follow-up # Common class effect on beta.2, the 2nd spline coefficient mbnma <- mb.run(network.gout,                  fun=tspline(type=\"bs\", knots=c(0.2),                             pool.1 = \"rel\", method.1=\"common\",                             pool.2=\"rel\", method.2=\"random\"),                 class.effect = list(beta.2=\"common\")) summary(mbnma) #> ======================================== #> Time-course MBNMA #> ======================================== #>  #> Time-course function: B-spline (knots = 0.2; degree = 1) #> Data modelled without intercept (change from baseline data assumed) #>  #> beta.1 parameter #> Pooling: relative effects #> Method: common treatment effects #>  #> |Treatment |Parameter |   Median|     2.5%|    97.5%| #> |:---------|:---------|--------:|--------:|--------:| #> |Plac      |d.1[1]    |   0.0000|   0.0000|   0.0000| #> |Allo_100  |d.1[2]    |  -1.4722|  -2.9599|  -0.0457| #> |Allo_200  |d.1[3]    |  -3.0027|  -3.2606|  -2.7491| #> |Allo_289  |d.1[4]    |  -4.9120|  -5.0946|  -4.7465| #> |Allo_400  |d.1[5]    | -12.7335| -14.2913| -11.1421| #> |Arha_NA   |d.1[6]    |  -6.8420|  -7.5544|  -6.1084| #> |BCX4_140  |d.1[7]    |  -4.5777|  -4.9785|  -4.1973| #> |BCX4_18.5 |d.1[8]    |  -2.4490|  -2.8879|  -1.9807| #> |BCX4_240  |d.1[9]    |  -5.8849|  -6.3524|  -5.4486| #> |BCX4_80   |d.1[10]   |  -3.5953|  -4.0706|  -3.1412| #> |Benz_NA   |d.1[11]   | -15.5365| -16.7682| -14.3059| #> |Febu_140  |d.1[12]   |  -7.2846|  -7.4671|  -7.1146| #> |Febu_210  |d.1[13]   |  -8.8137|  -8.9180|  -8.7143| #> |Febu_25   |d.1[14]   |  -3.8383|  -4.0055|  -3.6751| #> |Febu_72.5 |d.1[15]   |  -6.1711|  -6.3535|  -6.0017| #> |RDEA_100  |d.1[16]   |  -2.3520|  -2.8893|  -1.8132| #> |RDEA_200  |d.1[17]   |  -4.1133|  -4.4753|  -3.7703| #> |RDEA_400  |d.1[18]   |  -5.2396|  -5.5828|  -4.9138| #> |RDEA_600  |d.1[19]   |  -8.0790|  -8.5172|  -7.6643| #>  #>  #> beta.2 parameter #> Pooling: relative effects #> Method: random treatment effects #> Class effects modelled for this parameter #>  #> |Treatment |Parameter |  Median|     2.5%|   97.5%| #> |:---------|:---------|-------:|--------:|-------:| #> |Plac      |d.2[1]    |  0.0000|   0.0000|  0.0000| #> |Allo_100  |d.2[2]    | 17.3279|   4.2738| 30.2725| #> |Allo_200  |d.2[3]    | 17.3279|   4.2738| 30.2725| #> |Allo_289  |d.2[4]    | 17.3279|   4.2738| 30.2725| #> |Allo_400  |d.2[5]    | 17.3279|   4.2738| 30.2725| #> |Arha_NA   |d.2[6]    | -0.9496| -63.5489| 60.3210| #> |BCX4_140  |d.2[7]    | 10.0073|  -1.9043| 22.7117| #> |BCX4_18.5 |d.2[8]    | 10.0073|  -1.9043| 22.7117| #> |BCX4_240  |d.2[9]    | 10.0073|  -1.9043| 22.7117| #> |BCX4_80   |d.2[10]   | 10.0073|  -1.9043| 22.7117| #> |Benz_NA   |d.2[11]   | 18.4265|  -6.6143| 44.0197| #> |Febu_140  |d.2[12]   | 16.1995|   5.4698| 26.4230| #> |Febu_210  |d.2[13]   | 16.1995|   5.4698| 26.4230| #> |Febu_25   |d.2[14]   | 16.1995|   5.4698| 26.4230| #> |Febu_72.5 |d.2[15]   | 16.1995|   5.4698| 26.4230| #> |RDEA_100  |d.2[16]   | 20.4347|   3.1861| 35.7722| #> |RDEA_200  |d.2[17]   | 20.4347|   3.1861| 35.7722| #> |RDEA_400  |d.2[18]   | 20.4347|   3.1861| 35.7722| #> |RDEA_600  |d.2[19]   | 20.4347|   3.1861| 35.7722| #>  #> Between-study SD modelled for this parameter: #>  #> |Parameter |  Median|   2.5%|   97.5%| #> |:---------|-------:|------:|-------:| #> |sd.beta.2 | 11.8564| 9.3029| 15.3545| #>  #>  #> Class Effects #>  #> Class effects for beta.2 #> Common (fixed) class effects #>  #> |Class |Parameter |  Median|     2.5%|   97.5%| #> |:-----|:---------|-------:|--------:|-------:| #> |Plac  |D.2[1]    |  0.0000|   0.0000|  0.0000| #> |Allo  |D.2[2]    | 17.3279|   4.2738| 30.2725| #> |Arha  |D.2[3]    | -0.9496| -63.5489| 60.3210| #> |BCX4  |D.2[4]    | 10.0073|  -1.9043| 22.7117| #> |Benz  |D.2[5]    | 18.4265|  -6.6143| 44.0197| #> |Febu  |D.2[6]    | 16.1995|   5.4698| 26.4230| #> |RDEA  |D.2[7]    | 20.4347|   3.1861| 35.7722| #>  #>  #> Correlation between time points #> Covariance structure: varadj  #> Rho assigned a numeric value: 0 #>  #> #### Model Fit Statistics #### #>  #> Effective number of parameters: #> pD (pV) calculated using the rule, pD = var(deviance)/2 = 86 #> Deviance = 149881 #> Residual deviance = 150575 #> Deviance Information Criterion (DIC) = 149967"},{"path":"/articles/MBNMAtime.html","id":"additional-arguments","dir":"Articles","previous_headings":"Analysis using mb.run()","what":"Additional arguments","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Several additional arguments can given mb.run() require explanation.","code":""},{"path":"/articles/MBNMAtime.html","id":"priors","dir":"Articles","previous_headings":"Analysis using mb.run() > Additional arguments","what":"Priors","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Default vague priors model follows: \\[ \\begin{aligned}   &\\alpha_{} \\sim N(0,10000)\\\\   &\\boldsymbol{\\mu}_{} \\sim N(0,10000)\\\\   &\\boldsymbol{d}_{t} \\sim N(0,10000)\\\\   &beta_{\\phi} \\sim N(0,10000)\\\\   &D_{\\phi,c} \\sim N(0,1000)\\\\   &\\tau_{\\phi} \\sim N(0,400) \\text{  limited  } x \\[0,\\infty]\\\\   &\\tau^D_{\\phi} \\sim N(0,400) \\text{ limited } x \\[0,\\infty]\\\\ \\end{aligned} \\] \\(\\alpha_i\\) response time=0 study \\(\\) \\(\\mu_i\\) vector study reference effects time-course parameter study \\(\\). single time-course parameter modelled using relative effects prior defined \\(\\mu_{} \\sim N(0,10000)\\). \\(\\boldsymbol{d}_{t}\\) vector pooled relative effects treatment \\(t\\) whose length number time-course parameters model. single time-course parameter modelled using relative effects prior defined \\(d_{t} \\sim N(0,10000)\\). \\(\\beta_{\\phi}\\) absolute effect time-course parameter \\(\\phi\\) modelled independently treatment \\(D_{\\phi,c}\\) class relative effect time-course parameter \\(\\phi\\) class \\(c\\) \\(\\tau_{\\phi}\\) -study SD time-course parameter \\(\\phi\\) \\(\\tau^D_{\\phi}\\) within-class SD time-course parameter \\(\\phi\\) Users may wish change , perhaps order use /less informative priors, also default prior distributions models may lead errors compiling/updating models. can likely certain types models. example prior distributions may generate results extreme JAGS compute, time-course parameters powers (e.g. Emax functions Hill parameter power parameters fractional polynomials). model fails compilation/updating (.e. due problem JAGS), mb.run() generate error return list arguments mb.run() used generate model. Within (within model run successfully), priors used model (JAGS syntax) stored within \"model.arg\". way model can first run vague priors rerun different priors, perhaps allow successful computation, perhaps provide informative priors, perhaps run sensitivity analysis different priors. change priors within model, list replacements can provided priors mb.run(). name element name parameter change (without indices) value element JAGS distribution use prior. See JAGS Manual (2017) syntax details regarding specifying distributions. can include censoring truncation desired. priors changed need specified - priors parameters aren’t specified take default values. Note JAGS, normal distributions specified using precision (1/variance) rather SD. example, may wish specify tighter prior -study SD:","code":"mbnma <- mb.run(network.copd,                  fun=tloglin(pool.rate=\"rel\", method.rate=\"random\"),                 priors=list(rate=\"dnorm(0,2) T(0,)\"))"},{"path":"/articles/MBNMAtime.html","id":"pd-effective-number-of-parameters","dir":"Articles","previous_headings":"Analysis using mb.run() > Additional arguments","what":"pD (effective number of parameters)","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"default value pd mb.run() pd=\"pv\", uses rapid approach automatically calculated R2jags package pv = var(deviance)/2. Whilst easy calculate, approximation effective number parameters, may numerically unstable (Gelman et al. 2003). However, shown reliable model comparison time-course MBNMA models simulation study (Pedder et al. 2020). reliable method estimating pd pd=\"pd.kl\", uses Kullback-Leibler divergence (Plummer 2008). reliable default method used R2jags calculating effective number parameters non-linear models. disadvantage approach requires running additional MCMC iterations, can slightly slower calculate. commonly-used approach Bayesian models calculating pD plug-method (pd=\"plugin\") (Spiegelhalter et al. 2002). However, can sometimes result negative non-sensical values due skewed posterior distributions deviance contributions can arise fitting non-linear models. Finally, pD can also calculated using optimism adjustment (pd=\"popt\") allows calculation penalized expected deviance (Plummer 2008). adjustment allows fact data used estimate model used assess parsimony. pd=\"pd.kl\", also requires running additional MCMC iterations.","code":""},{"path":"/articles/MBNMAtime.html","id":"correlation-between-time-course-parameters","dir":"Articles","previous_headings":"Analysis using mb.run() > Additional arguments","what":"Correlation between time-course parameters","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Since MBNMAtime version 0.2.2, mb.run() longer automatically models correlation time-course parameters modeled using relative effects. However, can enabled setting corparam=TRUE). Time-course parameters typically correlated allows information parameter help inform (s). correlation modeled using multivariate normal distribution whose covariance matrix \\(\\Sigma_t\\) modelled using correlation defined parameter rhoparam. previous versions, inverse Wishart prior used, though since considered overly constrain model.","code":""},{"path":"/articles/MBNMAtime.html","id":"arguments-to-be-sent-to-jags","dir":"Articles","previous_headings":"Analysis using mb.run() > Additional arguments","what":"Arguments to be sent to JAGS","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"addition arguments specific mb.run() also possible use arguments sent R2jags::jags(). relate improving performance MCMC simulations JAGS. key arguments may interest : n.chains number Markov chains run (default 3) n.iter total number iterations per MCMC chain n.burnin number iterations discarded ensure iterations saved chains converged n.thin thinning rate ensures results saved 1 every n.thin iterations per chain. can increased reduce autocorrelation MCMC samples","code":""},{"path":"/articles/MBNMAtime.html","id":"model-selection","dir":"Articles","previous_headings":"","what":"Model Selection","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Detailed description model selection based statistical measures Deviance Information Criterion (DIC) residual deviance outside scope vignette. However, following approach model identification selection recommended Pedder et al. (2020), also gives details model fit statistics used comparison: Identify candidate time-course functions based observed data clinical/biological reasoning Compare candidate time-course functions fitted common relative treatment effects time-course parameters candidate time-course functions converge successfully, absolute effects can modeled parameters convergence problematic Compare selected common effects model model(s) random effects different time-course parameters Compare model fitted univariate likelihood one fitted multivariate likelihood Finally validity consistency assumption explored selected final model (see Consistency Testing).","code":""},{"path":"/articles/MBNMAtime.html","id":"mcmc-convergence","dir":"Articles","previous_headings":"","what":"MCMC Convergence","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"MBNMAtime runs Bayesian models JAGS, uses Markov Chain Monte Carlo (MCMC) simulation (JAGS Computer Program 2017). However, validity results reliant MCMC chains converged successfully posterior densities parameters model. highly parameterised models run relatively limited data, often case MBNMA models, convergence can often challenge. Note convergence necessary able compare models evaluate model fit. However, successful convergence imply good model fit. full explanation facilitate check convergence outside scope vignette, simple steps checking convergence. None steps alone ensures convergence successful, interpretation jointly can provide strong evidence . Rhat values close 1 (<1.1 considered acceptable ). shown monitored parameters summary statistics table \"mbnma\" \"nma\" object printed. Trace plots “fuzzy caterpillar” look shows good mixing MCMC chains Density plots show smooth posterior distribution similar across chains Autocorrelation plots show low autocorrelation neighbouring MCMC iterations (.e. low correlation higher lags) HTML document convergence plots can easily generated parameters model simultaneously using mcmcplots::mcmcplot(). Two steps may improve convergence using MBNMAtime. One step run models iterations (can done using n.iter argument mb.run()). can take time MCMC chains converge, particularly non-linear models limited data. important note chains monitored converged - increasing number burn-iterations ensures case (using n.burnin argument mb.run()). Another method improve convergence providing information model via informative priors. detailed review MCMC convergence assessment see Sinharay (2003).","code":""},{"path":[]},{"path":"/articles/MBNMAtime.html","id":"deviance-plots","dir":"Articles","previous_headings":"Post-Estimation","what":"Deviance plots","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"assess well model fits data, can useful look plot contributions data point total deviance residual deviance. can done using devplot(). individual deviance contributions automatically monitored model, might require model run additional iterations. Results can plotted either scatter plot (plot.type=\"scatter\") series boxplots (plot.type=\"box\").  plots can see whilst model fit typically better later time points, fits poorly earlier time points. function appropriately captures time-course shape show reasonably flat shape deviance contributions (.e. contributions similar across time points). saved object, output devplot() contains results individual deviance contributions, can used identify extreme outliers.","code":"# Run a first-order fractional polynomial time-course MBNMA mbnma <- mb.run(network.pain,                  fun=tfpoly(degree=1,                           pool.1=\"rel\", method.1=\"random\",                           method.power1=0.5))  # Plot a box-plot of deviance contributions (the default) devplot(mbnma, n.iter=1000) #> Change from version 0.2.2 onwards: corparam=FALSE as default #> `dev` not monitored in mbnma$parameters.to.save. #> additional iterations will be run in order to obtain results for `dev`"},{"path":"/articles/MBNMAtime.html","id":"fitted-values","dir":"Articles","previous_headings":"Post-Estimation","what":"Fitted values","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Another approach assessing model fit can plot fitted values, using fitplot(). devplot(), may require running additional model iterations monitor theta. Fitted values plotted connecting lines observed values original dataset plotted points. plots can used identify model fits data well different treatments different parts time-course.","code":"# Plot fitted and observed values with treatment labels fitplot(mbnma, n.iter=1000)"},{"path":"/articles/MBNMAtime.html","id":"forest-plots","dir":"Articles","previous_headings":"Post-Estimation","what":"Forest plots","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Forest plots can easily generated MBNMA models using plot() method \"mbnma\" object. default plot separate panel time-course parameter model. Forest plots can generated parameters vary treatment/class.","code":"# Run a quadratic time-course MBNMA using the alogliptin dataset mbnma <- mb.run(network.alog,                  fun=tpoly(degree=2,                           pool.1=\"rel\", method.1=\"random\",                           pool.2=\"rel\", method.2=\"common\"                           ) ) #> Change from version 0.2.2 onwards: corparam=FALSE as default  plot(mbnma)"},{"path":"/articles/MBNMAtime.html","id":"get-relative-calculating-differences-between-treatments-at-a-specified-time-point","dir":"Articles","previous_headings":"Post-Estimation","what":"get.relative(): Calculating differences between treatments at a specified time-point","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Although mb.run() estimates effects different treatments different time-course parameters, necessarily easy draw conclusions , particularly time-course functions less easily interpretable parameters. get.relative() allows users calculate mean differences (log-Ratio Means mb.run(link=\"log\")) treatments specified time-point even subset, even none treatments investigated time-point included RCTs. results reported scale data modeled (.e. depending link function specified mb.run()), rather specific time-course parameters. Within matrices results, mean differences/relative effects shown row-defined treatment versus column-defined treatment.","code":"allres <- get.relative(mbnma, time=20,                        treats = c(\"alog_100\", \"alog_50\", \"placebo\")) print(allres) #> ======================================== #> Treatment comparisons at time = 20 #> ======================================== #>  #>      alog_100       0.9 (0.62, 1.2)    0.91 (-0.4, 2.3)  #> -0.9 (-1.2, -0.62)      alog_50       0.019 (-1.3, 1.4)  #> -0.91 (-2.3, 0.4)  -0.019 (-1.4, 1.3)      placebo"},{"path":"/articles/MBNMAtime.html","id":"rank-ranking","dir":"Articles","previous_headings":"Post-Estimation","what":"rank(): Ranking","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Rankings can calculated different time-course parameters MBNMA models using rank() \"mbnma\" object. parameter monitored MBNMA model varies treatment/class can ranked. vector assigned params. lower_better indicates whether negative scores ranked “better” (TRUE) “worse” (FALSE) addition, possible rank Area Curve (AUC) particular treatment adding \"auc\" vector params (included default). calculate area predicted response time, therefore function time-course parameters model simultaneously. However, dependent range times chosen integrate (int.range), different choice time-frame may lead different treatment rankings. \"auc\" can also currently calculated MBNMA models complex time-course functions (piecewise, fractional polynomials), MBNMA models use class effects. output object class(\"mb.rank\"), containing list ranked parameter params, consists summary table rankings raw information treatment ranking probabilities. summary median ranks 95% credible intervals can simply displayed using print(). Histograms ranking results can also plotted using plot() method, takes raw MCMC ranking results given rank.matrix plots number MCMC iterations parameter value treatment ranked particular position.  Cumulative rankograms indicating probability treatment ranked 1st, 2nd, etc. ranked parameter can also plotted using cumrank(). can used easily compare different treatments rank ranked parameter simultaneously. default, Surface Cumulative Ranking curve (SUCRA) also returned treatment ranked parameter (Salanti, Ades, Ioannidis 2011).","code":"# Identify quantile for knot at 1 week timequant <- 1/max(network.pain$data.ab$time)  # Run a piecewise linear time-course MBNMA with a knot at 1 week mbnma <- mb.run(network.pain,                 fun=tspline(type=\"ls\", knots = timequant,                             pool.1 = \"rel\", method.1=\"common\",                             pool.2 = \"rel\", method.2=\"common\")) #> Change from version 0.2.2 onwards: corparam=FALSE as default   # Rank results based on AUC (calculated 0-10 weeks), more negative slopes considered to be \"better\" ranks <- rank(mbnma, params=c(\"auc\", \"d.2\"),                      int.range=c(0,10),  lower_better = TRUE, n.iter=1000) print(ranks) #>  #> ======================================== #> Treatment rankings #> ========================================  #>  #> d.2 ranking #>  #> |Treatment |  Mean| Median| 2.5%| 97.5%| #> |:---------|-----:|------:|----:|-----:| #> |Pl_0      |  7.78|      8|    4|    12| #> |Ce_100    | 16.52|     17|    6|    25| #> |Ce_200    | 14.95|     15|   10|    20| #> |Ce_400    | 17.36|     18|    8|    25| #> |Du_90     | 14.86|      7|    1|    29| #> |Et_10     | 23.71|     26|    5|    29| #> |Et_30     | 13.77|     14|    6|    22| #> |Et_5      |  5.08|      3|    1|    23| #> |Et_60     | 23.55|     24|   15|    28| #> |Et_90     | 20.53|     24|    3|    29| #> |Lu_100    | 11.68|     11|    5|    19| #> |Lu_200    | 12.91|     13|    7|    20| #> |Lu_400    | 13.71|     14|    7|    21| #> |Lu_NA     | 14.78|      4|    1|    29| #> |Na_1000   | 20.31|     20|   15|    25| #> |Na_1500   | 17.74|     18|   10|    24| #> |Na_250    | 20.01|     24|    2|    29| #> |Na_750    | 21.20|     22|   12|    27| #> |Ox_44     |  8.26|      4|    1|    26| #> |Ro_12     | 20.78|     24|    3|    29| #> |Ro_125    | 13.79|     12|    1|    29| #> |Ro_25     | 24.03|     25|   13|    28| #> |Tr_100    |  5.35|      5|    2|    11| #> |Tr_200    |  6.74|      6|    2|    14| #> |Tr_300    |  9.13|      9|    4|    18| #> |Tr_400    |  6.46|      5|    2|    17| #> |Va_10     | 20.82|     22|    8|    28| #> |Va_20     | 15.95|     16|    4|    26| #> |Va_5      | 13.24|     13|    3|    25| #>  #>  #> auc ranking #>  #> |Treatment |  Mean| Median|  2.5%| 97.5%| #> |:---------|-----:|------:|-----:|-----:| #> |Pl_0      | 26.16|     26| 24.00| 28.00| #> |Ce_100    | 21.48|     22| 16.00| 26.00| #> |Ce_200    | 13.85|     14| 10.00| 18.00| #> |Ce_400    | 13.35|     13|  6.00| 21.00| #> |Du_90     | 15.66|     20|  1.00| 29.00| #> |Et_10     | 27.12|     28| 19.00| 29.00| #> |Et_30     |  6.54|      6|  3.00| 12.00| #> |Et_5      | 13.53|     12|  2.00| 27.00| #> |Et_60     |  4.25|      4|  2.00|  8.00| #> |Et_90     |  7.67|      4|  1.00| 25.00| #> |Lu_100    | 13.52|     13|  9.00| 19.00| #> |Lu_200    | 15.26|     15| 10.00| 20.00| #> |Lu_400    |  9.72|     10|  5.00| 16.00| #> |Lu_NA     | 14.18|     11|  1.00| 29.00| #> |Na_1000   |  8.23|      8|  5.00| 13.00| #> |Na_1500   |  9.15|      9|  4.00| 16.00| #> |Na_250    | 27.63|     28| 22.98| 29.00| #> |Na_750    | 19.19|     20| 12.00| 25.00| #> |Ox_44     |  4.99|      4|  1.00| 18.02| #> |Ro_12     | 20.71|     23|  5.00| 28.00| #> |Ro_125    |  2.67|      2|  1.00| 16.00| #> |Ro_25     | 16.72|     18|  5.00| 25.00| #> |Tr_100    | 23.09|     23| 18.00| 26.00| #> |Tr_200    | 22.26|     22| 18.00| 26.00| #> |Tr_300    | 15.41|     16|  8.00| 21.00| #> |Tr_400    | 11.24|     11|  4.00| 20.00| #> |Va_10     | 21.26|     22| 13.00| 26.00| #> |Va_20     | 13.68|     14|  5.00| 23.00| #> |Va_5      | 16.48|     17|  6.98| 24.00| # Ranking histograms for AUC plot(ranks, params = \"auc\") # Cumulative ranking for all ranked parameters cumrank(ranks) #> # A tibble: 58 × 3 #>    treatment parameter sucra #>    <fct>     <chr>     <dbl> #>  1 Pl_0      auc        3.34 #>  2 Pl_0      d.2       21.7  #>  3 Ce_100    auc        8.02 #>  4 Ce_100    d.2       13.0  #>  5 Ce_200    auc       15.6  #>  6 Ce_200    d.2       14.5  #>  7 Ce_400    auc       16.1  #>  8 Ce_400    d.2       12.1  #>  9 Du_90     auc       13.7  #> 10 Du_90     d.2       14.5  #> # … with 48 more rows"},{"path":"/articles/MBNMAtime.html","id":"prediction","dir":"Articles","previous_headings":"Post-Estimation","what":"Prediction","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"performing MBNMA, responses can predicted parameter estimates using predict() \"mbnma\" object. number important parameters need identified make robust predictions. However, default values can used set values zero reference treatment baseline time-course parameters indicates mean differences / relative treatment effects estimated. information help file can accessed using ?predict.mbnma. One key parameter E0, defines value(s) use predicted mean time = 0. single numeric value can given E0 indicate deterministic value, function representing random number generator (RNG) distribution R (stochastic) (e.g. E0 = ~rnorm(n, 7, 0.2). values can identified population interest external data (e.g. observational/registry). challenging parameter(s) identify network reference treatment time-course, supplied predict() ref.resp argument. estimating mean differences / relative treatment effects time need specified since typically MBNMA, relative effects estimated network reference effect modeled nuisance parameter. However, predicting mean responses time need provide input network reference treatment effect time-course parameters modeled using pool=\"rel\" can apply relative effects estimated model . two options providing values. first approach give values time-course parameter modeled using relative effects ref.resp. given list, separate named element time-course parameter. element can take either single numeric value (deterministic), function representing random number generator distribution R (stochastic). second assign ref.resp data frame composed single-arm studies network reference treatment. separate synthesis model reference treatment effect run, values used prediction reference treatment effect. dataset series observational studies measured multiple follow-times closely match population interest prediction. Alternatively subset data original RCT dataset used MBNMA model (though may less generalisable population interest). also possible specify time points make predictions (times), given vector positive numbers. left default maximum follow-dataset used upper limit range predicted time-points. object class \"mb.predict\" returned, list summary tables MCMC prediction matrices treatment, addition original mbnma object. summary() method can used print mean posterior predictions time point treatment. Predicted values can also plotted using plot() method object class(\"mb.predict\"). Within default arguments, median predicted network reference treatment effect overlaid predictions treatment. Setting overlay.ref = FALSE prevents causes network reference treatment effect plotted separate panel. Shaded counts observations original dataset predicted time point can plotted 95% CrI treatment setting disp.obs = TRUE.  can used identify extrapolation/interpretation time-course might occurring particular treatment, predictions might therefore problematic. illustrate situation informative, can look predictions quadratic time-course function fitted Obesity dataset:  can see, within limits observed data predicted values appear reasonable. However, extrapolation beyond dexf_30MG leads rather strange results, suggesting unrealistically huge increase body weight 50 weeks treatment. hand, predicted response 50 weeks follow-treatment 15 within limits observed data likely justifiable.","code":"# Run an Emax time-course MBNMA using the osteoarthritis dataset mbnma <- mb.run(network.pain,                 fun=temax(pool.emax=\"rel\", method.emax=\"common\",                           pool.et50=\"abs\", method.et50=\"common\"),                 rho=\"dunif(0,1)\", covar=\"varadj\") # Specify placebo time-course parameters ref.params <- list(emax=-2)  # Predict responses for a selection of treatments using a stochastic E0 and # placebo parameters defined in ref.params to estimate the network reference treatment effect pred <- predict(mbnma, treats=c(\"Pl_0\", \"Ce_200\", \"Du_90\", \"Et_60\",                                          \"Lu_400\", \"Na_1000\", \"Ox_44\", \"Ro_25\",                                         \"Tr_300\", \"Va_20\"),                         E0=~rnorm(n, 8, 0.5), ref.resp=ref.params)  print(pred) # Generate a dataset of network reference treatment responses over time placebo.df <- network.pain$data.ab[network.pain$data.ab$treatment==1,]  # Predict responses for a selection of treatments using a deterministic E0 and  #placebo.df to model the network reference treatment effect pred <- predict(mbnma, treats=c(\"Pl_0\", \"Ce_200\", \"Du_90\", \"Et_60\",                                          \"Lu_400\", \"Na_1000\", \"Ox_44\", \"Ro_25\",                                         \"Tr_300\", \"Va_20\"),                         E0=10, ref.resp=placebo.df)  print(pred) plot(pred, overlay.ref=TRUE, disp.obs=TRUE) # Fit a quadratic time-course MBNMA to the Obesity dataset network.obese <- mb.network(obesityBW_CFB, reference = \"plac\")  mbnma <- mb.run(network.obese,                 fun=tpoly(degree=2,                           pool.1 = \"rel\", method.1=\"common\",                           pool.2=\"rel\", method.2=\"common\"))  # Define stochastic values centred at zero for network reference treatment ref.params <- list(beta.1=~rnorm(n, 0, 0.05), beta.2=~rnorm(n, 0, 0.0001))  # Predict responses over the pred.obese <- predict(mbnma, times=c(0:50), E0=100, treats = c(1,4,15),                         ref.resp=ref.params)  # Plot predictions plot(pred.obese, disp.obs = TRUE)"},{"path":"/articles/MBNMAtime.html","id":"plotting-lumped-nma-results","dir":"Articles","previous_headings":"Post-Estimation > Prediction","what":"Plotting “lumped” NMA results","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"addition plots MBNMA predictions, possible add predicted results NMA model multiple “lumped” NMA models performed different time “bins” (specified overlay.nma), time periods within assuming treatment effects constant time. similar output generated binplot(). Either \"random\" (default) \"common\" effects NMA can specified, model fit statistics reported resulting plot. can useful assess MBNMA predictions agreement predictions lumped NMA models specific set time-points, can general indicator fit time-course model. However, important note NMA model necessarily robust model, since ignores potential differences treatment effects may arise lumping time-points together. wider range specified overlay.nma, greater effect lumping stronger assumption similarity studies. NMA predictions plotted range specified overlay.nma horizontal line representing posterior median, 95%CrI shown shaded rectangle. NMA predictions theory represent time-points within range since lump together data time-points, though width (x-axis) shaded rectangle represents range time-points studies included time bin. Predictions treatments disconnected network reference treatment data points specified within overlay.nma estimated included.","code":"# Overlay predictions from lumped NMAs between 5-8 and between 8-15 weeks follow-up plot(pred, overlay.nma=c(5,8,15), n.iter=20000) #> Reference treatment in plots is Pl_0 #> Running overlay.nma for time=5 and time=8 #> Running overlay.nma for time=8 and time=15"},{"path":"/articles/MBNMAtime.html","id":"consistency-testing","dir":"Articles","previous_headings":"","what":"Consistency Testing","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"performing MBNMA pooling relative treatment effects (pool=\"rel\"), modelling approach assumes consistency direct indirect evidence within network. incredibly useful assumption allows us improve precision existing direct estimates, estimate relative effects treatments compared head--head trials, making use indirect evidence. However, assumption hold extremely problematic inference, important able test . number different approaches exist allow standard Network Meta-Analysis (Dias et al. 2013). Two implemented within MBNMAtime. important note model specifications likely sharing model parameters (e.g. heterogeneity parameters, correlation coefficients) across networks lead conservative tests consistency, may lead inflated type II error. Consistency also likely differ depending model used. Failing appropriately model time-course function may fact induce inconsistency data. “Lumping” together different time points studies standard NMA known potential cause inconsistency, one reasons accounting time-course using MBNMA important (Pedder et al. 2019). performing MBNMA, important first try identify best model possible terms time-course common/random effects, test consistency within model, rather testing consistency models known good fit data. Consistency testing can performed networks closed loops treatment comparisons exist drawn independent sources evidence. networks loops evidence, consistency formally tested (though may still present). mb.nodesplit.comparisons() function identifies loops evidence conform property, identifies treatment comparison within loop direct indirect evidence can compared using node-splitting (see ).","code":"# Loops of evidence within the alogliptin dataset splits.alog <- mb.nodesplit.comparisons(network.alog) print(splits.alog) #>   t1 t2    path #> 8  3  4 3->1->4 #> 7  2  5 2->1->5 #> 6  2  4 2->1->4 #> 5  2  3 2->1->3"},{"path":"/articles/MBNMAtime.html","id":"unrelated-mean-effects-ume-models","dir":"Articles","previous_headings":"Consistency Testing","what":"Unrelated Mean Effects (UME) models","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"check consistency using UME fit model assume consistency relationships, models direct relative effects arm study study reference treatment. consistency assumption holds true results UME model MBNMA similar. However, discrepancy direct indirect evidence network, consistency assumption may valid, UME results likely differ several ways: UME model may provide better fit data, measured deviance residual deviance -study SD different parameters may lower UME model Individual relative effects may differ magnitude (severely) direction different treatment comparisons UME MBNMA models UME can fitted time-course parameter modelled using relative effects (pool=\"rel\"). UME can specified time-course parameter separate analyses, can modelled single analysis. comparing deviance (residual deviance) models UME fitted different time-course parameters MBNMA model, can see reduction deviance different UME models. Given deviance lowest UME modelled beta.1 suggestive inconsistency direct indirect evidence beta.1, perhaps also beta.2 given modelling UME also leads reduction deviance. Direct estimates UME MBNMA models can also compared examine greater detail inconsistency may affecting results. However, important note whilst discrepancy UME MBNMA results may seen particular relative effect, inconsistency exclusively applicable particular treatment comparison may originate comparisons network. consistency checking important, violation consistency assumption raises concerns estimates treatments within network.","code":"# Identify quantile for knot at 0.5 weeks timequant <- 0.5/max(network.pain$data.ab$time)  # Fit a B-spline MBNMA with common relative effects on slope.1 and slope.2 mbnma <- mb.run(network.pain,                 fun=tspline(type=\"bs\", knots=timequant,                             pool.1 = \"rel\", method.1=\"common\",                             pool.2 = \"rel\", method.2=\"common\"                             ))  # Fit a UME model on both spline coefficients simultaneously ume <- mb.run(network.pain,                 fun=tspline(type=\"bs\", knots=timequant,                             pool.1 = \"rel\", method.1=\"common\",                             pool.2 = \"rel\", method.2=\"common\"                             ),               UME=TRUE)  # Fit a UME model on the 1nd coefficient only ume.slope.1 <- mb.run(network.pain,                 fun=tspline(type=\"bs\", knots=timequant,                             pool.1 = \"rel\", method.1=\"common\",                             pool.2 = \"rel\", method.2=\"common\"                             ),               UME=\"beta.1\")  # Fit a UME model on the 2nd coefficient only ume.slope.2 <- mb.run(network.pain,                 fun=tspline(type=\"bs\", knots=timequant,                             pool.1 = \"rel\", method.1=\"common\",                             pool.2 = \"rel\", method.2=\"common\"                             ),               UME=\"beta.2\") #> [1] \"Deviance for mbnma: -104.54\" #> [1] \"Deviance for ume on beta.1 and beta.2: -115.5\" #> [1] \"Deviance for ume on beta.1: -117.0\" #> [1] \"Deviance for ume on beta.2: -115.2\""},{"path":"/articles/MBNMAtime.html","id":"node-splitting","dir":"Articles","previous_headings":"Consistency Testing","what":"Node-splitting","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"Another approach consistency checking node-splitting. splits contributions particular treatment comparison direct indirect evidence, two can compared test similarity. mb.nodesplit() takes similar arguments mb.run() define underlying MBNMA model test consistency, returns object class(\"mb.nodesplit\"). two additional arguments required: comparisons indicates treatment comparisons perform node-split. default value automatically identify comparisons direct indirect evidence contributions available using mb.nodesplit.comparisons(). nodesplit.parameters indicates time-course parameters perform node-split. can take time-course parameters assigned relative effects model (pool=\"rel\"). Alternatively default \"\" can used split available time-course parameters model pooled using relative effects. two models need run treatment comparison split, function can take time run. Performing print() method object class(\"mb.nodesplit\") prints summary node-split results console, whilst summary() method return data frame posterior summaries direct indirect estimates split treatment comparison time-course parameter. possible generate different plots node-split comparison using plot():  example, use different time-course function (1-parameter ITP) less good fit data, perform node-split rate time-course parameter, find seems strong discrepancy direct indirect estimates. strong evidence reject consistency assumption, either (case) try identify better fitting model, re-examine dataset try explain whether differences studies making different comparisons may causing . highlights importance testing consistency identifying appropriate time-course common/random treatment effects model.","code":"# Nodesplit using an Emax MBNMA nodesplit <- mb.nodesplit(network.pain,                           fun=temax(pool.emax=\"rel\", method.emax = \"random\",                                     pool.et50=\"abs\", method.et50 = \"common\"),                           nodesplit.parameters=\"all\"                           ) print(nodesplit) #> ======================================== #> Node-splitting analysis of inconsistency #> ======================================== #>  #> emax #>  #> |Comparison        | p-value| Median|   2.5%|  97.5%| #> |:-----------------|-------:|------:|------:|------:| #> |Ro_25 vs Ce_200   |   0.028|       |       |       | #> |-> direct         |        |  0.384| -0.460|  1.205| #> |-> indirect       |        | -0.541| -1.020| -0.064| #> |                  |        |       |       |       | #> |Na_1000 vs Ce_200 |   0.007|       |       |       | #> |-> direct         |        |  0.228| -0.213|  0.684| #> |-> indirect       |        | -0.515| -0.891| -0.137| #> |                  |        |       |       |       | # Plot forest plots of direct and indirect results for each node-split comparison plot(nodesplit, plot.type=\"forest\")  # Plot posterior densities of direct and indirect results for each node-split comparisons plot(nodesplit, plot.type=\"density\") # Nodesplit on emax of 1-parameter ITP MBNMA ns.itp <- mb.nodesplit(network.pain,                        fun=titp(pool.emax = \"rel\", method.emax=\"common\"),                        nodesplit.parameters=\"all\") print(ns.itp) #> ======================================== #> Node-splitting analysis of inconsistency #> ======================================== #>  #> emax #>  #> |Comparison        | p-value| Median|   2.5%|  97.5%| #> |:-----------------|-------:|------:|------:|------:| #> |Ro_25 vs Ce_200   |    0.09|       |       |       | #> |-> direct         |        |  0.163| -0.200|  0.542| #> |-> indirect       |        | -0.136| -0.440|  0.126| #> |                  |        |       |       |       | #> |Na_1000 vs Ce_200 |    0.00|       |       |       | #> |-> direct         |        |  0.002| -0.129|  0.137| #> |-> indirect       |        | -0.378| -0.513| -0.249| #> |                  |        |       |       |       | #>  #> rate #>  #> |Comparison        | p-value| Median|   2.5%|  97.5%| #> |:-----------------|-------:|------:|------:|------:| #> |Ro_25 vs Ce_200   |   0.396|       |       |       | #> |-> direct         |        | 21.295|  0.869| 68.722| #> |-> indirect       |        | 14.079|  0.261| 67.282| #> |                  |        |       |       |       | #> |Na_1000 vs Ce_200 |   0.082|       |       |       | #> |-> direct         |        | 21.176|  1.085| 69.708| #> |-> indirect       |        |  0.320| -0.088| 38.232| #> |                  |        |       |       |       |  plot(ns.itp, plot.type=\"forest\")"},{"path":"/articles/MBNMAtime.html","id":"conclusions","dir":"Articles","previous_headings":"","what":"Conclusions","title":"MBNMAtime for time-course Model-Based (Network) Meta-Analysis","text":"MBNMAtime provides complete set functions allow meta-analysis longitudinal time-course data plotting number informative graphics. Functions provided ranking, prediction, assessing consistency modelling using relative effects. accounting time-course meta-analysis can help explain heterogeneity/inconsistency may arise lumping together different time-points using conventional NMA. package allows flexible modelling either relative absolute effects interchangeably different time-course parameters within analysis, whilst providing straightforward syntax define models.","code":""},{"path":[]},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Hugo Pedder. Author, maintainer. Nicky Welton. Contributor, reviewer. Sofia Dias. Contributor, reviewer. Meg Bennetts. Contributor, reviewer. Martin Boucher. Contributor, reviewer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Pedder, H., Dias, S., Bennetts, M., Boucher, M. Welton, N. J. (2019), Modelling time-course relationships multiple treatments: Model-based network meta-analysis continuous summary outcomes. Research Synthesis Methods, 10:267-286. doi:10.1002/jrsm.1351","code":"@Article{,   title = {Modelling time-course relationships with multiple treatments: Model-based network meta-analysis for continuous summary outcomes},   author = {Hugo Pedder and Sofia Dias and Margherita Bennetts and Martin Boucher and Nicky J Welton},   journal = {Research Synthesis Methods},   year = {2019},   volume = {10},   number = {2},   pages = {267-286},   url = {https://doi.org/10.1002/jrsm.1351},   doi = {10.1002/jrsm.1351}, }"},{"path":"/index.html","id":"mbnmatime","dir":"","previous_headings":"","what":"Run Time-Course Model-Based Network Meta-Analysis (MBNMA) Models","title":"Run Time-Course Model-Based Network Meta-Analysis (MBNMA) Models","text":"goal MBNMAtime provide collection useful commands allow users run time-course Model-Based Network Meta-Analysis (MBNMA). allows meta-analysis studies multiple follow-measurements can account time-course single multiple treatment comparisons. Including available follow-measurements within study makes use available evidence way maintains connectivity treatments, way explains time-course, thus explaining heterogeneity inconsistency may present standard Network Meta-Analysis (NMA). models analyses implemented Bayesian framework, following extension standard NMA methodology presented Lu Ades (2004) run JAGS (JAGS Computer Program 2017). full details time-course MBNMA methodology see Pedder et al. (2019).","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Run Time-Course Model-Based Network Meta-Analysis (MBNMA) Models","text":"Currently package available CRAN can can installed using: development version can installed directly GitHub using devtools R package:","code":"install.packages(\"MBNMAtime\") # First install devtools install.packages(\"devtools\")  # Then install MBNMAtime directly from GitHub devtools::install_github(\"hugaped/MBNMAtime\")"},{"path":"/index.html","id":"workflow","dir":"","previous_headings":"","what":"Workflow","title":"Run Time-Course Model-Based Network Meta-Analysis (MBNMA) Models","text":"Functions within MBNMAtime follow clear pattern use: Load data correct format using mb.network() Specify suitable time-course function analyse data using mb.run() Test consistency using functions like mb.nodesplit() Examine model results using forest plots treatment rankings Use model predict responses estimate treatment effects specific time-points using predict() stages number informative plots can generated help make sense data models fitting. Exported functions package connected like : MBNMAtime package structure: Light green nodes represent classes generic functions can applied . Dashed boxes indicate functions can applied objects specific classes","code":""},{"path":[]},{"path":"/reference/MBNMAtime-package.html","id":null,"dir":"Reference","previous_headings":"","what":"MBNMAtime for Model-Based Network Meta-Analysis of longitudinal (time-course) data — MBNMAtime-package","title":"MBNMAtime for Model-Based Network Meta-Analysis of longitudinal (time-course) data — MBNMAtime-package","text":"MBNMAtime provides collection useful commands allow users run time-course Model-Based Network Meta-Analysis (MBNMA).","code":""},{"path":"/reference/MBNMAtime-package.html","id":"introduction","dir":"Reference","previous_headings":"","what":"Introduction","title":"MBNMAtime for Model-Based Network Meta-Analysis of longitudinal (time-course) data — MBNMAtime-package","text":"MBNMAtime allows meta-analysis studies multiple follow-measurements can account time-course single multiple treatment comparisons. Including available follow-measurements within study makes use available evidence way maintains connectivity treatments, way explains time-course, thus explaining heterogeneity inconsistency may present standard Network Meta-Analysis (NMA). models analyses implemented Bayesian framework, following extension standard NMA methodology presented (Lu Ades 2004)  run JAGS ( ) . Correlation time-points can accounted modeling framework. full details time-course MBNMA methodology see Pedder et al. (2019) .","code":""},{"path":"/reference/MBNMAtime-package.html","id":"workflow","dir":"Reference","previous_headings":"","what":"Workflow","title":"MBNMAtime for Model-Based Network Meta-Analysis of longitudinal (time-course) data — MBNMAtime-package","text":"Functions within MBNMAtime follow clear pattern use: Load data correct format using mb.network Specify suitable time-course function analyse data using mb.run Test consistency using mb.nodesplit fitting Unrelated Mean Effects models Examine model results using forest plots treatment rankings Use model predict responses estimate treatment effects specific time-points using predict.mbnma stages number informative plots can generated help make sense data models fitting.","code":""},{"path":"/reference/MBNMAtime-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"MBNMAtime for Model-Based Network Meta-Analysis of longitudinal (time-course) data — MBNMAtime-package","text":"(2017). https://mcmc-jags.sourceforge.io/. Lu G, Ades AE (2004). “Combination direct indirect evidence mixed treatment comparisons.” Stat Med, 23(20), 3105-24. ISSN 0277-6715 (Print) 0277-6715 (Linking), doi:10.1002/sim.1875 , https://pubmed.ncbi.nlm.nih.gov/15449338/. Pedder H, Dias S, Bennetts M, Boucher M, Welton NJ (2019). “Modelling time-course relationships multiple treatments: Model-Based Network Meta-Analysis continuous summary outcomes.” Res Synth Methods, 10(2), 267-286.","code":""},{"path":"/reference/MBNMAtime-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"MBNMAtime for Model-Based Network Meta-Analysis of longitudinal (time-course) data — MBNMAtime-package","text":"Maintainer: Hugo Pedder hugopedder@gmail.com (ORCID) contributors: Nicky Welton [contributor, reviewer] Sofia Dias [contributor, reviewer] Meg Bennetts [contributor, reviewer] Martin Boucher [contributor, reviewer]","code":""},{"path":"/reference/MBNMAtime-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MBNMAtime for Model-Based Network Meta-Analysis of longitudinal (time-course) data — MBNMAtime-package","text":"","code":"# \\donttest{ # Generate an \"mb.network\" object that stores data in the correct format network <- mb.network(osteopain) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Generate a network plot plot(network, label.distance=3)  # Analyse data using mb.run() result <- mb.run(network, fun=tloglin()) #> Change from version 0.2.2 onwards: corparam=FALSE as default #> module glm loaded  #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 88 #>    Total graph size: 7302 #>  #> Initializing model #>   # Time-course parameters can be explicitly specified # Correlation between time-points can be accounted for result <- mb.run(network,   fun=temax(pool.emax=\"rel\", method.emax=\"common\",     pool.et50=\"rel\", method.et50=\"common\"),   rho=\"dunif(0,1)\") #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 147 #>    Total graph size: 8296 #>  #> Initializing model #>   # Explore model fit statistics - plot residual deviances devplot(result, n.iter=500) #> `dev` not monitored in mbnma$parameters.to.save. #> additional iterations will be run in order to obtain results for `dev`   # Generate a forest plot for model results plot(result)   decision.treats <- c(\"Pl_0\", \"Ce_100\", \"Lu_400\", \"Ro_125\",   \"Na_1000\", \"Na_1500\", \"Et_10\")  # Predict responses for selected treatments pred <- predict(result, time=c(0:10), E0=8,   treats=decision.treats,   ref.resp=subset(osteopain, treatment==\"Pl_0\")) #> Data frame must contain only data from reference treatment #> Studies reporting change from baseline automatically identified from ref.resp #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 113 #>    Unobserved stochastic nodes: 32 #>    Total graph size: 2039 #>  #> Initializing model #>   # Plot predicted response plot(pred, disp.obs=TRUE) #> Reference treatment in plots is Pl_0   # Rank by Area Under the time-course Curve ranks <- rank(result, param=\"auc\", lower_better=TRUE, n.iter=500,   treats=decision.treats) #>    |                                                                               |                                                                      |   0%   |                                                                               |                                                                      |   1%   |                                                                               |=                                                                     |   1%   |                                                                               |=                                                                     |   2%   |                                                                               |==                                                                    |   2%   |                                                                               |==                                                                    |   3%   |                                                                               |===                                                                   |   4%   |                                                                               |===                                                                   |   5%   |                                                                               |====                                                                  |   5%   |                                                                               |====                                                                  |   6%   |                                                                               |=====                                                                 |   7%   |                                                                               |=====                                                                 |   8%   |                                                                               |======                                                                |   8%   |                                                                               |======                                                                |   9%   |                                                                               |=======                                                               |   9%   |                                                                               |=======                                                               |  10%   |                                                                               |=======                                                               |  11%   |                                                                               |========                                                              |  11%   |                                                                               |========                                                              |  12%   |                                                                               |=========                                                             |  12%   |                                                                               |=========                                                             |  13%   |                                                                               |==========                                                            |  14%   |                                                                               |==========                                                            |  15%   |                                                                               |===========                                                           |  15%   |                                                                               |===========                                                           |  16%   |                                                                               |============                                                          |  17%   |                                                                               |============                                                          |  18%   |                                                                               |=============                                                         |  18%   |                                                                               |=============                                                         |  19%   |                                                                               |==============                                                        |  19%   |                                                                               |==============                                                        |  20%   |                                                                               |==============                                                        |  21%   |                                                                               |===============                                                       |  21%   |                                                                               |===============                                                       |  22%   |                                                                               |================                                                      |  22%   |                                                                               |================                                                      |  23%   |                                                                               |=================                                                     |  24%   |                                                                               |=================                                                     |  25%   |                                                                               |==================                                                    |  25%   |                                                                               |==================                                                    |  26%   |                                                                               |===================                                                   |  27%   |                                                                               |===================                                                   |  28%   |                                                                               |====================                                                  |  28%   |                                                                               |====================                                                  |  29%   |                                                                               |=====================                                                 |  29%   |                                                                               |=====================                                                 |  30%   |                                                                               |=====================                                                 |  31%   |                                                                               |======================                                                |  31%   |                                                                               |======================                                                |  32%   |                                                                               |=======================                                               |  32%   |                                                                               |=======================                                               |  33%   |                                                                               |========================                                              |  34%   |                                                                               |========================                                              |  35%   |                                                                               |=========================                                             |  35%   |                                                                               |=========================                                             |  36%   |                                                                               |==========================                                            |  37%   |                                                                               |==========================                                            |  38%   |                                                                               |===========================                                           |  38%   |                                                                               |===========================                                           |  39%   |                                                                               |============================                                          |  39%   |                                                                               |============================                                          |  40%   |                                                                               |============================                                          |  41%   |                                                                               |=============================                                         |  41%   |                                                                               |=============================                                         |  42%   |                                                                               |==============================                                        |  42%   |                                                                               |==============================                                        |  43%   |                                                                               |===============================                                       |  44%   |                                                                               |===============================                                       |  45%   |                                                                               |================================                                      |  45%   |                                                                               |================================                                      |  46%   |                                                                               |=================================                                     |  47%   |                                                                               |=================================                                     |  48%   |                                                                               |==================================                                    |  48%   |                                                                               |==================================                                    |  49%   |                                                                               |===================================                                   |  49%   |                                                                               |===================================                                   |  50%   |                                                                               |===================================                                   |  51%   |                                                                               |====================================                                  |  51%   |                                                                               |====================================                                  |  52%   |                                                                               |=====================================                                 |  52%   |                                                                               |=====================================                                 |  53%   |                                                                               |======================================                                |  54%   |                                                                               |======================================                                |  55%   |                                                                               |=======================================                               |  55%   |                                                                               |=======================================                               |  56%   |                                                                               |========================================                              |  57%   |                                                                               |========================================                              |  58%   |                                                                               |=========================================                             |  58%   |                                                                               |=========================================                             |  59%   |                                                                               |==========================================                            |  59%   |                                                                               |==========================================                            |  60%   |                                                                               |==========================================                            |  61%   |                                                                               |===========================================                           |  61%   |                                                                               |===========================================                           |  62%   |                                                                               |============================================                          |  62%   |                                                                               |============================================                          |  63%   |                                                                               |=============================================                         |  64%   |                                                                               |=============================================                         |  65%   |                                                                               |==============================================                        |  65%   |                                                                               |==============================================                        |  66%   |                                                                               |===============================================                       |  67%   |                                                                               |===============================================                       |  68%   |                                                                               |================================================                      |  68%   |                                                                               |================================================                      |  69%   |                                                                               |=================================================                     |  69%   |                                                                               |=================================================                     |  70%   |                                                                               |=================================================                     |  71%   |                                                                               |==================================================                    |  71%   |                                                                               |==================================================                    |  72%   |                                                                               |===================================================                   |  72%   |                                                                               |===================================================                   |  73%   |                                                                               |====================================================                  |  74%   |                                                                               |====================================================                  |  75%   |                                                                               |=====================================================                 |  75%   |                                                                               |=====================================================                 |  76%   |                                                                               |======================================================                |  77%   |                                                                               |======================================================                |  78%   |                                                                               |=======================================================               |  78%   |                                                                               |=======================================================               |  79%   |                                                                               |========================================================              |  79%   |                                                                               |========================================================              |  80%   |                                                                               |========================================================              |  81%   |                                                                               |=========================================================             |  81%   |                                                                               |=========================================================             |  82%   |                                                                               |==========================================================            |  82%   |                                                                               |==========================================================            |  83%   |                                                                               |===========================================================           |  84%   |                                                                               |===========================================================           |  85%   |                                                                               |============================================================          |  85%   |                                                                               |============================================================          |  86%   |                                                                               |=============================================================         |  87%   |                                                                               |=============================================================         |  88%   |                                                                               |==============================================================        |  88%   |                                                                               |==============================================================        |  89%   |                                                                               |===============================================================       |  89%   |                                                                               |===============================================================       |  90%   |                                                                               |===============================================================       |  91%   |                                                                               |================================================================      |  91%   |                                                                               |================================================================      |  92%   |                                                                               |=================================================================     |  92%   |                                                                               |=================================================================     |  93%   |                                                                               |==================================================================    |  94%   |                                                                               |==================================================================    |  95%   |                                                                               |===================================================================   |  95%   |                                                                               |===================================================================   |  96%   |                                                                               |====================================================================  |  97%   |                                                                               |====================================================================  |  98%   |                                                                               |===================================================================== |  98%   |                                                                               |===================================================================== |  99%   |                                                                               |======================================================================|  99%   |                                                                               |======================================================================| 100%  plot(ranks) # Plot histogram of rankings  cumrank(ranks) # Plot cumulative rankograms  #> # A tibble: 7 × 3 #>   treatment parameter sucra #>   <fct>     <chr>     <dbl> #> 1 Pl_0      auc        0.5  #> 2 Ce_100    auc        2.36 #> 3 Lu_400    auc        1.65 #> 4 Ro_125    auc        3.75 #> 5 Na_1000   auc        5.34 #> 6 Na_1500   auc        4.40 #> 7 Et_10     auc        6    # }"},{"path":"/reference/add_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Add follow-up time and arm indices to a dataset — add_index","title":"Add follow-up time and arm indices to a dataset — add_index","text":"Adds follow-time (fups, fupcount) arm (arms, narms) indices dataset.","code":""},{"path":"/reference/add_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add follow-up time and arm indices to a dataset — add_index","text":"","code":"add_index(data.ab, reference = 1)"},{"path":"/reference/add_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add follow-up time and arm indices to a dataset — add_index","text":"data.ab data frame arm-level data \"long\" format containing columns: studyID Study identifiers time Numeric data indicating follow-times treatment Treatment identifiers (can numeric, factor character) class optional column indicating particular class code. Treatments identifier must also class code. reference number character (depending format treatment within data.ab) indicating reference treatment network (.e. estimated relative treatment effects estimated model compared ).","code":""},{"path":"/reference/add_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add follow-up time and arm indices to a dataset — add_index","text":"data frame similar data.ab additional columns: arm Arm identifiers coded study fupcount Follow-identifiers coded study fups total number follow-measurements study narm total number arms study treatment class non-numeric non-sequential (.e. missing numeric codes), treatments/classes returned data frame numbered recoded enforce sequential numbering (warning shown stating ).","code":""},{"path":"/reference/add_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add follow-up time and arm indices to a dataset — add_index","text":"","code":"# Add indices to osteoarthritis pain dataset data.ab <- add_index(osteopain) #> Reference treatment is `Pl_0`  # Add indices to dataset using different network reference treatment data.ab <- add_index(osteopain, reference=3) #> Reference treatment is `Ce_200`"},{"path":"/reference/alog_pcfb.html","id":null,"dir":"Reference","previous_headings":"","what":"Studies of alogliptin for lowering blood glucose concentration in patients with type II diabetes — alog_pcfb","title":"Studies of alogliptin for lowering blood glucose concentration in patients with type II diabetes — alog_pcfb","text":"dataset systematic review Randomised-Controlled Trials (RCTs) comparing different doses alogliptin placebo (Langford et al. 2016) . systematic review simply performed intended provide data illustrate statistical methodology rather clinical inference. Alogliptin treatment aimed reducing blood glucose concentration type II diabetes. outcome continuous, aggregate data responses correspond mean change HbA1c baseline follow-. dataset includes 14 Randomised-Controlled Trials (RCTs), comparing 5 different doses alogliptin placebo, leading 6 different treatments (combination dose agent) within network.","code":""},{"path":"/reference/alog_pcfb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Studies of alogliptin for lowering blood glucose concentration in patients with type II diabetes — alog_pcfb","text":"","code":"alog_pcfb"},{"path":"/reference/alog_pcfb.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Studies of alogliptin for lowering blood glucose concentration in patients with type II diabetes — alog_pcfb","text":"data frame long format (one row per arm study), 46 rows 9 variables: studyID Study identifiers clinicaltrialGov_ID clinicaltrial.gov ID code agent Character data indicating agent participants randomised dose Numeric data indicating standardised dose received treatment Character data indicating treatment (combination agent dose) participants randomised time Numeric data indicating time observation measured (given weeks) y Numeric data indicating mean change baseline blood glucose concentration (mg/dL) study arm se Numeric data indicating standard error mean change baseline blood glucose concentration (mg/dL) study arm n Numeric data indicating number arm follow-time","code":""},{"path":"/reference/alog_pcfb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Studies of alogliptin for lowering blood glucose concentration in patients with type II diabetes — alog_pcfb","text":"alog_pcfb data frame long format (one row per observation, arm study), variables studyID, clinicaltrialGov_ID, agent, dose, treatment, time, y, se, n.","code":""},{"path":"/reference/alog_pcfb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Studies of alogliptin for lowering blood glucose concentration in patients with type II diabetes — alog_pcfb","text":"Langford O, Aronson JK, van Valkenhoef G, Stevens RJ (2016). “Methods meta-analysis pharmacodynamic dose-response data application multi-arm studies alogliptin.” Stat Methods Med Res. ISSN 1477-0334 (Electronic) 0962-2802 (Linking), doi:10.1177/0962280216637093 , https://pubmed.ncbi.nlm.nih.gov/26994216/.","code":""},{"path":"/reference/binplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot relative effects from NMAs performed at multiple time-bins — binplot","title":"Plot relative effects from NMAs performed at multiple time-bins — binplot","text":"Plot relative effects NMAs performed multiple time-bins","code":""},{"path":"/reference/binplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot relative effects from NMAs performed at multiple time-bins — binplot","text":"","code":"binplot(   network,   overlay.nma = c(0, stats::quantile(network$data.ab$time)),   method = \"common\",   link = \"identity\",   lim = \"cred\",   plot.bins = TRUE,   legend = TRUE,   ... )"},{"path":"/reference/binplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot relative effects from NMAs performed at multiple time-bins — binplot","text":"network object class \"mb.network\". overlay.nma Numeric vector used overlay results standard NMA model \"lumps\" time-points together within time bin ranges specified overlay.nma. numbers overlay.nma define boundaries time bins within perform standard NMA. Length must >=2, can left NULL (default) indicate NMA perfomed. overlay.nma can specified overlay.ref==TRUE. See Details information. method Can take \"common\" \"random\" indicate type NMA model used synthesise data points given overlay.nma. default \"random\" since assumes different time-points overlay.nma lumped together estimate NMA. link Can take either \"identity\" (default), \"log\" (modelling Ratios Means (Friedrich et al. 2011) ) \"smd\" (modelling Standardised Mean Differences - although also corresponds identity link function). lim Specifies calculation either 95% credible intervals (lim=\"cred\") 95% prediction intervals (lim=\"pred\"). plot.bins Plot time bin boundaries vertical dashed lines. Setting plot.bins=TRUE overlay.nma specified also sets x-axis ticks time bin boundaries automatically. legend TRUE/FALSE indicate whether legend plotted. ... Arguments sent R2jags.","code":""},{"path":"/reference/binplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot relative effects from NMAs performed at multiple time-bins — binplot","text":"Performs several standard NMAs different time \"bins\", time periods within treatment effects assumed constant time. Separate NMAs performed within time bin data points studies fall within time bin (single follow-time taken study avoid double counting). Note wider time bin boundaries specified user, larger potential range included follow-times can introduce heterogeneity inconsistency. Results plotted versus network reference plotted specified link scale. time bin window marked plot vertical dashed lines. NMA estimates within time bin plotted horizontal solid black line (posterior median) shaded region indicating 95% credible interval (prediction intervals can instead plotted). width shaded regions equal range study time-points included NMA performed within timebin, may therefore narrow time bin specified binplot() command due follow-times data available included studies.","code":""},{"path":"/reference/binplot.html","id":"overlaying-nma-results","dir":"Reference","previous_headings":"","what":"Overlaying NMA results","title":"Plot relative effects from NMAs performed at multiple time-bins — binplot","text":"overlay.nma indicates regions data (defined \"time bins\") may reasonable \"lump\" different follow-times different studies together assume standard NMA model. example: overlay.nma=c(5,10) indicates single NMA studies follow-times >5 <=10 overlay.nma=c(5,10,15) indicates two NMAs performed studies follow-times >5 <=10 studies follow-times >10 <=15 used MBNMA (via predict.mbnma()) allows comparison MBNMA results specific range time within time bin. can useful assess time-course function might suitable using binplot(), assess MBNMA predictions agreement predictions NMA model using plot.mb.predict() specific range time-points. can general indicator fit time-course model. However, important note wider range specified overlay.nma, likely different time-points included, therefore greater heterogeneity/inconsistency NMA model. overlay.nma includes several follow-times study single time-point taken (one closest mean(overlay.nma)). NMA predictions plotted range specified overlay.nma horizontal line, 95%CrI shown grey rectangle. NMA predictions represent time-points within range since lump together data time-points. Predictions treatments disconnected network reference treatment data points specified within overlay.nma estimated included. important note NMA model necessarily \"correct\" model, since \"lumps\" different time-points together ignores potential differences treatment effects may arise . wider range specified overlay.nma, greater effect \"lumping\" stronger assumption similarity studies. NMA model estimated corresponding prediction made , time bin must include network reference treatment (treatment=1) evaluated least 1 connected study time bin. given time bin meet criteria NMA calculated .","code":""},{"path":"/reference/binplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot relative effects from NMAs performed at multiple time-bins — binplot","text":"","code":"# \\donttest{ # Create an mb.network object from a dataset alognet <- mb.network(alog_pcfb) #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data  # Plot relative effects from NMAs calculated for a single time-bins # Do not plot time-bin boundaries binplot(alognet, overlay.nma=c(0,5), plot.bins=FALSE) #> Running overlay.nma for time=0 and time=5 #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 32 #>    Unobserved stochastic nodes: 14 #>    Total graph size: 307 #>  #> Initializing model #>    # Plot relative effects from NMAs at multiple time-bins # With random treatment effects binplot(alognet, overlay.nma=c(5,10,15,20),   method=\"random\") #> Running overlay.nma for time=5 and time=10 #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 42 #>    Unobserved stochastic nodes: 48 #>    Total graph size: 580 #>  #> Initializing model #>  #> Running overlay.nma for time=10 and time=15 #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 46 #>    Unobserved stochastic nodes: 52 #>    Total graph size: 641 #>  #> Initializing model #>  #> Running overlay.nma for time=15 and time=20 #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 23 #>    Unobserved stochastic nodes: 28 #>    Total graph size: 321 #>  #> Initializing model #>   # }"},{"path":"/reference/copd.html","id":null,"dir":"Reference","previous_headings":"","what":"Studies comparing Tiotropium, Aclidinium and Placebo for maintenance treatment of moderate to severe chronic obstructive pulmonary disease — copd","title":"Studies comparing Tiotropium, Aclidinium and Placebo for maintenance treatment of moderate to severe chronic obstructive pulmonary disease — copd","text":"dataset systematic review Randomised-Controlled Trials (RCTs) maintenance treatment moderate severe chronic obstructive pulmonary disease (COPD) (Karabis et al. 2013) . Data extracted (Tallarita et al. 2019) . SEs imputed three studies, number patients randomised imputed one study (LAS 39) missing, using median standard deviation calculated studies dataset. outcome trough Forced Expiratory Volume 1 second (FEV1), measured litres reported study arm mean change baseline follow-. dataset includes 13 Randomised-Controlled Trials (RCTs), comparing 2 treatments (Tiotropium Aclidinium) placebo.","code":""},{"path":"/reference/copd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Studies comparing Tiotropium, Aclidinium and Placebo for maintenance treatment of moderate to severe chronic obstructive pulmonary disease — copd","text":"","code":"copd"},{"path":"/reference/copd.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Studies comparing Tiotropium, Aclidinium and Placebo for maintenance treatment of moderate to severe chronic obstructive pulmonary disease — copd","text":"data frame long format (one row per arm study), 80 rows 6 variables: studyID Study identifiers time Numeric data indicating time observation measured (given weeks) y Numeric data indicating mean change baseline FEV1 (litres) study arm se Numeric data indicating standard error mean change baseline FEV1 study arm treatment Factor data indicating treatment participants randomised n Numeric data indicating number participants randomised arm","code":""},{"path":"/reference/copd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Studies comparing Tiotropium, Aclidinium and Placebo for maintenance treatment of moderate to severe chronic obstructive pulmonary disease — copd","text":"copd data frame long format (one row per observation, arm study), variables studyID, time, y, se, treatment, n.","code":""},{"path":"/reference/copd.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Studies comparing Tiotropium, Aclidinium and Placebo for maintenance treatment of moderate to severe chronic obstructive pulmonary disease — copd","text":"Karabis , Lindner L, Mocarski M, Huisman E, Greening (2013). “Comparative efficacy aclidinium versus glycopyrronium tiotropium, maintenance treatment moderate severe COPD patients: systematic review network meta-analysis.” Int J Chron Obstruct Pulmon Dis, 8, 405-423. doi:10.2147/COPD.S48967 , https://pubmed.ncbi.nlm.nih.gov/24043936/. Tallarita M, De lorio M, Baio G (2019). “comparative review network meta-analysis models longitudinal randomized controlled trial.” Statistics Medicine, 38(16), 3053-3072. doi:10.1002/sim.8169 , https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8169.","code":""},{"path":"/reference/cumrank.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot cumulative ranking curves from MBNMA models — cumrank","title":"Plot cumulative ranking curves from MBNMA models — cumrank","text":"Plot cumulative ranking curves MBNMA models","code":""},{"path":"/reference/cumrank.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot cumulative ranking curves from MBNMA models — cumrank","text":"","code":"cumrank(x, params = NULL, sucra = TRUE, ...)"},{"path":"/reference/cumrank.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot cumulative ranking curves from MBNMA models — cumrank","text":"x object class \"mb.rank\" generated rank.mbnma() params character vector containing model parameters monitored mbnma ranking desired (e.g. \"beta.1\", \"emax\"). Parameters must vary treatment ranking possible. Can include \"auc\" (see details). sucra logical object indicate whether Surface Cumulative Ranking Curve (SUCRA) values calculated returned data frame. Areas calculated using readWKT. ... Arguments sent ggplot::geom_line()","code":""},{"path":"/reference/cumrank.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot cumulative ranking curves from MBNMA models — cumrank","text":"Line plots showing cumulative ranking probabilities agent/class dose-response parameter x. object returned list contains plot (object class(c(\"gg\", \"ggplot\")) data frame SUCRA values sucra = TRUE.","code":""},{"path":"/reference/cumrank.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot cumulative ranking curves from MBNMA models — cumrank","text":"","code":"# \\donttest{ # Using the alogliptin data network <- mb.network(alog_pcfb) #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data  # Estimate rankings  from an Emax dose-response MBNMA emax <- mb.run(network, fun=temax()) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 233 #>    Unobserved stochastic nodes: 38 #>    Total graph size: 4166 #>  #> Initializing model #>  ranks <- rank(emax, params=c(\"emax\", \"et50\", \"auc\")) #>    |                                                                               |                                                                      |   0%   |                                                                               |                                                                      |   1%   |                                                                               |=                                                                     |   1%   |                                                                               |=                                                                     |   2%   |                                                                               |==                                                                    |   2%   |                                                                               |==                                                                    |   3%   |                                                                               |==                                                                    |   4%   |                                                                               |===                                                                   |   4%   |                                                                               |===                                                                   |   5%   |                                                                               |====                                                                  |   5%   |                                                                               |====                                                                  |   6%   |                                                                               |=====                                                                 |   6%   |                                                                               |=====                                                                 |   7%   |                                                                               |=====                                                                 |   8%   |                                                                               |======                                                                |   8%   |                                                                               |======                                                                |   9%   |                                                                               |=======                                                               |   9%   |                                                                               |=======                                                               |  10%   |                                                                               |=======                                                               |  11%   |                                                                               |========                                                              |  11%   |                                                                               |========                                                              |  12%   |                                                                               |=========                                                             |  12%   |                                                                               |=========                                                             |  13%   |                                                                               |=========                                                             |  14%   |                                                                               |==========                                                            |  14%   |                                                                               |==========                                                            |  15%   |                                                                               |===========                                                           |  15%   |                                                                               |===========                                                           |  16%   |                                                                               |============                                                          |  16%   |                                                                               |============                                                          |  17%   |                                                                               |============                                                          |  18%   |                                                                               |=============                                                         |  18%   |                                                                               |=============                                                         |  19%   |                                                                               |==============                                                        |  19%   |                                                                               |==============                                                        |  20%   |                                                                               |==============                                                        |  21%   |                                                                               |===============                                                       |  21%   |                                                                               |===============                                                       |  22%   |                                                                               |================                                                      |  22%   |                                                                               |================                                                      |  23%   |                                                                               |================                                                      |  24%   |                                                                               |=================                                                     |  24%   |                                                                               |=================                                                     |  25%   |                                                                               |==================                                                    |  25%   |                                                                               |==================                                                    |  26%   |                                                                               |===================                                                   |  26%   |                                                                               |===================                                                   |  27%   |                                                                               |===================                                                   |  28%   |                                                                               |====================                                                  |  28%   |                                                                               |====================                                                  |  29%   |                                                                               |=====================                                                 |  29%   |                                                                               |=====================                                                 |  30%   |                                                                               |=====================                                                 |  31%   |                                                                               |======================                                                |  31%   |                                                                               |======================                                                |  32%   |                                                                               |=======================                                               |  32%   |                                                                               |=======================                                               |  33%   |                                                                               |=======================                                               |  34%   |                                                                               |========================                                              |  34%   |                                                                               |========================                                              |  35%   |                                                                               |=========================                                             |  35%   |                                                                               |=========================                                             |  36%   |                                                                               |==========================                                            |  36%   |                                                                               |==========================                                            |  37%   |                                                                               |==========================                                            |  38%   |                                                                               |===========================                                           |  38%   |                                                                               |===========================                                           |  39%   |                                                                               |============================                                          |  39%   |                                                                               |============================                                          |  40%   |                                                                               |============================                                          |  41%   |                                                                               |=============================                                         |  41%   |                                                                               |=============================                                         |  42%   |                                                                               |==============================                                        |  42%   |                                                                               |==============================                                        |  43%   |                                                                               |==============================                                        |  44%   |                                                                               |===============================                                       |  44%   |                                                                               |===============================                                       |  45%   |                                                                               |================================                                      |  45%   |                                                                               |================================                                      |  46%   |                                                                               |=================================                                     |  46%   |                                                                               |=================================                                     |  47%   |                                                                               |=================================                                     |  48%   |                                                                               |==================================                                    |  48%   |                                                                               |==================================                                    |  49%   |                                                                               |===================================                                   |  49%   |                                                                               |===================================                                   |  50%   |                                                                               |===================================                                   |  51%   |                                                                               |====================================                                  |  51%   |                                                                               |====================================                                  |  52%   |                                                                               |=====================================                                 |  52%   |                                                                               |=====================================                                 |  53%   |                                                                               |=====================================                                 |  54%   |                                                                               |======================================                                |  54%   |                                                                               |======================================                                |  55%   |                                                                               |=======================================                               |  55%   |                                                                               |=======================================                               |  56%   |                                                                               |========================================                              |  56%   |                                                                               |========================================                              |  57%   |                                                                               |========================================                              |  58%   |                                                                               |=========================================                             |  58%   |                                                                               |=========================================                             |  59%   |                                                                               |==========================================                            |  59%   |                                                                               |==========================================                            |  60%   |                                                                               |==========================================                            |  61%   |                                                                               |===========================================                           |  61%   |                                                                               |===========================================                           |  62%   |                                                                               |============================================                          |  62%   |                                                                               |============================================                          |  63%   |                                                                               |============================================                          |  64%   |                                                                               |=============================================                         |  64%   |                                                                               |=============================================                         |  65%   |                                                                               |==============================================                        |  65%   |                                                                               |==============================================                        |  66%   |                                                                               |===============================================                       |  66%   |                                                                               |===============================================                       |  67%   |                                                                               |===============================================                       |  68%   |                                                                               |================================================                      |  68%   |                                                                               |================================================                      |  69%   |                                                                               |=================================================                     |  69%   |                                                                               |=================================================                     |  70%   |                                                                               |=================================================                     |  71%   |                                                                               |==================================================                    |  71%   |                                                                               |==================================================                    |  72%   |                                                                               |===================================================                   |  72%   |                                                                               |===================================================                   |  73%   |                                                                               |===================================================                   |  74%   |                                                                               |====================================================                  |  74%   |                                                                               |====================================================                  |  75%   |                                                                               |=====================================================                 |  75%   |                                                                               |=====================================================                 |  76%   |                                                                               |======================================================                |  76%   |                                                                               |======================================================                |  77%   |                                                                               |======================================================                |  78%   |                                                                               |=======================================================               |  78%   |                                                                               |=======================================================               |  79%   |                                                                               |========================================================              |  79%   |                                                                               |========================================================              |  80%   |                                                                               |========================================================              |  81%   |                                                                               |=========================================================             |  81%   |                                                                               |=========================================================             |  82%   |                                                                               |==========================================================            |  82%   |                                                                               |==========================================================            |  83%   |                                                                               |==========================================================            |  84%   |                                                                               |===========================================================           |  84%   |                                                                               |===========================================================           |  85%   |                                                                               |============================================================          |  85%   |                                                                               |============================================================          |  86%   |                                                                               |=============================================================         |  86%   |                                                                               |=============================================================         |  87%   |                                                                               |=============================================================         |  88%   |                                                                               |==============================================================        |  88%   |                                                                               |==============================================================        |  89%   |                                                                               |===============================================================       |  89%   |                                                                               |===============================================================       |  90%   |                                                                               |===============================================================       |  91%   |                                                                               |================================================================      |  91%   |                                                                               |================================================================      |  92%   |                                                                               |=================================================================     |  92%   |                                                                               |=================================================================     |  93%   |                                                                               |=================================================================     |  94%   |                                                                               |==================================================================    |  94%   |                                                                               |==================================================================    |  95%   |                                                                               |===================================================================   |  95%   |                                                                               |===================================================================   |  96%   |                                                                               |====================================================================  |  96%   |                                                                               |====================================================================  |  97%   |                                                                               |====================================================================  |  98%   |                                                                               |===================================================================== |  98%   |                                                                               |===================================================================== |  99%   |                                                                               |======================================================================|  99%   |                                                                               |======================================================================| 100%  # Plot cumulative rankings for both dose-response parameters simultaneously # Note that SUCRA values are also returned cumrank(ranks)  #> # A tibble: 18 × 3 #>    treatment parameter sucra #>    <fct>     <chr>     <dbl> #>  1 placebo   auc       5.00  #>  2 placebo   emax      5.00  #>  3 placebo   et50      0.5   #>  4 alog_6.25 auc       4.42  #>  5 alog_6.25 emax      4.35  #>  6 alog_6.25 et50      4.22  #>  7 alog_12.5 auc       3.19  #>  8 alog_12.5 emax      3.62  #>  9 alog_12.5 et50      2.07  #> 10 alog_25   auc       2.05  #> 11 alog_25   emax      2.48  #> 12 alog_25   et50      1.96  #> 13 alog_50   auc       0.933 #> 14 alog_50   emax      1.43  #> 15 alog_50   et50      3.82  #> 16 alog_100  auc       1.90  #> 17 alog_100  emax      0.628 #> 18 alog_100  et50      4.93  # }"},{"path":"/reference/default.priors.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets default priors for JAGS model code — default.priors","title":"Sets default priors for JAGS model code — default.priors","text":"function creates JAGS code snippets default MBNMA model priors.","code":""},{"path":"/reference/default.priors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets default priors for JAGS model code — default.priors","text":"","code":"default.priors(fun = tloglin())"},{"path":"/reference/default.priors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets default priors for JAGS model code — default.priors","text":"fun object class \"timefun\" generated (see Details) using tloglin(), tpoly(), titp(), temax(), tfpoly(), tspline() tuser()","code":""},{"path":"/reference/default.priors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sets default priors for JAGS model code — default.priors","text":"list, element named JAGS snippet corresponding prior MBNMA JAGS code.","code":""},{"path":"/reference/default.priors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sets default priors for JAGS model code — default.priors","text":"","code":"# \\donttest{ default.priors(fun=temax()) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> $rho #> [1] \"rho ~ dunif(0,1)\" #>  #> $alpha #> [1] \"alpha[i] ~ dnorm(0,0.0001)\" #>  #> $inv.R #> [1] \"inv.R ~ dwish(omega[,], mat.size)\" #>  #> $rhoparam #> [1] \"rhoparam ~ dunif(-1,1)\" #>  #> $mu.1 #> [1] \"mu.1[i] ~ dnorm(0,0.0001)\" #>  #> $m.mu.1 #> [1] \"mu.1 ~ dnorm(0,0.0001)\" #>  #> $d.1 #> [1] \"d.1[k] ~ dnorm(0,0.001)\" #>  #> $dume.1 #> [1] \"d.1[c,k] ~ dnorm(0,0.001)\" #>  #> $D.1 #> [1] \"D.1[k] ~ dnorm(0,0.001)\" #>  #> $beta.1 #> [1] \"beta.1 ~ dnorm(0,0.0001)\" #>  #> $sd.mu.1 #> [1] \"sd.mu.1 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.d.1 #> [1] \"sd.d.1 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.D.1 #> [1] \"sd.D.1 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.beta.1 #> [1] \"sd.beta.1 ~ dnorm(0,0.05) T(0,)\" #>  #> $mu.2 #> [1] \"mu.2[i] ~ dnorm(0.00001,0.0001) T(0,)\" #>  #> $m.mu.2 #> [1] \"mu.2 ~ dnorm(0.00001,0.0001) T(0,)\" #>  #> $d.2 #> [1] \"d.2[k] ~ dnorm(0.00001,0.001) T(0,)\" #>  #> $dume.2 #> [1] \"d.2[c,k] ~ dnorm(0.00001,0.001) T(0,)\" #>  #> $D.2 #> [1] \"D.2[k] ~ dnorm(0.00001,0.001) T(0,)\" #>  #> $beta.2 #> [1] \"beta.2 ~ dnorm(0.00001,0.0001) T(0,)\" #>  #> $sd.mu.2 #> [1] \"sd.mu.2 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.d.2 #> [1] \"sd.d.2 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.D.2 #> [1] \"sd.D.2 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.beta.2 #> [1] \"sd.beta.2 ~ dnorm(0,0.05) T(0,)\" #>  #> $mu.3 #> [1] \"mu.3[i] ~ dnorm(0.00001,0.0001) T(0,)\" #>  #> $m.mu.3 #> [1] \"mu.3 ~ dnorm(0.00001,0.0001) T(0,)\" #>  #> $d.3 #> [1] \"d.3[k] ~ dnorm(0.00001,0.001) T(0,)\" #>  #> $dume.3 #> [1] \"d.3[c,k] ~ dnorm(0.00001,0.001) T(0,)\" #>  #> $D.3 #> [1] \"D.3[k] ~ dnorm(0.00001,0.001) T(0,)\" #>  #> $beta.3 #> [1] \"beta.3 ~ dnorm(0.00001,0.0001) T(0,)\" #>  #> $sd.mu.3 #> [1] \"sd.mu.3 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.d.3 #> [1] \"sd.d.3 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.D.3 #> [1] \"sd.D.3 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.beta.3 #> [1] \"sd.beta.3 ~ dnorm(0,0.05) T(0,)\" #>  #> $mu.4 #> [1] \"mu.4[i] ~ dnorm(0,0.0001)\" #>  #> $m.mu.4 #> [1] \"mu.4 ~ dnorm(0,0.0001)\" #>  #> $d.4 #> [1] \"d.4[k] ~ dnorm(0,0.001)\" #>  #> $dume.4 #> [1] \"d.4[c,k] ~ dnorm(0,0.001)\" #>  #> $D.4 #> [1] \"D.4[k] ~ dnorm(0,0.001)\" #>  #> $beta.4 #> [1] \"beta.4 ~ dnorm(0,0.0001)\" #>  #> $sd.mu.4 #> [1] \"sd.mu.4 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.d.4 #> [1] \"sd.d.4 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.D.4 #> [1] \"sd.D.4 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.beta.4 #> [1] \"sd.beta.4 ~ dnorm(0,0.05) T(0,)\" #>  #> $mu.z.1 #> [1] \"mu.z[i,1] ~ dnorm(0,0.0001)\" #>  #> $z.1 #> [1] \"z[1,k] ~ dnorm(0,0.0001)\" #>  #> $mu.z.2 #> [1] \"mu.z[i,2] ~ dnorm(0,0.0001) T(-d.prior[2],)\" #>  #> $z.2 #> [1] \"z[2,k] ~ dnorm(0,0.0001) T(-d.prior[2],)\" #>   default.priors(fun=titp(p.expon=TRUE)) #> 'rate' parameters are on exponential scale to ensure they take positive values on the natural scale #> $rho #> [1] \"rho ~ dunif(0,1)\" #>  #> $alpha #> [1] \"alpha[i] ~ dnorm(0,0.0001)\" #>  #> $inv.R #> [1] \"inv.R ~ dwish(omega[,], mat.size)\" #>  #> $rhoparam #> [1] \"rhoparam ~ dunif(-1,1)\" #>  #> $mu.1 #> [1] \"mu.1[i] ~ dnorm(0,0.0001)\" #>  #> $m.mu.1 #> [1] \"mu.1 ~ dnorm(0,0.0001)\" #>  #> $d.1 #> [1] \"d.1[k] ~ dnorm(0,0.001)\" #>  #> $dume.1 #> [1] \"d.1[c,k] ~ dnorm(0,0.001)\" #>  #> $D.1 #> [1] \"D.1[k] ~ dnorm(0,0.001)\" #>  #> $beta.1 #> [1] \"beta.1 ~ dnorm(0,0.0001)\" #>  #> $sd.mu.1 #> [1] \"sd.mu.1 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.d.1 #> [1] \"sd.d.1 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.D.1 #> [1] \"sd.D.1 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.beta.1 #> [1] \"sd.beta.1 ~ dnorm(0,0.05) T(0,)\" #>  #> $mu.2 #> [1] \"mu.2[i] ~ dnorm(0.00001,0.0001) T(0,)\" #>  #> $m.mu.2 #> [1] \"mu.2 ~ dnorm(0.00001,0.0001) T(0,)\" #>  #> $d.2 #> [1] \"d.2[k] ~ dnorm(0.00001,0.001) T(0,)\" #>  #> $dume.2 #> [1] \"d.2[c,k] ~ dnorm(0.00001,0.001) T(0,)\" #>  #> $D.2 #> [1] \"D.2[k] ~ dnorm(0.00001,0.001) T(0,)\" #>  #> $beta.2 #> [1] \"beta.2 ~ dnorm(0.00001,0.0001) T(0,)\" #>  #> $sd.mu.2 #> [1] \"sd.mu.2 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.d.2 #> [1] \"sd.d.2 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.D.2 #> [1] \"sd.D.2 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.beta.2 #> [1] \"sd.beta.2 ~ dnorm(0,0.05) T(0,)\" #>  #> $mu.3 #> [1] \"mu.3[i] ~ dnorm(0.00001,0.0001) T(0,)\" #>  #> $m.mu.3 #> [1] \"mu.3 ~ dnorm(0.00001,0.0001) T(0,)\" #>  #> $d.3 #> [1] \"d.3[k] ~ dnorm(0.00001,0.001) T(0,)\" #>  #> $dume.3 #> [1] \"d.3[c,k] ~ dnorm(0.00001,0.001) T(0,)\" #>  #> $D.3 #> [1] \"D.3[k] ~ dnorm(0.00001,0.001) T(0,)\" #>  #> $beta.3 #> [1] \"beta.3 ~ dnorm(0.00001,0.0001) T(0,)\" #>  #> $sd.mu.3 #> [1] \"sd.mu.3 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.d.3 #> [1] \"sd.d.3 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.D.3 #> [1] \"sd.D.3 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.beta.3 #> [1] \"sd.beta.3 ~ dnorm(0,0.05) T(0,)\" #>  #> $mu.4 #> [1] \"mu.4[i] ~ dnorm(0,0.0001)\" #>  #> $m.mu.4 #> [1] \"mu.4 ~ dnorm(0,0.0001)\" #>  #> $d.4 #> [1] \"d.4[k] ~ dnorm(0,0.001)\" #>  #> $dume.4 #> [1] \"d.4[c,k] ~ dnorm(0,0.001)\" #>  #> $D.4 #> [1] \"D.4[k] ~ dnorm(0,0.001)\" #>  #> $beta.4 #> [1] \"beta.4 ~ dnorm(0,0.0001)\" #>  #> $sd.mu.4 #> [1] \"sd.mu.4 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.d.4 #> [1] \"sd.d.4 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.D.4 #> [1] \"sd.D.4 ~ dnorm(0,0.05) T(0,)\" #>  #> $sd.beta.4 #> [1] \"sd.beta.4 ~ dnorm(0,0.05) T(0,)\" #>  #> $mu.z.1 #> [1] \"mu.z[i,1] ~ dnorm(0,0.0001)\" #>  #> $z.1 #> [1] \"z[1,k] ~ dnorm(0,0.0001)\" #>  #> $mu.z.2 #> [1] \"mu.z[i,2] ~ dnorm(0,0.0001) T(-d.prior[2],)\" #>  #> $z.2 #> [1] \"z[2,k] ~ dnorm(0,0.0001) T(-d.prior[2],)\" #>  # }"},{"path":"/reference/devplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot deviance contributions from an MBNMA model — devplot","title":"Plot deviance contributions from an MBNMA model — devplot","text":"Plot deviance contributions MBNMA model","code":""},{"path":"/reference/devplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot deviance contributions from an MBNMA model — devplot","text":"","code":"devplot(   mbnma,   dev.type = \"dev\",   plot.type = \"box\",   xaxis = \"time\",   facet = TRUE,   n.iter = round(mbnma$BUGSoutput$n.iter/4),   n.thin = mbnma$BUGSoutput$n.thin,   ... )"},{"path":"/reference/devplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot deviance contributions from an MBNMA model — devplot","text":"mbnma S3 object class \"mbnma\" generated running time-course MBNMA model dev.type Deviances plot - can either residual deviances (\"resdev\") deviances (\"dev\", default) plot.type Deviances can plotted either scatter points (\"scatter\" - using geom_point()) boxplots (\"box\", default) xaxis character object indicates whether deviance contributions plotted time (\"time\") follow-count (\"fup\") facet boolean object indicates whether facet treatment n.iter number iterations update model whilst monitoring additional parameters (necessary). Must positive integer. Default value used mbnma. n.thin thinning rate. Must positive integer. Default value used mbnma. ... Arguments sent ggplot2::ggplot()","code":""},{"path":"/reference/devplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot deviance contributions from an MBNMA model — devplot","text":"Generates plot deviance contributions returns list containing plot (object class c(\"gg\", \"ggplot\")), data.frame posterior mean deviance/residual deviance contributions observation.","code":""},{"path":"/reference/devplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot deviance contributions from an MBNMA model — devplot","text":"Deviances plotted models converged successfully. deviance contributions monitored mbnma$parameters..save additional iterations run get results . Deviance contributions calculated models multivariate likelihood (.e. account correlation observations) covariance matrix models treated unknown (rho=\"estimate\") deviance contributions correlated.","code":""},{"path":"/reference/devplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot deviance contributions from an MBNMA model — devplot","text":"","code":"# \\donttest{ # Make network alognet <- mb.network(alog_pcfb) #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data  # Run MBNMA mbnma <- mb.run(alognet, fun=tpoly(degree=2), intercept=FALSE) #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 233 #>    Unobserved stochastic nodes: 38 #>    Total graph size: 4178 #>  #> Initializing model #>   # Plot residual deviance contributions in a scatterplot devplot(mbnma) #> `dev` not monitored in mbnma$parameters.to.save. #> additional iterations will be run in order to obtain results for `dev`   # Plot deviance contributions in boxplots at each follow-up measurement # Monitor for 500 additional iterations devplot(mbnma, dev.type=\"dev\", plot.type=\"box\", xaxis=\"fup\", n.iter=500) #> `dev` not monitored in mbnma$parameters.to.save. #> additional iterations will be run in order to obtain results for `dev`  # }"},{"path":"/reference/diabetes.html","id":null,"dir":"Reference","previous_headings":"","what":"Studies comparing treatments for type 2 diabetes — diabetes","title":"Studies comparing treatments for type 2 diabetes — diabetes","text":"dataset trials reduction hsemoglobin A1c (HbA1c) patients type 2 diabetes(Ding Fu 2013) . Data reported study arm mean change baseline follow-. dataset includes 4 Randomised-Controlled Trials (RCTs), comparing 4 treatments.","code":""},{"path":"/reference/diabetes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Studies comparing treatments for type 2 diabetes — diabetes","text":"","code":"diabetes"},{"path":"/reference/diabetes.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Studies comparing treatments for type 2 diabetes — diabetes","text":"data frame long format (one row per arm study), 28 rows 7 variables: studyID Study identifiers treatment Numeric data indicating treatment participants randomised time Numeric data indicating time observation measured (given weeks) y Numeric data indicating mean change baseline HbA1c study arm se Numeric data indicating standard error mean change baseline HbA1c study arm sd Numeric data indicating standard deviation mean change baseline HbA1c study arm n Numeric data indicating number participants arm time-point","code":""},{"path":"/reference/diabetes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Studies comparing treatments for type 2 diabetes — diabetes","text":"diabetes data frame long format (one row per observation, arm study), variables studyID, treatment, time, y, se, sd, n.","code":""},{"path":"/reference/diabetes.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Studies comparing treatments for type 2 diabetes — diabetes","text":"Ding Y, Fu H (2013). “Bayesian indirect mixed treatment comparisons across longitudinal time points.” Statistics Medicine, 32, 2613-2628. doi:10.1002/sim.5688 .","code":""},{"path":"/reference/fitplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot fitted values from MBNMA model — fitplot","title":"Plot fitted values from MBNMA model — fitplot","text":"Plot fitted values MBNMA model","code":""},{"path":"/reference/fitplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot fitted values from MBNMA model — fitplot","text":"","code":"fitplot(   mbnma,   treat.labs = NULL,   disp.obs = TRUE,   n.iter = round(mbnma$BUGSoutput$n.iter/4),   n.thin = mbnma$BUGSoutput$n.thin,   ... )"},{"path":"/reference/fitplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot fitted values from MBNMA model — fitplot","text":"mbnma S3 object class \"mbnma\" generated running time-course MBNMA model treat.labs character vector treatment labels name graph panels. Can use mb.network()[[\"treatments\"]] original dataset doubt. disp.obs boolean object indicate whether raw data responses plotted points graph n.iter number total iterations per chain (including burn ;     default: 2000) n.thin thinning rate. Must positive integer.  Set     n.thin > 1 save memory computation time     n.iter large.  Default max(1, floor(n.chains *     (n.iter-n.burnin) / 1000)) thin     least 2000 simulations. ... Arguments sent ggplot2::ggplot()","code":""},{"path":"/reference/fitplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot fitted values from MBNMA model — fitplot","text":"Generates plot fitted values MBNMA model returns list containing plot (object class c(\"gg\", \"ggplot\")), data.frame posterior mean fitted values observation.","code":""},{"path":"/reference/fitplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot fitted values from MBNMA model — fitplot","text":"Fitted values plotted models converged successfully. fitted values (theta) monitored mbnma$parameters..save additional iterations run get results .","code":""},{"path":"/reference/fitplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot fitted values from MBNMA model — fitplot","text":"","code":"# \\donttest{ # Make network painnet <- mb.network(osteopain) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Run MBNMA mbnma <- mb.run(painnet,   fun=temax(pool.emax=\"rel\", method.emax=\"common\",     pool.et50=\"abs\", method.et50=\"random\")) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 194 #>    Total graph size: 8210 #>  #> Initializing model #>   # Plot fitted values from the model # Monitor fitted values for 500 additional iterations fitplot(mbnma, n.iter=500) #> `theta` not monitored in mbnma$parameters.to.save. #> additional iterations will be run in order to obtain results  # }"},{"path":"/reference/gen.parameters.to.save.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatically generate parameters to save for a dose-response MBNMA model — gen.parameters.to.save","title":"Automatically generate parameters to save for a dose-response MBNMA model — gen.parameters.to.save","text":"Automatically generate parameters save dose-response MBNMA model","code":""},{"path":"/reference/gen.parameters.to.save.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatically generate parameters to save for a dose-response MBNMA model — gen.parameters.to.save","text":"","code":"gen.parameters.to.save(fun, model)"},{"path":"/reference/gen.parameters.to.save.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatically generate parameters to save for a dose-response MBNMA model — gen.parameters.to.save","text":"fun object class \"timefun\" generated (see Details) using tloglin(), tpoly(), titp(), temax(), tfpoly(), tspline() tuser() model JAGS model written character object","code":""},{"path":"/reference/genmaxcols.html","id":null,"dir":"Reference","previous_headings":"","what":"Get large vector of distinct colours using Rcolorbrewer — genmaxcols","title":"Get large vector of distinct colours using Rcolorbrewer — genmaxcols","text":"Get large vector distinct colours using Rcolorbrewer","code":""},{"path":"/reference/genmaxcols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get large vector of distinct colours using Rcolorbrewer — genmaxcols","text":"","code":"genmaxcols()"},{"path":"/reference/genspline.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates spline basis matrices for fitting to time-course function — genspline","title":"Generates spline basis matrices for fitting to time-course function — genspline","text":"Generates spline basis matrices fitting time-course function","code":""},{"path":"/reference/genspline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates spline basis matrices for fitting to time-course function — genspline","text":"","code":"genspline(   x,   spline = \"bs\",   knots = 1,   degree = 1,   max.time = max(x),   boundaries = NULL )"},{"path":"/reference/genspline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates spline basis matrices for fitting to time-course function — genspline","text":"x numeric vector indicating time points available dataset spline Indicates type spline function. Can either piecewise linear spline (\"ls\"), natural cubic spline (\"ns\") B-spline (\"bs\"). knots number/location knots. single integer given indicates number knots (equally spaced across range time-points). numeric vector given indicates quantiles knots proportion maximum study follow-dataset. example, maximum follow-time dataset 10 months, knots=c(0.1,0.5) indicate knots fitted 1 5 months follow-. degree positive integer giving degree polynomial spline function composed (e.g. degree=3 represents cubic spline). max.time number indicating maximum time calculate spline function. boundaries positive numeric vector length 2 represents time-points anchor B-spline natural cubic spline basis matrix. allows data extend beyond boundary knots, basis parameters depend x. default (boundaries=NULL)range x.","code":""},{"path":"/reference/genspline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generates spline basis matrices for fitting to time-course function — genspline","text":"spline basis matrix number rows equal length(x) number columns equal number coefficients spline.","code":""},{"path":"/reference/genspline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates spline basis matrices for fitting to time-course function — genspline","text":"","code":"x <- 0:100  genspline(x) #>        1    2 #> 0   0.00 0.00 #> 1   0.02 0.00 #> 2   0.04 0.00 #> 3   0.06 0.00 #> 4   0.08 0.00 #> 5   0.10 0.00 #> 6   0.12 0.00 #> 7   0.14 0.00 #> 8   0.16 0.00 #> 9   0.18 0.00 #> 10  0.20 0.00 #> 11  0.22 0.00 #> 12  0.24 0.00 #> 13  0.26 0.00 #> 14  0.28 0.00 #> 15  0.30 0.00 #> 16  0.32 0.00 #> 17  0.34 0.00 #> 18  0.36 0.00 #> 19  0.38 0.00 #> 20  0.40 0.00 #> 21  0.42 0.00 #> 22  0.44 0.00 #> 23  0.46 0.00 #> 24  0.48 0.00 #> 25  0.50 0.00 #> 26  0.52 0.00 #> 27  0.54 0.00 #> 28  0.56 0.00 #> 29  0.58 0.00 #> 30  0.60 0.00 #> 31  0.62 0.00 #> 32  0.64 0.00 #> 33  0.66 0.00 #> 34  0.68 0.00 #> 35  0.70 0.00 #> 36  0.72 0.00 #> 37  0.74 0.00 #> 38  0.76 0.00 #> 39  0.78 0.00 #> 40  0.80 0.00 #> 41  0.82 0.00 #> 42  0.84 0.00 #> 43  0.86 0.00 #> 44  0.88 0.00 #> 45  0.90 0.00 #> 46  0.92 0.00 #> 47  0.94 0.00 #> 48  0.96 0.00 #> 49  0.98 0.00 #> 50  1.00 0.00 #> 51  0.98 0.02 #> 52  0.96 0.04 #> 53  0.94 0.06 #> 54  0.92 0.08 #> 55  0.90 0.10 #> 56  0.88 0.12 #> 57  0.86 0.14 #> 58  0.84 0.16 #> 59  0.82 0.18 #> 60  0.80 0.20 #> 61  0.78 0.22 #> 62  0.76 0.24 #> 63  0.74 0.26 #> 64  0.72 0.28 #> 65  0.70 0.30 #> 66  0.68 0.32 #> 67  0.66 0.34 #> 68  0.64 0.36 #> 69  0.62 0.38 #> 70  0.60 0.40 #> 71  0.58 0.42 #> 72  0.56 0.44 #> 73  0.54 0.46 #> 74  0.52 0.48 #> 75  0.50 0.50 #> 76  0.48 0.52 #> 77  0.46 0.54 #> 78  0.44 0.56 #> 79  0.42 0.58 #> 80  0.40 0.60 #> 81  0.38 0.62 #> 82  0.36 0.64 #> 83  0.34 0.66 #> 84  0.32 0.68 #> 85  0.30 0.70 #> 86  0.28 0.72 #> 87  0.26 0.74 #> 88  0.24 0.76 #> 89  0.22 0.78 #> 90  0.20 0.80 #> 91  0.18 0.82 #> 92  0.16 0.84 #> 93  0.14 0.86 #> 94  0.12 0.88 #> 95  0.10 0.90 #> 96  0.08 0.92 #> 97  0.06 0.94 #> 98  0.04 0.96 #> 99  0.02 0.98 #> 100 0.00 1.00  # Generate a quadratic B-spline with 1 equally spaced internal knot genspline(x, spline=\"bs\", knots=2, degree=2) #>           1       2       3      4 #> 0   0.00000 0.00000 0.00000 0.0000 #> 1   0.05865 0.00045 0.00000 0.0000 #> 2   0.11460 0.00180 0.00000 0.0000 #> 3   0.16785 0.00405 0.00000 0.0000 #> 4   0.21840 0.00720 0.00000 0.0000 #> 5   0.26625 0.01125 0.00000 0.0000 #> 6   0.31140 0.01620 0.00000 0.0000 #> 7   0.35385 0.02205 0.00000 0.0000 #> 8   0.39360 0.02880 0.00000 0.0000 #> 9   0.43065 0.03645 0.00000 0.0000 #> 10  0.46500 0.04500 0.00000 0.0000 #> 11  0.49665 0.05445 0.00000 0.0000 #> 12  0.52560 0.06480 0.00000 0.0000 #> 13  0.55185 0.07605 0.00000 0.0000 #> 14  0.57540 0.08820 0.00000 0.0000 #> 15  0.59625 0.10125 0.00000 0.0000 #> 16  0.61440 0.11520 0.00000 0.0000 #> 17  0.62985 0.13005 0.00000 0.0000 #> 18  0.64260 0.14580 0.00000 0.0000 #> 19  0.65265 0.16245 0.00000 0.0000 #> 20  0.66000 0.18000 0.00000 0.0000 #> 21  0.66465 0.19845 0.00000 0.0000 #> 22  0.66660 0.21780 0.00000 0.0000 #> 23  0.66585 0.23805 0.00000 0.0000 #> 24  0.66240 0.25920 0.00000 0.0000 #> 25  0.65625 0.28125 0.00000 0.0000 #> 26  0.64740 0.30420 0.00000 0.0000 #> 27  0.63585 0.32805 0.00000 0.0000 #> 28  0.62160 0.35280 0.00000 0.0000 #> 29  0.60465 0.37845 0.00000 0.0000 #> 30  0.58500 0.40500 0.00000 0.0000 #> 31  0.56265 0.43245 0.00000 0.0000 #> 32  0.53760 0.46080 0.00000 0.0000 #> 33  0.50985 0.49005 0.00000 0.0000 #> 34  0.48020 0.51960 0.00020 0.0000 #> 35  0.45125 0.54750 0.00125 0.0000 #> 36  0.42320 0.57360 0.00320 0.0000 #> 37  0.39605 0.59790 0.00605 0.0000 #> 38  0.36980 0.62040 0.00980 0.0000 #> 39  0.34445 0.64110 0.01445 0.0000 #> 40  0.32000 0.66000 0.02000 0.0000 #> 41  0.29645 0.67710 0.02645 0.0000 #> 42  0.27380 0.69240 0.03380 0.0000 #> 43  0.25205 0.70590 0.04205 0.0000 #> 44  0.23120 0.71760 0.05120 0.0000 #> 45  0.21125 0.72750 0.06125 0.0000 #> 46  0.19220 0.73560 0.07220 0.0000 #> 47  0.17405 0.74190 0.08405 0.0000 #> 48  0.15680 0.74640 0.09680 0.0000 #> 49  0.14045 0.74910 0.11045 0.0000 #> 50  0.12500 0.75000 0.12500 0.0000 #> 51  0.11045 0.74910 0.14045 0.0000 #> 52  0.09680 0.74640 0.15680 0.0000 #> 53  0.08405 0.74190 0.17405 0.0000 #> 54  0.07220 0.73560 0.19220 0.0000 #> 55  0.06125 0.72750 0.21125 0.0000 #> 56  0.05120 0.71760 0.23120 0.0000 #> 57  0.04205 0.70590 0.25205 0.0000 #> 58  0.03380 0.69240 0.27380 0.0000 #> 59  0.02645 0.67710 0.29645 0.0000 #> 60  0.02000 0.66000 0.32000 0.0000 #> 61  0.01445 0.64110 0.34445 0.0000 #> 62  0.00980 0.62040 0.36980 0.0000 #> 63  0.00605 0.59790 0.39605 0.0000 #> 64  0.00320 0.57360 0.42320 0.0000 #> 65  0.00125 0.54750 0.45125 0.0000 #> 66  0.00020 0.51960 0.48020 0.0000 #> 67  0.00000 0.49005 0.50985 0.0001 #> 68  0.00000 0.46080 0.53760 0.0016 #> 69  0.00000 0.43245 0.56265 0.0049 #> 70  0.00000 0.40500 0.58500 0.0100 #> 71  0.00000 0.37845 0.60465 0.0169 #> 72  0.00000 0.35280 0.62160 0.0256 #> 73  0.00000 0.32805 0.63585 0.0361 #> 74  0.00000 0.30420 0.64740 0.0484 #> 75  0.00000 0.28125 0.65625 0.0625 #> 76  0.00000 0.25920 0.66240 0.0784 #> 77  0.00000 0.23805 0.66585 0.0961 #> 78  0.00000 0.21780 0.66660 0.1156 #> 79  0.00000 0.19845 0.66465 0.1369 #> 80  0.00000 0.18000 0.66000 0.1600 #> 81  0.00000 0.16245 0.65265 0.1849 #> 82  0.00000 0.14580 0.64260 0.2116 #> 83  0.00000 0.13005 0.62985 0.2401 #> 84  0.00000 0.11520 0.61440 0.2704 #> 85  0.00000 0.10125 0.59625 0.3025 #> 86  0.00000 0.08820 0.57540 0.3364 #> 87  0.00000 0.07605 0.55185 0.3721 #> 88  0.00000 0.06480 0.52560 0.4096 #> 89  0.00000 0.05445 0.49665 0.4489 #> 90  0.00000 0.04500 0.46500 0.4900 #> 91  0.00000 0.03645 0.43065 0.5329 #> 92  0.00000 0.02880 0.39360 0.5776 #> 93  0.00000 0.02205 0.35385 0.6241 #> 94  0.00000 0.01620 0.31140 0.6724 #> 95  0.00000 0.01125 0.26625 0.7225 #> 96  0.00000 0.00720 0.21840 0.7744 #> 97  0.00000 0.00405 0.16785 0.8281 #> 98  0.00000 0.00180 0.11460 0.8836 #> 99  0.00000 0.00045 0.05865 0.9409 #> 100 0.00000 0.00000 0.00000 1.0000  # Generate a natural spline with 2 knots at selected quantiles genspline(x, spline=\"ns\", knots=c(0.1, 0.5)) #>                1          2           3 #> 0    0.000000000 0.00000000  0.00000000 #> 1   -0.014156667 0.03969467 -0.02551800 #> 2   -0.028112452 0.07916287 -0.05089041 #> 3   -0.041666470 0.11817812 -0.07597165 #> 4   -0.054617838 0.15651395 -0.10061611 #> 5   -0.066765674 0.19394389 -0.12467821 #> 6   -0.077909094 0.23024146 -0.14801237 #> 7   -0.087847215 0.26518020 -0.17047299 #> 8   -0.096379153 0.29853363 -0.19191448 #> 9   -0.103304027 0.33007527 -0.21219125 #> 10  -0.108420951 0.35957866 -0.23115771 #> 11  -0.111576347 0.38686644 -0.24869787 #> 12  -0.112805841 0.41195769 -0.26481407 #> 13  -0.112192366 0.43492063 -0.27953826 #> 14  -0.109818852 0.45582345 -0.29290238 #> 15  -0.105768230 0.47473438 -0.30493837 #> 16  -0.100123432 0.49172161 -0.31567818 #> 17  -0.092967387 0.50685335 -0.32515374 #> 18  -0.084383028 0.52019781 -0.33339701 #> 19  -0.074453285 0.53182320 -0.34043991 #> 20  -0.063261088 0.54179771 -0.34631440 #> 21  -0.050889370 0.55018957 -0.35105242 #> 22  -0.037421061 0.55706697 -0.35468591 #> 23  -0.022939091 0.56249812 -0.35724681 #> 24  -0.007526393 0.56655123 -0.35876706 #> 25   0.008734103 0.56929451 -0.35927861 #> 26   0.025759467 0.57079616 -0.35881340 #> 27   0.043466767 0.57112439 -0.35740338 #> 28   0.061773071 0.57034740 -0.35508047 #> 29   0.080595450 0.56853341 -0.35187663 #> 30   0.099850972 0.56575061 -0.34782381 #> 31   0.119456707 0.56206722 -0.34295393 #> 32   0.139329723 0.55755144 -0.33729894 #> 33   0.159387088 0.55227149 -0.33089080 #> 34   0.179545874 0.54629555 -0.32376143 #> 35   0.199723147 0.53969185 -0.31594278 #> 36   0.219835978 0.53252859 -0.30746679 #> 37   0.239801435 0.52487398 -0.29836542 #> 38   0.259536588 0.51679622 -0.28867059 #> 39   0.278958505 0.50836352 -0.27841425 #> 40   0.297984256 0.49964408 -0.26762834 #> 41   0.316530909 0.49070612 -0.25634481 #> 42   0.334515533 0.48161784 -0.24459560 #> 43   0.351855199 0.47244744 -0.23241264 #> 44   0.368466973 0.46326314 -0.21982789 #> 45   0.384267926 0.45413314 -0.20687329 #> 46   0.399175127 0.44512564 -0.19358077 #> 47   0.413105645 0.43630886 -0.17998228 #> 48   0.425976548 0.42775100 -0.16610977 #> 49   0.437704905 0.41952026 -0.15199517 #> 50   0.448207787 0.41168486 -0.13767043 #> 51   0.457420444 0.40430009 -0.12316276 #> 52   0.465350863 0.39736958 -0.10848045 #> 53   0.472025210 0.39088408 -0.09362707 #> 54   0.477469654 0.38483430 -0.07860618 #> 55   0.481710364 0.37921098 -0.06342134 #> 56   0.484773507 0.37400485 -0.04807613 #> 57   0.486685252 0.36920663 -0.03257410 #> 58   0.487471767 0.36480705 -0.01691882 #> 59   0.487159219 0.36079685 -0.00111385 #> 60   0.485773778 0.35716676  0.01483724 #> 61   0.483341610 0.35390749  0.03093090 #> 62   0.479888885 0.35100979  0.04716355 #> 63   0.475441771 0.34846438  0.06353163 #> 64   0.470026435 0.34626198  0.08003158 #> 65   0.463669046 0.34439334  0.09665984 #> 66   0.456395772 0.34284917  0.11341283 #> 67   0.448232780 0.34162021  0.13028700 #> 68   0.439206240 0.34069719  0.14727879 #> 69   0.429342320 0.34007084  0.16438462 #> 70   0.418667187 0.33973188  0.18160094 #> 71   0.407207009 0.33967104  0.19892417 #> 72   0.394987955 0.33987906  0.21635076 #> 73   0.382036194 0.34034666  0.23387715 #> 74   0.368377892 0.34106457  0.25149976 #> 75   0.354039218 0.34202352  0.26921504 #> 76   0.339046341 0.34321424  0.28701941 #> 77   0.323425429 0.34462747  0.30490933 #> 78   0.307202649 0.34625392  0.32288121 #> 79   0.290404170 0.34808433  0.34093151 #> 80   0.273056159 0.35010942  0.35905664 #> 81   0.255184786 0.35231993  0.37725306 #> 82   0.236816218 0.35470659  0.39551719 #> 83   0.217976624 0.35726012  0.41384548 #> 84   0.198692171 0.35997126  0.43223435 #> 85   0.178989027 0.36283072  0.45068025 #> 86   0.158893362 0.36582925  0.46917961 #> 87   0.138431342 0.36895757  0.48772886 #> 88   0.117629137 0.37220642  0.50632445 #> 89   0.096512914 0.37556651  0.52496280 #> 90   0.075108841 0.37902858  0.54364036 #> 91   0.053443087 0.38258336  0.56235356 #> 92   0.031541819 0.38622157  0.58109883 #> 93   0.009431207 0.38993395  0.59987262 #> 94  -0.012862583 0.39371123  0.61867135 #> 95  -0.035313382 0.39754414  0.63749147 #> 96  -0.057895021 0.40142339  0.65632941 #> 97  -0.080581333 0.40533973  0.67518160 #> 98  -0.103346149 0.40928388  0.69404449 #> 99  -0.126163302 0.41324658  0.71291450 #> 100 -0.149006623 0.41721854  0.73178808  # Generate a piecewise linear spline with 3 equally spaced knots genspline(x, spline=\"ls\", knots=3) #>      1  2  3  4 #> 0    0  0  0  0 #> 1    1  0  0  0 #> 2    2  0  0  0 #> 3    3  0  0  0 #> 4    4  0  0  0 #> 5    5  0  0  0 #> 6    6  0  0  0 #> 7    7  0  0  0 #> 8    8  0  0  0 #> 9    9  0  0  0 #> 10  10  0  0  0 #> 11  11  0  0  0 #> 12  12  0  0  0 #> 13  13  0  0  0 #> 14  14  0  0  0 #> 15  15  0  0  0 #> 16  16  0  0  0 #> 17  17  0  0  0 #> 18  18  0  0  0 #> 19  19  0  0  0 #> 20  20  0  0  0 #> 21  21  0  0  0 #> 22  22  0  0  0 #> 23  23  0  0  0 #> 24  24  0  0  0 #> 25  25  0  0  0 #> 26  25  1  0  0 #> 27  25  2  0  0 #> 28  25  3  0  0 #> 29  25  4  0  0 #> 30  25  5  0  0 #> 31  25  6  0  0 #> 32  25  7  0  0 #> 33  25  8  0  0 #> 34  25  9  0  0 #> 35  25 10  0  0 #> 36  25 11  0  0 #> 37  25 12  0  0 #> 38  25 13  0  0 #> 39  25 14  0  0 #> 40  25 15  0  0 #> 41  25 16  0  0 #> 42  25 17  0  0 #> 43  25 18  0  0 #> 44  25 19  0  0 #> 45  25 20  0  0 #> 46  25 21  0  0 #> 47  25 22  0  0 #> 48  25 23  0  0 #> 49  25 24  0  0 #> 50  25 25  0  0 #> 51  25 25  1  0 #> 52  25 25  2  0 #> 53  25 25  3  0 #> 54  25 25  4  0 #> 55  25 25  5  0 #> 56  25 25  6  0 #> 57  25 25  7  0 #> 58  25 25  8  0 #> 59  25 25  9  0 #> 60  25 25 10  0 #> 61  25 25 11  0 #> 62  25 25 12  0 #> 63  25 25 13  0 #> 64  25 25 14  0 #> 65  25 25 15  0 #> 66  25 25 16  0 #> 67  25 25 17  0 #> 68  25 25 18  0 #> 69  25 25 19  0 #> 70  25 25 20  0 #> 71  25 25 21  0 #> 72  25 25 22  0 #> 73  25 25 23  0 #> 74  25 25 24  0 #> 75  25 25 25  0 #> 76  25 25 25  1 #> 77  25 25 25  2 #> 78  25 25 25  3 #> 79  25 25 25  4 #> 80  25 25 25  5 #> 81  25 25 25  6 #> 82  25 25 25  7 #> 83  25 25 25  8 #> 84  25 25 25  9 #> 85  25 25 25 10 #> 86  25 25 25 11 #> 87  25 25 25 12 #> 88  25 25 25 13 #> 89  25 25 25 14 #> 90  25 25 25 15 #> 91  25 25 25 16 #> 92  25 25 25 17 #> 93  25 25 25 18 #> 94  25 25 25 19 #> 95  25 25 25 20 #> 96  25 25 25 21 #> 97  25 25 25 22 #> 98  25 25 25 23 #> 99  25 25 25 24 #> 100 25 25 25 25"},{"path":"/reference/get.closest.time.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a dataset with a single time point from each study closest to specified time — get.closest.time","title":"Create a dataset with a single time point from each study closest to specified time — get.closest.time","text":"Takes closest time point arm study specified time (t) within mb.network object. Useful network plots exploring standard NMA.","code":""},{"path":"/reference/get.closest.time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a dataset with a single time point from each study closest to specified time — get.closest.time","text":"","code":"get.closest.time(network, t = stats::median(network$data.ab$time))"},{"path":"/reference/get.closest.time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a dataset with a single time point from each study closest to specified time — get.closest.time","text":"network object class \"mb.network\". t time point ","code":""},{"path":"/reference/get.closest.time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a dataset with a single time point from each study closest to specified time — get.closest.time","text":"data frame long format responses closest time point t arm study.","code":""},{"path":"/reference/get.closest.time.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a dataset with a single time point from each study closest to specified time — get.closest.time","text":"","code":"# Using the alogliptin dataset network <- mb.network(alog_pcfb) #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data  # Take a single follow-up time from each study... # ...closest to 7 get.closest.time(network, t=7) #> # A tibble: 46 × 13 #> # Groups:   studyID, arm [46] #>    studyID  time treatment  narm   arm     y     se     n clinical…¹ agent  dose #>      <dbl> <dbl>     <dbl> <int> <int> <dbl>  <dbl> <dbl> <chr>      <chr> <dbl> #>  1       1     2         1     5     1  0    0.0216    75 NCT012634… alog…  0    #>  2       1     2         2     5     2 -0.16 0.0172    79 NCT012634… alog…  6.25 #>  3       1     2         3     5     3 -0.17 0.0212    84 NCT012634… alog… 12.5  #>  4       1     2         4     5     4 -0.16 0.0210    79 NCT012634… alog… 25    #>  5       1     2         5     5     5 -0.15 0.0203    79 NCT012634… alog… 50    #>  6       2     4         1     3     1 -0.11 0.052     63 NCT002864… alog…  0    #>  7       2     4         3     3     2 -0.37 0.035    131 NCT002864… alog… 12.5  #>  8       2     4         4     3     3 -0.45 0.036    128 NCT002864… alog… 25    #>  9       3    12         2     4     1 -0.55 0.0726    93 NCT012634… alog…  6.25 #> 10       3    12         3     4     2 -0.7  0.0548    97 NCT012634… alog… 12.5  #> # … with 36 more rows, 2 more variables: fupcount <int>, fups <int>, and #> #   abbreviated variable name ¹​clinicaltrialGov_ID  # ...closest to 20 get.closest.time(network, t=7) #> # A tibble: 46 × 13 #> # Groups:   studyID, arm [46] #>    studyID  time treatment  narm   arm     y     se     n clinical…¹ agent  dose #>      <dbl> <dbl>     <dbl> <int> <int> <dbl>  <dbl> <dbl> <chr>      <chr> <dbl> #>  1       1     2         1     5     1  0    0.0216    75 NCT012634… alog…  0    #>  2       1     2         2     5     2 -0.16 0.0172    79 NCT012634… alog…  6.25 #>  3       1     2         3     5     3 -0.17 0.0212    84 NCT012634… alog… 12.5  #>  4       1     2         4     5     4 -0.16 0.0210    79 NCT012634… alog… 25    #>  5       1     2         5     5     5 -0.15 0.0203    79 NCT012634… alog… 50    #>  6       2     4         1     3     1 -0.11 0.052     63 NCT002864… alog…  0    #>  7       2     4         3     3     2 -0.37 0.035    131 NCT002864… alog… 12.5  #>  8       2     4         4     3     3 -0.45 0.036    128 NCT002864… alog… 25    #>  9       3    12         2     4     1 -0.55 0.0726    93 NCT012634… alog…  6.25 #> 10       3    12         3     4     2 -0.7  0.0548    97 NCT012634… alog… 12.5  #> # … with 36 more rows, 2 more variables: fupcount <int>, fups <int>, and #> #   abbreviated variable name ¹​clinicaltrialGov_ID  # ...closest to the median follow-up across all studies get.closest.time(network, t=26) #> # A tibble: 46 × 13 #> # Groups:   studyID, arm [46] #>    studyID  time treatment  narm   arm     y     se     n clinical…¹ agent  dose #>      <dbl> <dbl>     <dbl> <int> <int> <dbl>  <dbl> <dbl> <chr>      <chr> <dbl> #>  1       1     2         1     5     1  0    0.0216    75 NCT012634… alog…  0    #>  2       1     2         2     5     2 -0.16 0.0172    79 NCT012634… alog…  6.25 #>  3       1     2         3     5     3 -0.17 0.0212    84 NCT012634… alog… 12.5  #>  4       1     2         4     5     4 -0.16 0.0210    79 NCT012634… alog… 25    #>  5       1     2         5     5     5 -0.15 0.0203    79 NCT012634… alog… 50    #>  6       2     4         1     3     1 -0.11 0.052     63 NCT002864… alog…  0    #>  7       2     4         3     3     2 -0.37 0.035    131 NCT002864… alog… 12.5  #>  8       2     4         4     3     3 -0.45 0.036    128 NCT002864… alog… 25    #>  9       3    12         2     4     1 -0.55 0.0726    93 NCT012634… alog…  6.25 #> 10       3    12         3     4     2 -0.7  0.0548    97 NCT012634… alog… 12.5  #> # … with 36 more rows, 2 more variables: fupcount <int>, fups <int>, and #> #   abbreviated variable name ¹​clinicaltrialGov_ID"},{"path":"/reference/get.earliest.time.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a dataset with the earliest time point only — get.earliest.time","title":"Create a dataset with the earliest time point only — get.earliest.time","text":"Takes earliest time point arm study within mb.network object. Useful network plots.","code":""},{"path":"/reference/get.earliest.time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a dataset with the earliest time point only — get.earliest.time","text":"","code":"get.earliest.time(network)"},{"path":"/reference/get.earliest.time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a dataset with the earliest time point only — get.earliest.time","text":"network object class \"mb.network\".","code":""},{"path":"/reference/get.earliest.time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a dataset with the earliest time point only — get.earliest.time","text":"data frame long format responses earliest time point arm study.","code":""},{"path":"/reference/get.earliest.time.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a dataset with the earliest time point only — get.earliest.time","text":"","code":"# Using the alogliptin dataset network <- mb.network(alog_pcfb) #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data  # Generate a data frame with only the earliest time point included in each study get.earliest.time(network) #>    studyID time treatment narm arm     y         se   n clinicaltrialGov_ID #> 1        1    2         1    5   1  0.00 0.02159290  75         NCT01263470 #> 2        1    2         2    5   2 -0.16 0.01721384  79         NCT01263470 #> 3        1    2         3    5   3 -0.17 0.02116714  84         NCT01263470 #> 4        1    2         4    5   4 -0.16 0.02103914  79         NCT01263470 #> 5        1    2         5    5   5 -0.15 0.02025158  79         NCT01263470 #> 6        2    4         1    3   1 -0.11 0.05200000  63         NCT00286455 #> 7        2    4         3    3   2 -0.37 0.03500000 131         NCT00286455 #> 8        2    4         4    3   3 -0.45 0.03600000 128         NCT00286455 #> 9        3   12         2    4   1 -0.55 0.07258662  93         NCT01263496 #> 10       3   12         3    4   2 -0.70 0.05482869  97         NCT01263496 #> 11       3   12         4    4   3 -0.74 0.05363391  94         NCT01263496 #> 12       3   12         5    4   4 -0.86 0.05157106  94         NCT01263496 #> 13       4    4         1    3   1 -0.14 0.04200000  90         NCT00286494 #> 14       4    4         3    3   2 -0.40 0.02900000 182         NCT00286494 #> 15       4    4         4    3   3 -0.45 0.03000000 176         NCT00286494 #> 16       5    4         1    3   1 -0.18 0.04200000  89         NCT00286468 #> 17       5    4         3    3   2 -0.40 0.02800000 191         NCT00286468 #> 18       5    4         4    3   3 -0.46 0.02900000 186         NCT00286468 #> 19       6    4         1    3   1 -0.10 0.04400000  91         NCT00286442 #> 20       6    4         3    3   2 -0.36 0.03100000 188         NCT00286442 #> 21       6    4         4    3   3 -0.40 0.03100000 187         NCT00286442 #> 22       7    2         1    3   1 -0.04 0.01734459 115         NCT01318070 #> 23       7    2         3    3   2 -0.22 0.01430194 110         NCT01318070 #> 24       7    2         4    3   3 -0.22 0.01461703 111         NCT01318070 #> 25       8    4         1    3   1 -0.26 0.04500000 114         NCT00286429 #> 26       8    4         3    3   2 -0.47 0.04500000 116         NCT00286429 #> 27       8    4         4    3   3 -0.58 0.04500000 116         NCT00286429 #> 28       9    2         1    3   1  0.08 0.02946134 103         NCT01318083 #> 29       9    2         3    3   2 -0.12 0.02392617 104         NCT01318083 #> 30       9    2         4    3   3 -0.13 0.02019996 104         NCT01318083 #> 31      10    2         1    3   1 -0.01 0.02092458  74         NCT01263483 #> 32      10    2         3    3   2 -0.19 0.01709147  76         NCT01263483 #> 33      10    2         4    3   3 -0.21 0.01968904  79         NCT01263483 #> 34      11    6         1    6   1  0.02 0.09700000  41         NCT00755846 #> 35      11    6         2    6   2 -0.12 0.09500000  42         NCT00755846 #> 36      11    6         3    6   3 -0.35 0.09600000  42         NCT00755846 #> 37      11    6         4    6   4 -0.36 0.09300000  45         NCT00755846 #> 38      11    6         5    6   5 -0.32 0.09700000  43         NCT00755846 #> 39      11    6         6    6   6 -0.31 0.09400000  44         NCT00755846 #> 40      12    8         3    2   1 -0.68 0.02888231 165         NCT01318122 #> 41      12    8         4    2   2 -0.73 0.03240606 164         NCT01318122 #> 42      13    8         3    2   1 -0.69 0.04630668 107         NCT01263509 #> 43      13    8         4    2   2 -0.79 0.04170000 100         NCT01263509 #> 44      14    2         1    3   1  0.06 0.01970000 100         NCT01318109 #> 45      14    2         3    3   2 -0.13 0.02043441  92         NCT01318109 #> 46      14    2         4    3   3 -0.13 0.01530931  96         NCT01318109 #>         agent   dose fupcount fups #> 1  alogliptin   0.00        1    4 #> 2  alogliptin   6.25        1    4 #> 3  alogliptin  12.50        1    4 #> 4  alogliptin  25.00        1    4 #> 5  alogliptin  50.00        1    4 #> 6  alogliptin   0.00        1    6 #> 7  alogliptin  12.50        1    6 #> 8  alogliptin  25.00        1    6 #> 9  alogliptin   6.25        1    8 #> 10 alogliptin  12.50        1    8 #> 11 alogliptin  25.00        1    8 #> 12 alogliptin  50.00        1    8 #> 13 alogliptin   0.00        1    6 #> 14 alogliptin  12.50        1    6 #> 15 alogliptin  25.00        1    6 #> 16 alogliptin   0.00        1    5 #> 17 alogliptin  12.50        1    5 #> 18 alogliptin  25.00        1    5 #> 19 alogliptin   0.00        1    6 #> 20 alogliptin  12.50        1    6 #> 21 alogliptin  25.00        1    6 #> 22 alogliptin   0.00        1    4 #> 23 alogliptin  12.50        1    4 #> 24 alogliptin  25.00        1    4 #> 25 alogliptin   0.00        1    6 #> 26 alogliptin  12.50        1    6 #> 27 alogliptin  25.00        1    6 #> 28 alogliptin   0.00        1    4 #> 29 alogliptin  12.50        1    4 #> 30 alogliptin  25.00        1    4 #> 31 alogliptin   0.00        1    4 #> 32 alogliptin  12.50        1    4 #> 33 alogliptin  25.00        1    4 #> 34 alogliptin   0.00        1    2 #> 35 alogliptin   6.25        1    2 #> 36 alogliptin  12.50        1    2 #> 37 alogliptin  25.00        1    2 #> 38 alogliptin  50.00        1    2 #> 39 alogliptin 100.00        1    2 #> 40 alogliptin  12.50        1    8 #> 41 alogliptin  25.00        1    8 #> 42 alogliptin  12.50        1    9 #> 43 alogliptin  25.00        1    9 #> 44 alogliptin   0.00        1    4 #> 45 alogliptin  12.50        1    4 #> 46 alogliptin  25.00        1    4"},{"path":"/reference/get.latest.time.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a dataset with the latest time point only — get.latest.time","title":"Create a dataset with the latest time point only — get.latest.time","text":"Takes latest time point arm study within mb.network object. Useful network plots.","code":""},{"path":"/reference/get.latest.time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a dataset with the latest time point only — get.latest.time","text":"","code":"get.latest.time(network)"},{"path":"/reference/get.latest.time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a dataset with the latest time point only — get.latest.time","text":"network object class \"mb.network\".","code":""},{"path":"/reference/get.latest.time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a dataset with the latest time point only — get.latest.time","text":"data frame long format responses latest time point arm study.","code":""},{"path":"/reference/get.latest.time.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a dataset with the latest time point only — get.latest.time","text":"","code":"# Using the alogliptin dataset network <- mb.network(alog_pcfb) #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data  # Generate a data frame with only the latest time point included in each study get.latest.time(network) #>    studyID time treatment narm arm     y         se   n clinicaltrialGov_ID #> 1        1   12         1    5   1  0.06 0.05311623  75         NCT01263470 #> 2        1   12         2    5   2 -0.51 0.07650598  79         NCT01263470 #> 3        1   12         3    5   3 -0.70 0.06219210  84         NCT01263470 #> 4        1   12         4    5   4 -0.76 0.06187984  79         NCT01263470 #> 5        1   12         5    5   5 -0.82 0.05287913  79         NCT01263470 #> 6        2   26         1    3   1 -0.02 0.09400000  63         NCT00286455 #> 7        2   26         3    3   2 -0.56 0.06500000 131         NCT00286455 #> 8        2   26         4    3   3 -0.59 0.06600000 128         NCT00286455 #> 9        3   40         2    4   1 -0.33 0.07622222  81         NCT01263496 #> 10       3   40         3    4   2 -0.48 0.09923275  79         NCT01263496 #> 11       3   40         4    4   3 -0.66 0.07808110  79         NCT01263496 #> 12       3   40         5    4   4 -0.77 0.08346834  84         NCT01263496 #> 13       4   26         1    3   1 -0.19 0.08100000  95         NCT00286494 #> 14       4   26         3    3   2 -0.66 0.05600000 196         NCT00286494 #> 15       4   26         4    3   3 -0.80 0.05600000 195         NCT00286494 #> 16       5   26         1    3   1  0.01 0.08400000  97         NCT00286468 #> 17       5   26         3    3   2 -0.38 0.05800000 201         NCT00286468 #> 18       5   26         4    3   3 -0.52 0.05800000 197         NCT00286468 #> 19       6   26         1    3   1 -0.10 0.07600000 103         NCT00286442 #> 20       6   26         3    3   2 -0.61 0.05300000 210         NCT00286442 #> 21       6   26         4    3   3 -0.59 0.05400000 203         NCT00286442 #> 22       7   12         1    3   1 -0.19 0.05128776 115         NCT01318070 #> 23       7   12         3    3   2 -0.91 0.04176295 111         NCT01318070 #> 24       7   12         4    3   3 -0.97 0.04891748 113         NCT01318070 #> 25       8   26         1    3   1 -0.13 0.07700000 126         NCT00286429 #> 26       8   26         3    3   2 -0.63 0.07600000 130         NCT00286429 #> 27       8   26         4    3   3 -0.71 0.07800000 126         NCT00286429 #> 28       9   12         1    3   1  0.34 0.06010509 103         NCT01318083 #> 29       9   12         3    3   2 -0.60 0.05491252 104         NCT01318083 #> 30       9   12         4    3   3 -0.66 0.05491252 104         NCT01318083 #> 31      10   12         1    3   1  0.04 0.05347391  74         NCT01263483 #> 32      10   12         3    3   2 -0.96 0.06308933  76         NCT01263483 #> 33      10   12         4    3   3 -0.91 0.05400422  79         NCT01263483 #> 34      11   12         1    6   1 -0.01 0.13430944  41         NCT00755846 #> 35      11   12         2    6   2 -0.19 0.12035661  42         NCT00755846 #> 36      11   12         3    6   3 -0.54 0.12189965  42         NCT00755846 #> 37      11   12         4    6   4 -0.56 0.11627553  45         NCT00755846 #> 38      11   12         5    6   5 -0.44 0.12352384  43         NCT00755846 #> 39      11   12         6    6   6 -0.51 0.11909698  44         NCT00755846 #> 40      12   36         3    2   1 -0.67 0.04742520 147         NCT01318122 #> 41      12   36         4    2   2 -0.69 0.04874593 151         NCT01318122 #> 42      13   40         3    2   1 -0.78 0.08194019  82         NCT01263509 #> 43      13   40         4    2   2 -0.92 0.07608902  78         NCT01263509 #> 44      14   12         1    3   1  0.21 0.06400000 100         NCT01318109 #> 45      14   12         3    3   2 -0.54 0.05838404  92         NCT01318109 #> 46      14   12         4    3   3 -0.64 0.05001042  96         NCT01318109 #>         agent   dose fupcount fups #> 1  alogliptin   0.00        4    4 #> 2  alogliptin   6.25        4    4 #> 3  alogliptin  12.50        4    4 #> 4  alogliptin  25.00        4    4 #> 5  alogliptin  50.00        4    4 #> 6  alogliptin   0.00        6    6 #> 7  alogliptin  12.50        6    6 #> 8  alogliptin  25.00        6    6 #> 9  alogliptin   6.25        8    8 #> 10 alogliptin  12.50        8    8 #> 11 alogliptin  25.00        8    8 #> 12 alogliptin  50.00        8    8 #> 13 alogliptin   0.00        6    6 #> 14 alogliptin  12.50        6    6 #> 15 alogliptin  25.00        6    6 #> 16 alogliptin   0.00        5    5 #> 17 alogliptin  12.50        5    5 #> 18 alogliptin  25.00        5    5 #> 19 alogliptin   0.00        6    6 #> 20 alogliptin  12.50        6    6 #> 21 alogliptin  25.00        6    6 #> 22 alogliptin   0.00        4    4 #> 23 alogliptin  12.50        4    4 #> 24 alogliptin  25.00        4    4 #> 25 alogliptin   0.00        6    6 #> 26 alogliptin  12.50        6    6 #> 27 alogliptin  25.00        6    6 #> 28 alogliptin   0.00        4    4 #> 29 alogliptin  12.50        4    4 #> 30 alogliptin  25.00        4    4 #> 31 alogliptin   0.00        4    4 #> 32 alogliptin  12.50        4    4 #> 33 alogliptin  25.00        4    4 #> 34 alogliptin   0.00        2    2 #> 35 alogliptin   6.25        2    2 #> 36 alogliptin  12.50        2    2 #> 37 alogliptin  25.00        2    2 #> 38 alogliptin  50.00        2    2 #> 39 alogliptin 100.00        2    2 #> 40 alogliptin  12.50        8    8 #> 41 alogliptin  25.00        8    8 #> 42 alogliptin  12.50        9    9 #> 43 alogliptin  25.00        9    9 #> 44 alogliptin   0.00        4    4 #> 45 alogliptin  12.50        4    4 #> 46 alogliptin  25.00        4    4"},{"path":"/reference/get.model.vals.html","id":null,"dir":"Reference","previous_headings":"","what":"Get MBNMA model values — get.model.vals","title":"Get MBNMA model values — get.model.vals","text":"Extracts specific information required prediction time-course MBNMA model","code":""},{"path":"/reference/get.model.vals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get MBNMA model values — get.model.vals","text":"","code":"get.model.vals(mbnma, E0 = 0, level = \"treatments\", lim = \"cred\")"},{"path":"/reference/get.model.vals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get MBNMA model values — get.model.vals","text":"mbnma S3 object class \"mbnma\" generated running time-course MBNMA model E0 object indicate value(s) use response time = 0 prediction. can take number different formats depending used/calculated. default 0 may lead non-sensical predictions Ratio Means modeled. numeric() single numeric value representing deterministic response time = 0 formula() formula representing stochastic distribution response time = 0. specified random number generator (RNG) given string, can take RNG distribution function exists R. example: ~rnorm(n, 7, 0.5). level Can take either \"treatment\" make predictions treatments, \"class\" make predictions classes (case object must class effect model). lim Specifies calculation either 95% credible intervals (lim=\"cred\") 95% prediction intervals (lim=\"pred\").","code":""},{"path":"/reference/get.model.vals.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get MBNMA model values — get.model.vals","text":"list containing named elements correspond different time-course parameters mbnma. elements contain MCMC results either taken directly mbnma (case random time-course parameters specified method=\"random\") randomly generated using parameter values estimated mbnma. Additional elements contain following values: timecourse character object specifies time-course used mbnma terms alpha, beta, mu, d time. Consistency relative time-course parameters specified terms mu d. time.params character vector indicates different time-course parameters required prediction @noRd","code":""},{"path":"/reference/get.prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Get current priors from JAGS model code — get.prior","title":"Get current priors from JAGS model code — get.prior","text":"Identical get.prior() MBNMAdose. function takes JAGS model presented string identifies prior values used calculation.","code":""},{"path":"/reference/get.prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get current priors from JAGS model code — get.prior","text":"","code":"get.prior(model)"},{"path":"/reference/get.prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get current priors from JAGS model code — get.prior","text":"model character object JAGS MBNMA model code","code":""},{"path":"/reference/get.prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get current priors from JAGS model code — get.prior","text":"character vector, element line JAGS code corresponding prior JAGS code.","code":""},{"path":"/reference/get.prior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get current priors from JAGS model code — get.prior","text":"Even MBNMA model initialised successfully results calculated, JAGS model saved MBNMA$model.arg$jagscode therefore priors can still obtained. allows priors changed even failing models, may help solve issues initialisation.","code":""},{"path":"/reference/get.prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get current priors from JAGS model code — get.prior","text":"","code":"# \\donttest{ # Create mb.network object using an MBNMAtime dataset network <- mb.network(osteopain) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Create mb.network object using an MBNMAdose dataset  # Run linear MBNMA result <- mb.run(network, fun=tpoly(degree=1,     pool.1=\"rel\", method.1=\"random\")) #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 163 #>    Total graph size: 7701 #>  #> Initializing model #>   # Obtain model prior values get.prior(result$model.arg$jagscode) #> $mu.1 #> [1] \"dnorm(0,0.0001)\" #>  #> $alpha #> [1] \"dnorm(0,0.0001)\" #>  #> $d.1 #> [1] \"dnorm(0,0.001)\" #>  #> $sd.beta.1 #> [1] \"dnorm(0,0.05) T(0,)\" #>   # ...also equivalent to print(result$model.arg$priors) #> $mu.1 #> [1] \"dnorm(0,0.0001)\" #>  #> $alpha #> [1] \"dnorm(0,0.0001)\" #>  #> $d.1 #> [1] \"dnorm(0,0.001)\" #>  #> $sd.beta.1 #> [1] \"dnorm(0,0.05) T(0,)\" #>  # }"},{"path":"/reference/get.relative.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates relative effects/mean differences at a particular time-point — get.relative","title":"Calculates relative effects/mean differences at a particular time-point — get.relative","text":"Uses mbnma time-course parameter estimates calculate treatment differences treatments classes particular time-point. Can used compare treatments evaluated studies different follow-times, even compare treatments different MBNMA models via common comparator.","code":""},{"path":"/reference/get.relative.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates relative effects/mean differences at a particular time-point — get.relative","text":"","code":"get.relative(   mbnma,   mbnma.add = NULL,   time = max(mbnma$model.arg$jagsdata$time, na.rm = TRUE),   treats = unique(c(mbnma$network$treatments, mbnma.add$network$treatments)),   classes = NULL,   lim = \"cred\" )"},{"path":"/reference/get.relative.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates relative effects/mean differences at a particular time-point — get.relative","text":"mbnma S3 object class \"mbnma\" generated running time-course MBNMA model mbnma.add S3 object class(\"mbnma\") generated running time-course MBNMA model. specified results two different MBNMA models combined perform 2-stage MBNMA (see Details). time numeric value time estimate relative effects/mean differences. treats character vector treatment names calculate relative effects/mean differences. Must subset mbnma$network$treatments classes character vector class names calculate relative effects/mean differences . Must subset mbnma$network$classes. works class effect models. lim Specifies calculation either 95% credible intervals (lim=\"cred\") 95% prediction intervals (lim=\"pred\").","code":""},{"path":"/reference/get.relative.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates relative effects/mean differences at a particular time-point — get.relative","text":"object class \"relative.array\" list containing: time-point results estimated Matrices posterior means, medians, SDs upper lower 95% credible intervals differences treatment array containing MCMC results differences treatments specified treats classes specified classes. Results reported tables row-defined treatment minus column-defined treatment.","code":""},{"path":"/reference/get.relative.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculates relative effects/mean differences at a particular time-point — get.relative","text":"get.relative() can also used perform 2-stage MBNMA allows synthesis results two different MBNMA models via single common comparator. MBNMA model, treatments must share time-course function. However, 2-stage approach can enable fitting different time-course functions different sets (\"subnetworks\") treatments. example, treatments may rich time-course information, allowing complex time-course function used, whereas others may sparse, requiring simpler time-course function. Relative comparisons treatments two datasets specific follow-times can estimated MBNMA predicted effects versus common comparator using Bucher method assuming consistency.  Step 1: network chosen network reference treatment () subnetworks rich sparse time-course data. Step 2: Separate time-course MBNMAs fitted subnetwork using different time-course function, relative effects versus network reference treatment predicted time. Step 3: Bucher method used calculate predicted relative effects treatments specific time-points interest (e.g. \\(S_{1}\\), \\(S_{2}\\) \\(S_{3}\\)). clarity, 95%CrIs shown plots tables calculated computed get.relative(). Thick connecting lines network plots indicate comparisons rich time-course data can modelled complex function (e.g. B-spline), thin connecting lines network plots indicate comparisons sparse time-course data can modelled less complex function (e.g. BEST-ITP). Comparisons treatments different subnetworks network reference must excluded (red dashed line network plot).","code":""},{"path":"/reference/get.relative.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates relative effects/mean differences at a particular time-point — get.relative","text":"","code":"# \\donttest{ # Create an mb.network object from a dataset alognet <- mb.network(alog_pcfb) #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data  # Run a quadratic time-course MBNMA using the alogliptin dataset mbnma <- mb.run(alognet,   fun=tpoly(degree=2,   pool.1=\"rel\", method.1=\"random\",   pool.2=\"rel\", method.2=\"common\"   ) ) #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 233 #>    Unobserved stochastic nodes: 71 #>    Total graph size: 4375 #>  #> Initializing model #>   # Calculate differences between all treatments at 20 weeks follow-up allres <- get.relative(mbnma, time=20)  # Calculate difference between a subset of treatments at 10 weeks follow-up subres <- get.relative(mbnma, time=10,   treats=c(\"alog_50\", \"alog_25\", \"placebo\"))    ########################### ##### 2-stage MBNMA ##### ###########################  # Using the osteoarthritis dataset # With placebo (Pl_0) as common comparator between subnetworks  #### Sparse model ####  # Treatments on which time-course data is limited sparse.trt <- c(\"Ce_100\", \"Ce_400\", \"Du_90\", \"Lu_200\", \"Lu_400\",   \"Lu_NA\", \"Et_5\", \"Ox_44\")  # Create a subnetwork of studies comparing these treatments sparse.df <- osteopain %>% dplyr::group_by(studyID) %>%   dplyr::filter(any(treatment %in% sparse.trt)) %>%   dplyr::ungroup() %>%   subset(treatment %in% c(\"Pl_0\", sparse.trt))  sparse.net <- mb.network(sparse.df) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Run a ITP MBNMA with a known rate sparse.mbnma <- mb.run(sparse.net, fun=titp(method.rate=0.8, pool.rate=\"abs\")) #> 'rate' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 76 #>    Unobserved stochastic nodes: 28 #>    Total graph size: 1447 #>  #> Initializing model #>    #### Complex model ####  # Treatments on which time-course data is rich rich.trt <- levels(osteopain$treatment)[!levels(osteopain$treatment) %in%   c(\"Pl_0\", \"Ce_100\", \"Ce_400\", \"Du_90\", \"Lu_200\",     \"Lu_400\", \"Lu_NA\", \"Et_5\", \"Ox_44\")]  # Create a subnetwork of studies comparing these treatments rich.df <- osteopain %>% dplyr::group_by(studyID) %>%   dplyr::filter(any(treatment %in% rich.trt)) %>%   dplyr::ungroup() %>%   subset(treatment %in% c(\"Pl_0\", rich.trt))  rich.net <- mb.network(rich.df) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Run a Emax MBNMA rich.mbnma <- mb.run(rich.net, temax(p.expon = FALSE)) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 363 #>    Unobserved stochastic nodes: 121 #>    Total graph size: 7221 #>  #> Initializing model #>    #### Calculate relative effects between models ####  # At 10 weeks follow-up rels.sparse <- get.relative(sparse.mbnma, time=10) rels.rich <- get.relative(rich.mbnma, time=10)  rels.all <- get.relative(mbnma=rich.mbnma,   mbnma.add=sparse.mbnma, time=10)  print(rels.all$median) #>                Pl_0      Ce_200        Et_10       Et_30       Et_60 #> Pl_0             NA  0.95786207  0.469334428  1.23378832  1.65104875 #> Ce_200  -0.95786207          NA -0.488661876  0.27712434  0.69363518 #> Et_10   -0.46933443  0.48866188           NA  0.76143617  1.17949230 #> Et_30   -1.23378832 -0.27712434 -0.761436172          NA  0.41674922 #> Et_60   -1.65104875 -0.69363518 -1.179492300 -0.41674922          NA #> Et_90   -1.72706352 -0.77034248 -1.255377879 -0.49623025 -0.07486704 #> Lu_100  -0.91707338  0.03812998 -0.447195659  0.31741448  0.73164489 #> Na_1000 -1.19839526 -0.24041777 -0.726833138  0.03466576  0.45141675 #> Na_1500 -1.12539762 -0.16751788 -0.654163401  0.10753726  0.52128551 #> Na_250  -0.01088976  0.94759464  0.457724208  1.22238443  1.63665364 #> Na_750  -0.87520387  0.07948040 -0.406690178  0.35585021  0.77217264 #> Ro_12   -0.94362175  0.01531815 -0.478537003  0.28707661  0.70645547 #> Ro_125  -2.36837938 -1.41603317 -1.894439485 -1.13912344 -0.72269930 #> Ro_25   -1.30449668 -0.34627935 -0.833557870 -0.07076989  0.34751406 #> Tr_100  -0.47401141  0.48499402 -0.002972076  0.76025536  1.17728633 #> Tr_200  -0.47520834  0.48285819 -0.006878507  0.75658514  1.17424077 #> Tr_300  -0.83637689  0.12029146 -0.366580429  0.39566060  0.81136393 #> Tr_400  -0.92616118  0.03153188 -0.458384412  0.30544346  0.72171895 #> Va_10   -0.75118963  0.20423689 -0.276337892  0.47968076  0.89745136 #> Va_20   -0.98705567 -0.03191077 -0.514140767  0.24376982  0.65940699 #> Va_5    -0.84660087  0.11089067 -0.375176385  0.38608759  0.80267054 #> Ce_100  -0.55007895  0.40762766 -0.079763851  0.68235735  1.10316703 #> Ce_400  -0.90080821  0.05782586 -0.430826006  0.32837016  0.74873969 #> Du_90   -0.55164514  0.40710162 -0.078717040  0.68164239  1.09687832 #> Et_5    -1.02461478 -0.06734514 -0.556659585  0.20554810  0.62508481 #> Lu_200  -0.54515606  0.41176949 -0.074239899  0.68976238  1.10447932 #> Lu_400  -0.71082978  0.24796676 -0.237677730  0.52258084  0.94144304 #> Lu_NA   -0.80460489  0.15501763 -0.330053818  0.43287575  0.85220838 #> Ox_44   -1.08198328 -0.12564933 -0.605861337  0.15170452  0.56290980 #>               Et_90       Lu_100     Na_1000     Na_1500      Na_250 #> Pl_0     1.72706352  0.917073375  1.19839526  1.12539762  0.01088976 #> Ce_200   0.77034248 -0.038129982  0.24041777  0.16751788 -0.94759464 #> Et_10    1.25537788  0.447195659  0.72683314  0.65416340 -0.45772421 #> Et_30    0.49623025 -0.317414481 -0.03466576 -0.10753726 -1.22238443 #> Et_60    0.07486704 -0.731644888 -0.45141675 -0.52128551 -1.63665364 #> Et_90            NA -0.811938484 -0.52713274 -0.59900260 -1.71258656 #> Lu_100   0.81193848           NA  0.28209799  0.21080301 -0.90762622 #> Na_1000  0.52713274 -0.282097987          NA -0.07277652 -1.18621790 #> Na_1500  0.59900260 -0.210803013  0.07277652          NA -1.11760073 #> Na_250   1.71258656  0.907626219  1.18621790  1.11760073          NA #> Na_750   0.84843963  0.040318640  0.32055112  0.24781214 -0.86549628 #> Ro_12    0.78294994 -0.024468874  0.25594286  0.18164701 -0.93628713 #> Ro_125  -0.64435562 -1.453843402 -1.17130484 -1.24093645 -2.35619638 #> Ro_25    0.41983802 -0.384629976 -0.10571838 -0.17555158 -1.29108199 #> Tr_100   1.25343019  0.444476781  0.72279736  0.65190481 -0.45929123 #> Tr_200   1.24726037  0.441249886  0.72399891  0.65212549 -0.46080699 #> Tr_300   0.88768676  0.077387143  0.36053704  0.28978348 -0.82411911 #> Tr_400   0.80032595 -0.008887405  0.27315666  0.20321486 -0.91574571 #> Va_10    0.97706760  0.166102129  0.44468249  0.37180709 -0.74003835 #> Va_20    0.73779495 -0.069744969  0.20952806  0.13860244 -0.97237896 #> Va_5     0.88102018  0.068879795  0.35317011  0.28073868 -0.83923359 #> Ce_100   1.17999484  0.367657435  0.64958822  0.57525171 -0.54052624 #> Ce_400   0.83009327  0.016301202  0.29798097  0.22597662 -0.88618994 #> Du_90    1.17889107  0.364859059  0.64727252  0.57598260 -0.53971037 #> Et_5     0.69555706 -0.111579982  0.17183682  0.10257705 -1.01257380 #> Lu_200   1.18160199  0.373686979  0.65308387  0.57929988 -0.53109513 #> Lu_400   1.01957486  0.207239104  0.48941330  0.41700509 -0.69482600 #> Lu_NA    0.93017153  0.117810989  0.39577773  0.32480707 -0.79405001 #> Ox_44    0.65248279 -0.166111854  0.11616749  0.04504749 -1.06942653 #>              Na_750       Ro_12    Ro_125       Ro_25       Tr_100       Tr_200 #> Pl_0     0.87520387  0.94362175 2.3683794  1.30449668  0.474011414  0.475208344 #> Ce_200  -0.07948040 -0.01531815 1.4160332  0.34627935 -0.484994020 -0.482858185 #> Et_10    0.40669018  0.47853700 1.8944395  0.83355787  0.002972076  0.006878507 #> Et_30   -0.35585021 -0.28707661 1.1391234  0.07076989 -0.760255361 -0.756585139 #> Et_60   -0.77217264 -0.70645547 0.7226993 -0.34751406 -1.177286331 -1.174240773 #> Et_90   -0.84843963 -0.78294994 0.6443556 -0.41983802 -1.253430189 -1.247260373 #> Lu_100  -0.04031864  0.02446887 1.4538434  0.38462998 -0.444476781 -0.441249886 #> Na_1000 -0.32055112 -0.25594286 1.1713048  0.10571838 -0.722797360 -0.723998912 #> Na_1500 -0.24781214 -0.18164701 1.2409364  0.17555158 -0.651904814 -0.652125487 #> Na_250   0.86549628  0.93628713 2.3561964  1.29108199  0.459291232  0.460806985 #> Na_750           NA  0.07106871 1.4923774  0.42573403 -0.402787361 -0.397739555 #> Ro_12   -0.07106871          NA 1.4206115  0.35481691 -0.475201281 -0.470283764 #> Ro_125  -1.49237744 -1.42061146        NA -1.06315567 -1.891708096 -1.890989925 #> Ro_25   -0.42573403 -0.35481691 1.0631557          NA -0.831647469 -0.829905992 #> Tr_100   0.40278736  0.47520128 1.8917081  0.83164747           NA  0.002698239 #> Tr_200   0.39773956  0.47028376 1.8909899  0.82990599 -0.002698239           NA #> Tr_300   0.04097244  0.10672252 1.5321272  0.47008916 -0.365169298 -0.362255743 #> Tr_400  -0.04730743  0.02005809 1.4434590  0.37791734 -0.455067941 -0.454049081 #> Va_10    0.12291324  0.19769505 1.6144251  0.55269539 -0.277928180 -0.274611126 #> Va_20   -0.10988483 -0.03993481 1.3835749  0.31718526 -0.515740014 -0.513532894 #> Va_5     0.02940144  0.10144568 1.5221554  0.45775026 -0.374250262 -0.368679754 #> Ce_100   0.32855692  0.39928297 1.8236828  0.75674006 -0.078883040 -0.073038817 #> Ce_400  -0.02487317  0.04597596 1.4697168  0.40882970 -0.428450256 -0.422137502 #> Du_90    0.32640813  0.39461629 1.8199503  0.75210404 -0.074928133 -0.073834990 #> Et_5    -0.14837947 -0.07729025 1.3413456  0.27683033 -0.554414021 -0.553121169 #> Lu_200   0.33090809  0.39744360 1.8265525  0.75797001 -0.073299113 -0.069029143 #> Lu_400   0.16824387  0.23585257 1.6599437  0.59656826 -0.233888005 -0.232405942 #> Lu_NA    0.07611853  0.14798156 1.5716172  0.50372586 -0.327304601 -0.321849737 #> Ox_44   -0.20588120 -0.13557471 1.2912296  0.22765748 -0.605963756 -0.606869420 #>               Tr_300       Tr_400       Va_10       Va_20         Va_5 #> Pl_0     0.836376892  0.926161184  0.75118963  0.98705567  0.846600866 #> Ce_200  -0.120291457 -0.031531885 -0.20423689  0.03191077 -0.110890674 #> Et_10    0.366580429  0.458384412  0.27633789  0.51414077  0.375176385 #> Et_30   -0.395660602 -0.305443457 -0.47968076 -0.24376982 -0.386087587 #> Et_60   -0.811363934 -0.721718952 -0.89745136 -0.65940699 -0.802670545 #> Et_90   -0.887686756 -0.800325950 -0.97706760 -0.73779495 -0.881020179 #> Lu_100  -0.077387143  0.008887405 -0.16610213  0.06974497 -0.068879795 #> Na_1000 -0.360537044 -0.273156665 -0.44468249 -0.20952806 -0.353170111 #> Na_1500 -0.289783483 -0.203214859 -0.37180709 -0.13860244 -0.280738678 #> Na_250   0.824119107  0.915745714  0.74003835  0.97237896  0.839233588 #> Na_750  -0.040972440  0.047307428 -0.12291324  0.10988483 -0.029401443 #> Ro_12   -0.106722524 -0.020058095 -0.19769505  0.03993481 -0.101445678 #> Ro_125  -1.532127156 -1.443458984 -1.61442514 -1.38357486 -1.522155424 #> Ro_25   -0.470089160 -0.377917337 -0.55269539 -0.31718526 -0.457750261 #> Tr_100   0.365169298  0.455067941  0.27792818  0.51574001  0.374250262 #> Tr_200   0.362255743  0.454049081  0.27461113  0.51353289  0.368679754 #> Tr_300            NA  0.086078976 -0.08689509  0.15138500  0.007326397 #> Tr_400  -0.086078976           NA -0.17513426  0.06016429 -0.078268439 #> Va_10    0.086895090  0.175134260          NA  0.23361545  0.092671264 #> Va_20   -0.151385001 -0.060164285 -0.23361545          NA -0.137784896 #> Va_5    -0.007326397  0.078268439 -0.09267126  0.13778490           NA #> Ce_100   0.289971098  0.374401110  0.20680507  0.43820127  0.301048068 #> Ce_400  -0.060549949  0.026443144 -0.14982822  0.08288781 -0.051411393 #> Du_90    0.287019221  0.378941107  0.20017623  0.44221168  0.300180207 #> Et_5    -0.182616343 -0.103139919 -0.27127979 -0.04033424 -0.178618882 #> Lu_200   0.291425573  0.382988295  0.20555469  0.44030199  0.299780937 #> Lu_400   0.129604320  0.218932568  0.04046688  0.27651458  0.135816265 #> Lu_NA    0.040564419  0.130156998 -0.04419796  0.19086128  0.045568727 #> Ox_44   -0.244589431 -0.153104947 -0.32296853 -0.09442702 -0.231945130 #>               Ce_100      Ce_400        Du_90        Et_5       Lu_200 #> Pl_0     0.550078951  0.90080821  0.551645137  1.02461478  0.545156059 #> Ce_200  -0.407627656 -0.05782586 -0.407101622  0.06734514 -0.411769486 #> Et_10    0.079763851  0.43082601  0.078717040  0.55665959  0.074239899 #> Et_30   -0.682357350 -0.32837016 -0.681642390 -0.20554810 -0.689762385 #> Et_60   -1.103167032 -0.74873969 -1.096878319 -0.62508481 -1.104479315 #> Et_90   -1.179994838 -0.83009327 -1.178891067 -0.69555706 -1.181601991 #> Lu_100  -0.367657435 -0.01630120 -0.364859059  0.11157998 -0.373686979 #> Na_1000 -0.649588218 -0.29798097 -0.647272523 -0.17183682 -0.653083865 #> Na_1500 -0.575251714 -0.22597662 -0.575982601 -0.10257705 -0.579299883 #> Na_250   0.540526241  0.88618994  0.539710369  1.01257380  0.531095134 #> Na_750  -0.328556918  0.02487317 -0.326408132  0.14837947 -0.330908093 #> Ro_12   -0.399282971 -0.04597596 -0.394616287  0.07729025 -0.397443595 #> Ro_125  -1.823682849 -1.46971678 -1.819950304 -1.34134563 -1.826552461 #> Ro_25   -0.756740062 -0.40882970 -0.752104039 -0.27683033 -0.757970006 #> Tr_100   0.078883040  0.42845026  0.074928133  0.55441402  0.073299113 #> Tr_200   0.073038817  0.42213750  0.073834990  0.55312117  0.069029143 #> Tr_300  -0.289971098  0.06054995 -0.287019221  0.18261634 -0.291425573 #> Tr_400  -0.374401110 -0.02644314 -0.378941107  0.10313992 -0.382988295 #> Va_10   -0.206805069  0.14982822 -0.200176233  0.27127979 -0.205554687 #> Va_20   -0.438201269 -0.08288781 -0.442211676  0.04033424 -0.440301990 #> Va_5    -0.301048068  0.05141139 -0.300180207  0.17861888 -0.299780937 #> Ce_100            NA  0.35135787  0.002509104  0.47434844 -0.008029354 #> Ce_400  -0.351357869          NA -0.350686708  0.12469187 -0.352040398 #> Du_90   -0.002509104  0.35068671           NA  0.47189098 -0.003418536 #> Et_5    -0.474348438 -0.12469187 -0.471890983          NA -0.481963676 #> Lu_200   0.008029354  0.35204040  0.003418536  0.48196368           NA #> Lu_400  -0.158204636  0.19055163 -0.159894306  0.31824389 -0.162575961 #> Lu_NA   -0.249432667  0.09538543 -0.247327931  0.22805366 -0.255081584 #> Ox_44   -0.535164628 -0.18587336 -0.536208083 -0.05750913 -0.535867453 #>              Lu_400       Lu_NA       Ox_44 #> Pl_0     0.71082978  0.80460489  1.08198328 #> Ce_200  -0.24796676 -0.15501763  0.12564933 #> Et_10    0.23767773  0.33005382  0.60586134 #> Et_30   -0.52258084 -0.43287575 -0.15170452 #> Et_60   -0.94144304 -0.85220838 -0.56290980 #> Et_90   -1.01957486 -0.93017153 -0.65248279 #> Lu_100  -0.20723910 -0.11781099  0.16611185 #> Na_1000 -0.48941330 -0.39577773 -0.11616749 #> Na_1500 -0.41700509 -0.32480707 -0.04504749 #> Na_250   0.69482600  0.79405001  1.06942653 #> Na_750  -0.16824387 -0.07611853  0.20588120 #> Ro_12   -0.23585257 -0.14798156  0.13557471 #> Ro_125  -1.65994373 -1.57161717 -1.29122964 #> Ro_25   -0.59656826 -0.50372586 -0.22765748 #> Tr_100   0.23388801  0.32730460  0.60596376 #> Tr_200   0.23240594  0.32184974  0.60686942 #> Tr_300  -0.12960432 -0.04056442  0.24458943 #> Tr_400  -0.21893257 -0.13015700  0.15310495 #> Va_10   -0.04046688  0.04419796  0.32296853 #> Va_20   -0.27651458 -0.19086128  0.09442702 #> Va_5    -0.13581626 -0.04556873  0.23194513 #> Ce_100   0.15820464  0.24943267  0.53516463 #> Ce_400  -0.19055163 -0.09538543  0.18587336 #> Du_90    0.15989431  0.24732793  0.53620808 #> Et_5    -0.31824389 -0.22805366  0.05750913 #> Lu_200   0.16257596  0.25508158  0.53586745 #> Lu_400           NA  0.09429357  0.37452183 #> Lu_NA   -0.09429357          NA  0.27989636 #> Ox_44   -0.37452183 -0.27989636          NA   # }"},{"path":"/reference/getjagsdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepares data for JAGS — getjagsdata","title":"Prepares data for JAGS — getjagsdata","text":"Converts MBNMA data frame list use JAGS model","code":""},{"path":"/reference/getjagsdata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepares data for JAGS — getjagsdata","text":"","code":"getjagsdata(   data.ab,   fun = NULL,   class = FALSE,   rho = NULL,   covstruct = \"CS\",   link = \"identity\",   cfb = NULL )"},{"path":"/reference/getjagsdata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepares data for JAGS — getjagsdata","text":"data.ab data frame arm-level data \"long\" format containing columns: studyID Study identifiers time Numeric data indicating follow-times y Numeric data indicating aggregate response given observation (e.g. mean) se Numeric data indicating standard error given observation treatment Treatment identifiers (can numeric, factor character) class optional column indicating particular class identifier. Observations treatment identifier must also class identifier. n optional column indicating number participants used calculate response given observation (required modelling using Standardised Mean Differences) fun object class \"timefun\" generated (see Details) using tloglin(), tpoly(), titp(), temax(), tfpoly(), tspline() tuser() class boolean object indicating whether data.ab contains information different classes treatments rho correlation coefficient modelling within-study correlation time points. default string representing prior distribution JAGS, indicating estimated data (e.g. rho=\"dunif(0,1)\"). rho also assigned numeric value (e.g. rho=0.7), fixes rho model value (e.g. use deterministic sensitivity analysis). set rho=0 (default) implies modelling correlation time points. covstruct character indicate covariance structure required modelling correlation time points (), since determines data. Can either \"CS\" (compound symmetry), \"AR1\" (autoregressive AR1) \"varadj\" (variance-adjustment). link Can take either \"identity\" (default), \"log\" (modelling Ratios Means (Friedrich et al. 2011) ) \"smd\" (modelling Standardised Mean Differences - although also corresponds identity link function). cfb logical vector whose length equal unique number studies data.ab, element TRUE study data reported change--baseline FALSE otherwise. left NULL (default) identified data assuming study data time=0 reports change--baseline.","code":""},{"path":"/reference/getjagsdata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepares data for JAGS — getjagsdata","text":"named list numbers, vector, matrices arrays sent JAGS. List elements : y array mean responses observation arm within study se array standard errors observation arm within study time matrix follow-times within study fups numeric vector number follow-measurements per study narm numeric vector number arms per study NS total number studies dataset NT total number treatments dataset treat matrix treatment codes within study Nclass Optional. total number classes dataset class Optional. matrix class codes within study classkey Optional. vector class codes correspond treatment codes. length number treatment codes. mat.triangle Optional. matrix number indicating fill covariance matrices within JAGS code. mat.order Optional. matrix number indicating order fill covariance matrices within JAGS code. timedif.0 Optional. vector difference times first second follow-time study.","code":""},{"path":"/reference/getjagsdata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepares data for JAGS — getjagsdata","text":"","code":"# Using the alogliptin dataset network <- mb.network(alog_pcfb) #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data jagsdat <- getjagsdata(network$data.ab)   # Get JAGS data with class netclass <- mb.network(goutSUA_CFBcomb) #> Reference treatment is `Plac` #> Studies reporting change from baseline automatically identified from the data jagsdat <- getjagsdata(netclass$data.ab, class=TRUE)   # Get JAGS data that allows for modelling correlation between time points painnet <- mb.network(osteopain) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data jagsdat <- getjagsdata(painnet$data.ab, rho=\"dunif(0,1)\", covstruct=\"AR1\")"},{"path":"/reference/getnmadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepares NMA data for JAGS — getnmadata","title":"Prepares NMA data for JAGS — getnmadata","text":"Converts data frame list use JAGS NMA model","code":""},{"path":"/reference/getnmadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepares NMA data for JAGS — getnmadata","text":"","code":"getnmadata(data.ab, link = \"identity\")"},{"path":"/reference/getnmadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepares NMA data for JAGS — getnmadata","text":"data.ab data frame arm-level data \"long\" format containing columns: studyID Study identifiers time Numeric data indicating follow-times y Numeric data indicating aggregate response given observation (e.g. mean) se Numeric data indicating standard error given observation treatment Treatment identifiers (can numeric, factor character) class optional column indicating particular class identifier. Observations treatment identifier must also class identifier. n optional column indicating number participants used calculate response given observation (required modelling using Standardised Mean Differences) link Can take either \"identity\" (default), \"log\" (modelling Ratios Means (Friedrich et al. 2011) ) \"smd\" (modelling Standardised Mean Differences - although also corresponds identity link function).","code":""},{"path":"/reference/getnmadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepares NMA data for JAGS — getnmadata","text":"named list numbers, vector, matrices arrays sent JAGS. List elements : y array mean responses observation arm within study se array standard errors observation arm within study narm numeric vector number arms per study NS total number studies dataset NT total number treatments dataset treat matrix treatment codes within study","code":""},{"path":"/reference/getnmadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepares NMA data for JAGS — getnmadata","text":"","code":"# Using the alogliptin dataset network <- mb.network(alog_pcfb) #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data  # Construct a dataset with the latest time point in each study data.ab <- get.latest.time(network) getnmadata(data.ab) #> $narm #>  [1] 6 5 4 3 3 3 3 3 3 3 3 3 2 2 #>  #> $NS #> [1] 14 #>  #> $studyID #>  [1] 11  1  3  2  4  5  6  7  8  9 10 14 12 13 #>  #> $NT #> [1] 6 #>  #> $y #>        [,1]  [,2]  [,3]  [,4]  [,5]  [,6] #>  [1,] -0.01 -0.19 -0.54 -0.56 -0.44 -0.51 #>  [2,]  0.06 -0.51 -0.70 -0.76 -0.82    NA #>  [3,] -0.33 -0.48 -0.66 -0.77    NA    NA #>  [4,] -0.02 -0.56 -0.59    NA    NA    NA #>  [5,] -0.19 -0.66 -0.80    NA    NA    NA #>  [6,]  0.01 -0.38 -0.52    NA    NA    NA #>  [7,] -0.10 -0.61 -0.59    NA    NA    NA #>  [8,] -0.19 -0.91 -0.97    NA    NA    NA #>  [9,] -0.13 -0.63 -0.71    NA    NA    NA #> [10,]  0.34 -0.60 -0.66    NA    NA    NA #> [11,]  0.04 -0.96 -0.91    NA    NA    NA #> [12,]  0.21 -0.54 -0.64    NA    NA    NA #> [13,] -0.67 -0.69    NA    NA    NA    NA #> [14,] -0.78 -0.92    NA    NA    NA    NA #>  #> $se #>             [,1]       [,2]       [,3]       [,4]       [,5]     [,6] #>  [1,] 0.13430944 0.12035661 0.12189965 0.11627553 0.12352384 0.119097 #>  [2,] 0.05311623 0.07650598 0.06219210 0.06187984 0.05287913       NA #>  [3,] 0.07622222 0.09923275 0.07808110 0.08346834         NA       NA #>  [4,] 0.09400000 0.06500000 0.06600000         NA         NA       NA #>  [5,] 0.08100000 0.05600000 0.05600000         NA         NA       NA #>  [6,] 0.08400000 0.05800000 0.05800000         NA         NA       NA #>  [7,] 0.07600000 0.05300000 0.05400000         NA         NA       NA #>  [8,] 0.05128776 0.04176295 0.04891748         NA         NA       NA #>  [9,] 0.07700000 0.07600000 0.07800000         NA         NA       NA #> [10,] 0.06010509 0.05491252 0.05491252         NA         NA       NA #> [11,] 0.05347391 0.06308933 0.05400422         NA         NA       NA #> [12,] 0.06400000 0.05838404 0.05001042         NA         NA       NA #> [13,] 0.04742520 0.04874593         NA         NA         NA       NA #> [14,] 0.08194019 0.07608902         NA         NA         NA       NA #>  #> $treat #>       [,1] [,2] [,3] [,4] [,5] [,6] #>  [1,]    1    2    3    4    5    6 #>  [2,]    1    2    3    4    5   NA #>  [3,]    2    3    4    5   NA   NA #>  [4,]    1    3    4   NA   NA   NA #>  [5,]    1    3    4   NA   NA   NA #>  [6,]    1    3    4   NA   NA   NA #>  [7,]    1    3    4   NA   NA   NA #>  [8,]    1    3    4   NA   NA   NA #>  [9,]    1    3    4   NA   NA   NA #> [10,]    1    3    4   NA   NA   NA #> [11,]    1    3    4   NA   NA   NA #> [12,]    1    3    4   NA   NA   NA #> [13,]    3    4   NA   NA   NA   NA #> [14,]    3    4   NA   NA   NA   NA #>"},{"path":"/reference/goutSUA_CFB.html","id":null,"dir":"Reference","previous_headings":"","what":"Studies of treatments for reducing serum uric acid in patients with gout — goutSUA_CFB","title":"Studies of treatments for reducing serum uric acid in patients with gout — goutSUA_CFB","text":"dataset systematic review interventions lowering Serum Uric Acid (SUA) concentration patients gout (published previously). outcome continuous, aggregate data responses correspond mean change baseline SUA mg/dL. Overall 41 treatments 8 agents network. Standard deviations imputed 181 observations.","code":""},{"path":"/reference/goutSUA_CFB.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Studies of treatments for reducing serum uric acid in patients with gout — goutSUA_CFB","text":"","code":"goutSUA_CFB"},{"path":"/reference/goutSUA_CFB.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Studies of treatments for reducing serum uric acid in patients with gout — goutSUA_CFB","text":"data frame 224 rows 7 variables: studyID Study identifiers time Numeric data indicating follow-times y Numeric data indicating mean response given observation se Numeric data indicating standard error given observation treatment Treatment identifiers factors. Labels shortened treatment names. treatname Character data giving full names treatment format agent_dose class Shortened agent names stored factors.","code":""},{"path":"/reference/goutSUA_CFB.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Studies of treatments for reducing serum uric acid in patients with gout — goutSUA_CFB","text":"Pfizer Ltd.","code":""},{"path":"/reference/goutSUA_CFB.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Studies of treatments for reducing serum uric acid in patients with gout — goutSUA_CFB","text":"goutSUA_CFB data frame long format (one row per observation, arm study), variables studyID, time, y, se, treatment, treatname class.","code":""},{"path":"/reference/goutSUA_CFBcomb.html","id":null,"dir":"Reference","previous_headings":"","what":"Studies of combined treatments for reducing serum uric acid in patients with gout — goutSUA_CFBcomb","title":"Studies of combined treatments for reducing serum uric acid in patients with gout — goutSUA_CFBcomb","text":"dataset systematic review interventions lowering Serum Uric Acid (SUA) concentration patients gout (published previously). outcome continuous, aggregate data responses correspond mean change baseline SUA mg/dL. Treatments similar doses pooled together improve network connectivity facilitate evidence synthesis, resulting 19 treatments 7 agents included network. Standard deviations imputed 181 observations.","code":""},{"path":"/reference/goutSUA_CFBcomb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Studies of combined treatments for reducing serum uric acid in patients with gout — goutSUA_CFBcomb","text":"","code":"goutSUA_CFBcomb"},{"path":"/reference/goutSUA_CFBcomb.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Studies of combined treatments for reducing serum uric acid in patients with gout — goutSUA_CFBcomb","text":"data frame 224 rows 7 variables: studyID Study identifiers time Numeric data indicating follow-times y Numeric data indicating mean response given observation se Numeric data indicating standard error given observation treatment Treatment identifiers factors. Labels shortened treatment names. treatname Character data giving full names treatment format agent_dose class Shortened agent names stored factors.","code":""},{"path":"/reference/goutSUA_CFBcomb.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Studies of combined treatments for reducing serum uric acid in patients with gout — goutSUA_CFBcomb","text":"Pfizer Ltd.","code":""},{"path":"/reference/goutSUA_CFBcomb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Studies of combined treatments for reducing serum uric acid in patients with gout — goutSUA_CFBcomb","text":"goutSUA_CFBcomb data frame long format (one row per observation, arm study), variables studyID, time, y, se, treatment, treatname class.","code":""},{"path":"/reference/hyalarthritis.html","id":null,"dir":"Reference","previous_headings":"","what":"Studies comparing hyaluronan (HA)–based viscosupplements for osteoarthritis — hyalarthritis","title":"Studies comparing hyaluronan (HA)–based viscosupplements for osteoarthritis — hyalarthritis","text":"dataset trials pain reduction patients osteoarthritis treated HA-based viscosupplements(Jansen et al. 2015) . Data reported study arm mean change baseline follow-visual analogue scale (0-100). dataset includes 16 Randomised-Controlled Trials (RCTs), comparing 6 treatments placebo.","code":""},{"path":"/reference/hyalarthritis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Studies comparing hyaluronan (HA)–based viscosupplements for osteoarthritis — hyalarthritis","text":"","code":"hyalarthritis"},{"path":"/reference/hyalarthritis.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Studies comparing hyaluronan (HA)–based viscosupplements for osteoarthritis — hyalarthritis","text":"data frame long format (one row per arm study), 150 rows 6 variables: studyID Study identifiers time Numeric data indicating time observation measured (given weeks) treatment Factor data indicating treatment participants randomised n Numeric data indicating number participants randomised arm y Numeric data indicating mean change baseline HbA1c study arm se Numeric data indicating standard error mean change baseline HbA1c study arm","code":""},{"path":"/reference/hyalarthritis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Studies comparing hyaluronan (HA)–based viscosupplements for osteoarthritis — hyalarthritis","text":"hyalarthritis data frame long format (one row per observation, arm study), variables studyID, time, treatment, n, y, se.","code":""},{"path":"/reference/hyalarthritis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Studies comparing hyaluronan (HA)–based viscosupplements for osteoarthritis — hyalarthritis","text":"Jansen JP, Vieira MC, Cope S (2015). “Network meta-analysis longitudinal data using fractional polynomials.” Stat Med, 34(15), 2294-311. ISSN 1097-0258 (Electronic) 0277-6715 (Linking), doi:10.1002/sim.6492 , https://pubmed.ncbi.nlm.nih.gov/25877808/.","code":""},{"path":"/reference/inconsistency.loops.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify comparisons in loops that fulfil criteria for node-splitting — inconsistency.loops","title":"Identify comparisons in loops that fulfil criteria for node-splitting — inconsistency.loops","text":"Identify comparisons informed direct indirect evidence independent sources, therefore fulfil criteria testing inconsistency via node-splitting. Follows method van Valkenhoef van Valkenhoef et al. (2016) .","code":""},{"path":"/reference/inconsistency.loops.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify comparisons in loops that fulfil criteria for node-splitting — inconsistency.loops","text":"","code":"inconsistency.loops(data)"},{"path":"/reference/inconsistency.loops.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify comparisons in loops that fulfil criteria for node-splitting — inconsistency.loops","text":"data data frame containing variables studyID treatment (numeric codes) indicate treatments used studies.","code":""},{"path":"/reference/inconsistency.loops.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify comparisons in loops that fulfil criteria for node-splitting — inconsistency.loops","text":"data frame comparisons informed direct indirect evidence independent sources. row data frame different treatment comparison. Numerical codes t1 t2 correspond treatment codes.","code":""},{"path":"/reference/inconsistency.loops.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify comparisons in loops that fulfil criteria for node-splitting — inconsistency.loops","text":"Similar gemtc::mtc.nodesplit() uses fixed reference treatment therefore suggests fewer loops test inconsistency. Heterogeneity can also parameterised inconsistency testing inconsistency additional loops whilst changing reference treatment also identifying heterogeneity. Depends igraph.","code":""},{"path":"/reference/inconsistency.loops.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Identify comparisons in loops that fulfil criteria for node-splitting — inconsistency.loops","text":"van Valkenhoef G, Dias S, Ades AE, Welton NJ (2016). “Automated generation node-splitting models assessment inconsistency network meta-analysis.” Res Synth Methods, 7(1), 80-93. ISSN 1759-2887 (Electronic) 1759-2879 (Linking), doi:10.1002/jrsm.1167 , https://pubmed.ncbi.nlm.nih.gov/26461181/.","code":""},{"path":"/reference/inconsistency.loops.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify comparisons in loops that fulfil criteria for node-splitting — inconsistency.loops","text":"","code":"data <- data.frame(studyID=c(1,1,2,2,3,3,4,4,5,5,5),   treatment=c(1,2,1,3,2,3,3,4,1,2,4)   )  # Identify comparisons informed by direct and indirect evidence inconsistency.loops(data) #>   t1 t2    path #> 5  3  4 3->1->4 #> 4  2  3 2->1->3"},{"path":"/reference/mb.comparisons.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify unique comparisons within a network (identical to MBNMAdose) — mb.comparisons","title":"Identify unique comparisons within a network (identical to MBNMAdose) — mb.comparisons","text":"Identify unique contrasts within network make head--head comparisons. Repetitions treatment comparison grouped together.","code":""},{"path":"/reference/mb.comparisons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify unique comparisons within a network (identical to MBNMAdose) — mb.comparisons","text":"","code":"mb.comparisons(data)"},{"path":"/reference/mb.comparisons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify unique comparisons within a network (identical to MBNMAdose) — mb.comparisons","text":"data data frame containing variables studyID treatment (numeric codes) indicate treatments used studies.","code":""},{"path":"/reference/mb.comparisons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify unique comparisons within a network (identical to MBNMAdose) — mb.comparisons","text":"data frame unique comparisons row represents different comparison. t1 t2 indicate treatment codes make comparison. nr indicates number times given comparison made within network. single observation study within dataset (.e. standard network meta-analysis) nr represent number studies compare treatments t1 t2. multiple observations study within dataset (time-course MBNMA) nr represent number time points dataset treatments t1 t2 compared.","code":""},{"path":"/reference/mb.comparisons.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify unique comparisons within a network (identical to MBNMAdose) — mb.comparisons","text":"","code":"data <- data.frame(studyID=c(1,1,2,2,3,3,4,4,5,5,5),   treatment=c(1,2,1,3,2,3,3,4,1,2,4)   )  # Identify comparisons informed by direct and indirect evidence mb.comparisons(data) #> # A tibble: 6 × 3 #> # Groups:   t1, t2 [6] #>      t1    t2    nr #>   <dbl> <dbl> <int> #> 1     1     2     2 #> 2     1     3     1 #> 3     1     4     1 #> 4     2     3     1 #> 5     2     4     1 #> 6     3     4     1"},{"path":"/reference/mb.make.contrast.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert arm-based MBNMA data to contrast data — mb.make.contrast","title":"Convert arm-based MBNMA data to contrast data — mb.make.contrast","text":"Converts object class mb.network arm-based long MBNMA data data frame contrast data (separate contrast treatment comparison time point within study). Data can either long wide.","code":""},{"path":"/reference/mb.make.contrast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert arm-based MBNMA data to contrast data — mb.make.contrast","text":"","code":"mb.make.contrast(network, datatype = NULL, format = \"wide\")"},{"path":"/reference/mb.make.contrast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert arm-based MBNMA data to contrast data — mb.make.contrast","text":"network object class mb.network datatype string indicating data type. Can binomial normal format string indicating data format. Can wide (two additional columns variable - contrast arms) long.","code":""},{"path":"/reference/mb.make.contrast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert arm-based MBNMA data to contrast data — mb.make.contrast","text":"data frame following columns. wide format, columns given indices 1 2 indicate arm given treatment comparison.: t treatment arm TE treatment effect (mean difference, log-odds) treatment arm 1 versus treatment arm 2 seTE standard error treatment effect (mean difference, log-odds) treatment arm 1 versus treatment arm 2 y mean response arm se standard error mean arm r number responders arm n total number participants arm fupcount Follow-identifier time time data reported studyID Study identifier","code":""},{"path":"/reference/mb.make.contrast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert arm-based MBNMA data to contrast data — mb.make.contrast","text":"","code":"# Create mb.network network <- mb.network(osteopain) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Convert to wide contrast data mb.make.contrast(network, format=\"wide\") #> Warning: Data type not specified and data frame contains y - data are assumed to be normal #>     t1 t2         TE       seTE       y1       y2        se1        se2 #> 1    1  6 -0.0530000 0.19136211 7.062000 7.009000 0.22216747 0.16055675 #> 2    1  7 -0.3060000 0.19588725 7.062000 6.756000 0.22216747 0.16960703 #> 3    1  8 -0.1890000 0.19028895 7.062000 6.873000 0.22216747 0.15841042 #> 4    1  9 -0.3760000 0.19204973 7.062000 6.686000 0.22216747 0.16193198 #> 5    1 10 -0.2080000 0.19209781 7.062000 6.854000 0.22216747 0.16202815 #> 6    6  7 -0.2530000 0.16508189 7.009000 6.756000 0.16055675 0.16960703 #> 7    6  8 -0.1360000 0.15948359 7.009000 6.873000 0.16055675 0.15841042 #> 8    6  9 -0.3230000 0.16124437 7.009000 6.686000 0.16055675 0.16193198 #> 9    6 10 -0.1550000 0.16129245 7.009000 6.854000 0.16055675 0.16202815 #> 10   7  8  0.1170000 0.16400873 6.756000 6.873000 0.16960703 0.15841042 #> 11   7  9 -0.0700000 0.16576951 6.756000 6.686000 0.16960703 0.16193198 #> 12   7 10  0.0980000 0.16581759 6.756000 6.854000 0.16960703 0.16202815 #> 13   8  9 -0.1870000 0.16017120 6.873000 6.686000 0.15841042 0.16193198 #> 14   8 10 -0.0190000 0.16021929 6.873000 6.854000 0.15841042 0.16202815 #> 15   9 10  0.1680000 0.16198007 6.686000 6.854000 0.16193198 0.16202815 #> 16   1  6 -0.7630000 0.19474230 6.362000 5.599000 0.22671752 0.16276707 #> 17   1  7 -1.5660000 0.19949402 6.362000 4.796000 0.22671752 0.17227052 #> 18   1  8 -0.5390000 0.19377309 6.362000 5.823000 0.22671752 0.16082866 #> 19   1  9 -2.4960000 0.19552830 6.362000 3.866000 0.22671752 0.16433909 #> 20   1 10 -2.2280000 0.19554723 6.362000 4.134000 0.22671752 0.16437693 #> 21   6  7 -0.8030000 0.16751880 5.599000 4.796000 0.16276707 0.17227052 #> 22   6  8  0.2240000 0.16179787 5.599000 5.823000 0.16276707 0.16082866 #> 23   6  9 -1.7330000 0.16355308 5.599000 3.866000 0.16276707 0.16433909 #> 24   6 10 -1.4650000 0.16357200 5.599000 4.134000 0.16276707 0.16437693 #> 25   7  8  1.0270000 0.16654959 4.796000 5.823000 0.17227052 0.16082866 #> 26   7  9 -0.9300000 0.16830480 4.796000 3.866000 0.17227052 0.16433909 #> 27   7 10 -0.6620000 0.16832373 4.796000 4.134000 0.17227052 0.16437693 #> 28   8  9 -1.9570000 0.16258387 5.823000 3.866000 0.16082866 0.16433909 #> 29   8 10 -1.6890000 0.16260280 5.823000 4.134000 0.16082866 0.16437693 #> 30   9 10  0.2680000 0.16435801 3.866000 4.134000 0.16433909 0.16437693 #> 31   1  6 -1.1830000 0.19862288 6.262000 5.079000 0.23247437 0.16477139 #> 32   1  7 -1.8460000 0.20339745 6.262000 4.416000 0.23247437 0.17432054 #> 33   1  8 -0.9190000 0.19754157 6.262000 5.343000 0.23247437 0.16260877 #> 34   1  9 -2.6460000 0.19949002 6.262000 3.616000 0.23247437 0.16650567 #> 35   1 10 -2.1780000 0.19942463 6.262000 4.084000 0.23247437 0.16637489 #> 36   6  7 -0.6630000 0.16954596 5.079000 4.416000 0.16477139 0.17432054 #> 37   6  8  0.2640000 0.16369008 5.079000 5.343000 0.16477139 0.16260877 #> 38   6  9 -1.4630000 0.16563853 5.079000 3.616000 0.16477139 0.16650567 #> 39   6 10 -0.9950000 0.16557314 5.079000 4.084000 0.16477139 0.16637489 #> 40   7  8  0.9270000 0.16846465 4.416000 5.343000 0.17432054 0.16260877 #> 41   7  9 -0.8000000 0.17041310 4.416000 3.616000 0.17432054 0.16650567 #> 42   7 10 -0.3320000 0.17034771 4.416000 4.084000 0.17432054 0.16637489 #> 43   8  9 -1.7270000 0.16455722 5.343000 3.616000 0.16260877 0.16650567 #> 44   8 10 -1.2590000 0.16449183 5.343000 4.084000 0.16260877 0.16637489 #> 45   9 10  0.4680000 0.16644028 3.616000 4.084000 0.16650567 0.16637489 #> 46   1  6 -0.8130000 0.20452069 6.052000 5.239000 0.24012258 0.16891879 #> 47   1  7 -1.5760000 0.20905302 6.052000 4.476000 0.24012258 0.17798345 #> 48   1  8 -0.8490000 0.20316418 6.052000 5.203000 0.24012258 0.16620577 #> 49   1  9 -2.4760000 0.20520110 6.052000 3.576000 0.24012258 0.17027961 #> 50   1 10 -2.1380000 0.20492614 6.052000 3.914000 0.24012258 0.16972969 #> 51   6  7 -0.7630000 0.17345112 5.239000 4.476000 0.16891879 0.17798345 #> 52   6  8 -0.0360000 0.16756228 5.239000 5.203000 0.16891879 0.16620577 #> 53   6  9 -1.6630000 0.16959920 5.239000 3.576000 0.16891879 0.17027961 #> 54   6 10 -1.3250000 0.16932424 5.239000 3.914000 0.16891879 0.16972969 #> 55   7  8  0.7270000 0.17209461 4.476000 5.203000 0.17798345 0.16620577 #> 56   7  9 -0.9000000 0.17413153 4.476000 3.576000 0.17798345 0.17027961 #> 57   7 10 -0.5620000 0.17385657 4.476000 3.914000 0.17798345 0.16972969 #> 58   8  9 -1.6270000 0.16824269 5.203000 3.576000 0.16620577 0.17027961 #> 59   8 10 -1.2890000 0.16796773 5.203000 3.914000 0.16620577 0.16972969 #> 60   9 10  0.3380000 0.17000465 3.576000 3.914000 0.17027961 0.16972969 #> 61   1  6 -0.6830000 0.20990399 5.902000 5.219000 0.24781410 0.17199388 #> 62   1  7 -1.7960000 0.21495520 5.902000 4.106000 0.24781410 0.18209630 #> 63   1  8 -1.0790000 0.20855693 5.902000 4.823000 0.24781410 0.16929977 #> 64   1  9 -2.4960000 0.21062464 5.902000 3.406000 0.24781410 0.17343517 #> 65   1 10 -2.1080000 0.21035013 5.902000 3.794000 0.24781410 0.17288616 #> 66   6  7 -1.1130000 0.17704509 5.219000 4.106000 0.17199388 0.18209630 #> 67   6  8 -0.3960000 0.17064683 5.219000 4.823000 0.17199388 0.16929977 #> 68   6  9 -1.8130000 0.17271453 5.219000 3.406000 0.17199388 0.17343517 #> 69   6 10 -1.4250000 0.17244002 5.219000 3.794000 0.17199388 0.17288616 #> 70   7  8  0.7170000 0.17569803 4.106000 4.823000 0.18209630 0.16929977 #> 71   7  9 -0.7000000 0.17776574 4.106000 3.406000 0.18209630 0.17343517 #> 72   7 10 -0.3120000 0.17749123 4.106000 3.794000 0.18209630 0.17288616 #> 73   8  9 -1.4170000 0.17136747 4.823000 3.406000 0.16929977 0.17343517 #> 74   8 10 -1.0290000 0.17109296 4.823000 3.794000 0.16929977 0.17288616 #> 75   9 10  0.3880000 0.17316066 3.406000 3.794000 0.17343517 0.17288616 #> 76   1 15 -0.1000000 0.16282835 6.600000 6.500000 0.16571813 0.15993856 #> 77   1 16  0.1000000 0.16106398 6.600000 6.700000 0.16571813 0.15640983 #> 78   1 17  0.1000000 0.17454336 6.600000 6.700000 0.16571813 0.18336859 #> 79   1 18  0.0000000 0.16841525 6.600000 6.600000 0.16571813 0.17111236 #> 80   1 22 -0.1000000 0.16771188 6.600000 6.500000 0.16571813 0.16970563 #> 81  15 16  0.2000000 0.15817419 6.500000 6.700000 0.15993856 0.15640983 #> 82  15 17  0.2000000 0.17165357 6.500000 6.700000 0.15993856 0.18336859 #> 83  15 18  0.1000000 0.16552546 6.500000 6.600000 0.15993856 0.17111236 #> 84  15 22  0.0000000 0.16482209 6.500000 6.500000 0.15993856 0.16970563 #> 85  16 17  0.0000000 0.16988921 6.700000 6.700000 0.15640983 0.18336859 #> 86  16 18 -0.1000000 0.16376109 6.700000 6.600000 0.15640983 0.17111236 #> 87  16 22 -0.2000000 0.16305773 6.700000 6.500000 0.15640983 0.16970563 #> 88  17 18 -0.1000000 0.17724047 6.700000 6.600000 0.18336859 0.17111236 #> 89  17 22 -0.2000000 0.17653711 6.700000 6.500000 0.18336859 0.16970563 #> 90  18 22 -0.1000000 0.17040899 6.600000 6.500000 0.17111236 0.16970563 #> 91   1 15 -0.9400000 0.16817165 4.390000 3.450000 0.17390525 0.16243804 #> 92   1 16 -0.9600000 0.16903918 4.390000 3.430000 0.17390525 0.16417310 #> 93   1 17  0.1600000 0.17308912 4.390000 4.550000 0.17390525 0.17227298 #> 94   1 18 -1.0600000 0.17193958 4.390000 3.330000 0.17390525 0.16997392 #> 95   1 22 -1.0700000 0.17524543 4.390000 3.320000 0.17390525 0.17658562 #> 96  15 16 -0.0200000 0.16330557 3.450000 3.430000 0.16243804 0.16417310 #> 97  15 17  1.1000000 0.16735551 3.450000 4.550000 0.16243804 0.17227298 #> 98  15 18 -0.1200000 0.16620598 3.450000 3.330000 0.16243804 0.16997392 #> 99  15 22 -0.1300000 0.16951183 3.450000 3.320000 0.16243804 0.17658562 #> 100 16 17  1.1200000 0.16822304 3.430000 4.550000 0.16417310 0.17227298 #> 101 16 18 -0.1000000 0.16707351 3.430000 3.330000 0.16417310 0.16997392 #> 102 16 22 -0.1100000 0.17037936 3.430000 3.320000 0.16417310 0.17658562 #> 103 17 18 -1.2200000 0.17112345 4.550000 3.330000 0.17227298 0.16997392 #> 104 17 22 -1.2300000 0.17442930 4.550000 3.320000 0.17227298 0.17658562 #> 105 18 22 -0.0100000 0.17327977 3.330000 3.320000 0.16997392 0.17658562 #> 106  1 15 -1.4100000 0.17080592 4.410000 3.000000 0.17768641 0.16392544 #> 107  1 16 -1.2300000 0.17207050 4.410000 3.180000 0.17768641 0.16645459 #> 108  1 17 -0.2400000 0.17589726 4.410000 4.170000 0.17768641 0.17410810 #> 109  1 18 -1.4600000 0.17464501 4.410000 2.950000 0.17768641 0.17160362 #> 110  1 22 -1.2500000 0.17854190 4.410000 3.160000 0.17768641 0.17939738 #> 111 15 16  0.1800000 0.16519002 3.000000 3.180000 0.16392544 0.16645459 #> 112 15 17  1.1700000 0.16901677 3.000000 4.170000 0.16392544 0.17410810 #> 113 15 18 -0.0500000 0.16776453 3.000000 2.950000 0.16392544 0.17160362 #> 114 15 22  0.1600000 0.17166141 3.000000 3.160000 0.16392544 0.17939738 #> 115 16 17  0.9900000 0.17028135 3.180000 4.170000 0.16645459 0.17410810 #> 116 16 18 -0.2300000 0.16902910 3.180000 2.950000 0.16645459 0.17160362 #> 117 16 22 -0.0200000 0.17292599 3.180000 3.160000 0.16645459 0.17939738 #> 118 17 18 -1.2200000 0.17285586 4.170000 2.950000 0.17410810 0.17160362 #> 119 17 22 -1.0100000 0.17675274 4.170000 3.160000 0.17410810 0.17939738 #> 120 18 22  0.2100000 0.17550050 2.950000 3.160000 0.17160362 0.17939738 #> 121  1 15 -1.2900000 0.17593980 4.050000 2.760000 0.18398436 0.16789523 #> 122  1 16 -1.1700000 0.17686548 4.050000 2.880000 0.18398436 0.16974660 #> 123  1 17  0.0900000 0.18106920 4.050000 4.140000 0.18398436 0.17815403 #> 124  1 18 -1.2100000 0.17969950 4.050000 2.840000 0.18398436 0.17541465 #> 125  1 22 -1.0800000 0.18374124 4.050000 2.970000 0.18398436 0.18349812 #> 126 15 16  0.1200000 0.16882091 2.760000 2.880000 0.16789523 0.16974660 #> 127 15 17  1.3800000 0.17302463 2.760000 4.140000 0.16789523 0.17815403 #> 128 15 18  0.0800000 0.17165494 2.760000 2.840000 0.16789523 0.17541465 #> 129 15 22  0.2100000 0.17569668 2.760000 2.970000 0.16789523 0.18349812 #> 130 16 17  1.2600000 0.17395031 2.880000 4.140000 0.16974660 0.17815403 #> 131 16 18 -0.0400000 0.17258062 2.880000 2.840000 0.16974660 0.17541465 #> 132 16 22  0.0900000 0.17662236 2.880000 2.970000 0.16974660 0.18349812 #> 133 17 18 -1.3000000 0.17678434 4.140000 2.840000 0.17815403 0.17541465 #> 134 17 22 -1.1700000 0.18082608 4.140000 2.970000 0.17815403 0.18349812 #> 135 18 22  0.1300000 0.17945638 2.840000 2.970000 0.17541465 0.18349812 #> 136  1 15 -1.2800000 0.18006989 3.970000 2.690000 0.18952849 0.17061128 #> 137  1 16 -1.2400000 0.18137242 3.970000 2.730000 0.18952849 0.17321634 #> 138  1 17  0.0200000 0.18542131 3.970000 3.990000 0.18952849 0.18131412 #> 139  1 18 -1.1800000 0.18425675 3.970000 2.790000 0.18952849 0.17898501 #> 140  1 22 -1.0700000 0.18789392 3.970000 2.900000 0.18952849 0.18625935 #> 141 15 16  0.0400000 0.17191381 2.690000 2.730000 0.17061128 0.17321634 #> 142 15 17  1.3000000 0.17596270 2.690000 3.990000 0.17061128 0.18131412 #> 143 15 18  0.1000000 0.17479815 2.690000 2.790000 0.17061128 0.17898501 #> 144 15 22  0.2100000 0.17843532 2.690000 2.900000 0.17061128 0.18625935 #> 145 16 17  1.2600000 0.17726523 2.730000 3.990000 0.17321634 0.18131412 #> 146 16 18  0.0600000 0.17610067 2.730000 2.790000 0.17321634 0.17898501 #> 147 16 22  0.1700000 0.17973785 2.730000 2.900000 0.17321634 0.18625935 #> 148 17 18 -1.2000000 0.18014956 3.990000 2.790000 0.18131412 0.17898501 #> 149 17 22 -1.0900000 0.18378674 3.990000 2.900000 0.18131412 0.18625935 #> 150 18 22  0.1100000 0.18262218 2.790000 2.900000 0.17898501 0.18625935 #> 151  1  2 -0.0233250 0.12723236 5.405620 5.382295 0.12743652 0.12702820 #> 152  1  3 -0.1395300 0.12837232 5.405620 5.266090 0.12743652 0.12930813 #> 153  1  4  0.0000000 0.12750130 5.405620 5.405620 0.12743652 0.12756608 #> 154  1 15  0.1394600 0.12809344 5.405620 5.545080 0.12743652 0.12875036 #> 155  2  3 -0.1162050 0.12816816 5.382295 5.266090 0.12702820 0.12930813 #> 156  2  4  0.0233250 0.12729714 5.382295 5.405620 0.12702820 0.12756608 #> 157  2 15  0.1627850 0.12788928 5.382295 5.545080 0.12702820 0.12875036 #> 158  3  4  0.1395300 0.12843710 5.266090 5.405620 0.12930813 0.12756608 #> 159  3 15  0.2789900 0.12902924 5.266090 5.545080 0.12930813 0.12875036 #> 160  4 15  0.1394600 0.12815822 5.405620 5.545080 0.12756608 0.12875036 #> 161  1  2 -0.6744615 0.13498571 5.020210 4.345749 0.13967062 0.13030080 #> 162  1  3 -1.1977000 0.13598993 5.020210 3.822510 0.13967062 0.13230924 #> 163  1  4 -1.0581015 0.13519756 5.020210 3.962108 0.13967062 0.13072450 #> 164  1 15 -0.8953845 0.13580065 5.020210 4.124826 0.13967062 0.13193069 #> 165  2  3 -0.5232385 0.13130502 4.345749 3.822510 0.13030080 0.13230924 #> 166  2  4 -0.3836400 0.13051265 4.345749 3.962108 0.13030080 0.13072450 #> 167  2 15 -0.2209230 0.13111574 4.345749 4.124826 0.13030080 0.13193069 #> 168  3  4  0.1395985 0.13151687 3.822510 3.962108 0.13230924 0.13072450 #> 169  3 15  0.3023155 0.13211996 3.822510 4.124826 0.13230924 0.13193069 #> 170  4 15  0.1627170 0.13132759 3.962108 4.124826 0.13072450 0.13193069 #> 171  1  2 -0.3953355 0.14630468 4.720889 4.325553 0.15125135 0.14135801 #> 172  1  3 -1.0000335 0.14725310 4.720889 3.720855 0.15125135 0.14325486 #> 173  1  4 -0.7558560 0.14650779 4.720889 3.965032 0.15125135 0.14176423 #> 174  1 15 -0.4535405 0.14719380 4.720889 4.267348 0.15125135 0.14313626 #> 175  2  3 -0.6046980 0.14230643 4.325553 3.720855 0.14135801 0.14325486 #> 176  2  4 -0.3605205 0.14156112 4.325553 3.965032 0.14135801 0.14176423 #> 177  2 15 -0.0582050 0.14224713 4.325553 4.267348 0.14135801 0.14313626 #> 178  3  4  0.2441775 0.14250954 3.720855 3.965032 0.14325486 0.14176423 #> 179  3 15  0.5464930 0.14319556 3.720855 4.267348 0.14325486 0.14313626 #> 180  4 15  0.3023155 0.14245024 3.965032 4.267348 0.14176423 0.14313626 #> 181  1  3 -0.2780000 0.14080128 6.016000 5.738000 0.14637110 0.13523145 #> 182  1 23 -0.0480000 0.14463706 6.016000 5.968000 0.14637110 0.14290302 #> 183  1 24  0.0420000 0.14130904 6.016000 6.058000 0.14637110 0.13624697 #> 184  1 25  0.1080000 0.14924851 6.016000 6.124000 0.14637110 0.15212591 #> 185  3 23  0.2300000 0.13906723 5.738000 5.968000 0.13523145 0.14290302 #> 186  3 24  0.3200000 0.13573921 5.738000 6.058000 0.13523145 0.13624697 #> 187  3 25  0.3860000 0.14367868 5.738000 6.124000 0.13523145 0.15212591 #> 188 23 24  0.0900000 0.13957499 5.968000 6.058000 0.14290302 0.13624697 #> 189 23 25  0.1560000 0.14751446 5.968000 6.124000 0.14290302 0.15212591 #> 190 24 25  0.0660000 0.14418644 6.058000 6.124000 0.13624697 0.15212591 #> 191  1  3 -0.9136600 0.14074292 4.660234 3.746574 0.14174890 0.13973694 #> 192  1 23  0.0408800 0.14094007 4.660234 4.701114 0.14174890 0.14013124 #> 193  1 24 -0.3136340 0.14118000 4.660234 4.346600 0.14174890 0.14061110 #> 194  1 25 -0.3272700 0.14144197 4.660234 4.332964 0.14174890 0.14113504 #> 195  3 23  0.9545400 0.13993409 3.746574 4.701114 0.13973694 0.14013124 #> 196  3 24  0.6000260 0.14017402 3.746574 4.346600 0.13973694 0.14061110 #> 197  3 25  0.5863900 0.14043599 3.746574 4.332964 0.13973694 0.14113504 #> 198 23 24 -0.3545140 0.14037117 4.701114 4.346600 0.14013124 0.14061110 #> 199 23 25 -0.3681500 0.14063314 4.701114 4.332964 0.14013124 0.14113504 #> 200 24 25 -0.0136360 0.14087307 4.346600 4.332964 0.14061110 0.14113504 #> 201  1  3 -0.9818420 0.14275970 4.265908 3.284066 0.14423560 0.14128381 #> 202  1 23 -0.1499980 0.14286712 4.265908 4.115910 0.14423560 0.14149865 #> 203  1 24 -0.2727260 0.14331252 4.265908 3.993182 0.14423560 0.14238944 #> 204  1 25 -0.5727240 0.14328608 4.265908 3.693184 0.14423560 0.14233657 #> 205  3 23  0.8318440 0.14139123 3.284066 4.115910 0.14128381 0.14149865 #> 206  3 24  0.7091160 0.14183662 3.284066 3.993182 0.14128381 0.14238944 #> 207  3 25  0.4091180 0.14181019 3.284066 3.693184 0.14128381 0.14233657 #> 208 23 24 -0.1227280 0.14194404 4.115910 3.993182 0.14149865 0.14238944 #> 209 23 25 -0.4227260 0.14191761 4.115910 3.693184 0.14149865 0.14233657 #> 210 24 25 -0.2999980 0.14236301 3.993182 3.693184 0.14238944 0.14233657 #> 211  1  3 -1.0499940 0.14458812 3.980672 2.930678 0.14662378 0.14255246 #> 212  1 23 -0.3136340 0.14481899 3.980672 3.667038 0.14662378 0.14301421 #> 213  1 24 -0.2181800 0.14526326 3.980672 3.762492 0.14662378 0.14390273 #> 214  1 25 -0.7500240 0.14522939 3.980672 3.230648 0.14662378 0.14383500 #> 215  3 23  0.7363600 0.14278334 2.930678 3.667038 0.14255246 0.14301421 #> 216  3 24  0.8318140 0.14322760 2.930678 3.762492 0.14255246 0.14390273 #> 217  3 25  0.2999700 0.14319373 2.930678 3.230648 0.14255246 0.14383500 #> 218 23 24  0.0954540 0.14345847 3.667038 3.762492 0.14301421 0.14390273 #> 219 23 25 -0.4363900 0.14342460 3.667038 3.230648 0.14301421 0.14383500 #> 220 24 25 -0.5318440 0.14386887 3.762492 3.230648 0.14390273 0.14383500 #> 221  1  3 -1.1318420 0.14967491 3.643174 2.511332 0.15307332 0.14627650 #> 222  1 23 -0.1636360 0.14990828 3.643174 3.479538 0.15307332 0.14674325 #> 223  1 24 -0.3409080 0.15017593 3.643174 3.302266 0.15307332 0.14727855 #> 224  1 25 -0.7636320 0.15030499 3.643174 2.879542 0.15307332 0.14753666 #> 225  3 23  0.9682060 0.14650988 2.511332 3.479538 0.14627650 0.14674325 #> 226  3 24  0.7909340 0.14677752 2.511332 3.302266 0.14627650 0.14727855 #> 227  3 25  0.3682100 0.14690658 2.511332 2.879542 0.14627650 0.14753666 #> 228 23 24 -0.1772720 0.14701090 3.479538 3.302266 0.14674325 0.14727855 #> 229 23 25 -0.5999960 0.14713996 3.479538 2.879542 0.14674325 0.14753666 #> 230 24 25 -0.4227240 0.14740760 3.302266 2.879542 0.14727855 0.14753666 #> 231  1  3 -0.7363600 0.15362766 3.292040 2.555680 0.15809206 0.14916326 #> 232  1 23  0.3136060 0.15404152 3.292040 3.605646 0.15809206 0.14999098 #> 233  1 24 -0.0681820 0.15443382 3.292040 3.223858 0.15809206 0.15077558 #> 234  1 25 -0.4636340 0.15436797 3.292040 2.828406 0.15809206 0.15064388 #> 235  3 23  1.0499660 0.14957712 2.555680 3.605646 0.14916326 0.14999098 #> 236  3 24  0.6681780 0.14996942 2.555680 3.223858 0.14916326 0.15077558 #> 237  3 25  0.2727260 0.14990357 2.555680 2.828406 0.14916326 0.15064388 #> 238 23 24 -0.3817880 0.15038328 3.605646 3.223858 0.14999098 0.15077558 #> 239 23 25 -0.7772400 0.15031743 3.605646 2.828406 0.14999098 0.15064388 #> 240 24 25 -0.3954520 0.15070973 3.223858 2.828406 0.15077558 0.15064388 #> 241  1  3 -0.7227220 0.15740857 3.268146 2.545424 0.16279536 0.15202178 #> 242  1 23  0.0818480 0.15768694 3.268146 3.349994 0.16279536 0.15257853 #> 243  1 24 -0.0272720 0.15808295 3.268146 3.240874 0.16279536 0.15337054 #> 244  1 25 -0.4909060 0.15802378 3.268146 2.777240 0.16279536 0.15325220 #> 245  3 23  0.8045700 0.15230015 2.545424 3.349994 0.15202178 0.15257853 #> 246  3 24  0.6954500 0.15269616 2.545424 3.240874 0.15202178 0.15337054 #> 247  3 25  0.2318160 0.15263699 2.545424 2.777240 0.15202178 0.15325220 #> 248 23 24 -0.1091200 0.15297453 3.349994 3.240874 0.15257853 0.15337054 #> 249 23 25 -0.5727540 0.15291536 3.349994 2.777240 0.15257853 0.15325220 #> 250 24 25 -0.4636340 0.15331137 3.240874 2.777240 0.15337054 0.15325220 #> 251  1 23  0.0460000 0.13635780 6.118000 6.164000 0.13298113 0.13973447 #> 252  1 24  0.1860000 0.13166450 6.118000 6.304000 0.13298113 0.13034787 #> 253  1 25 -0.1860000 0.13441535 6.118000 5.932000 0.13298113 0.13584957 #> 254  1 26 -0.1580000 0.13241765 6.118000 5.960000 0.13298113 0.13185418 #> 255 23 24  0.1400000 0.13504117 6.164000 6.304000 0.13973447 0.13034787 #> 256 23 25 -0.2320000 0.13779202 6.164000 5.932000 0.13973447 0.13584957 #> 257 23 26 -0.2040000 0.13579433 6.164000 5.960000 0.13973447 0.13185418 #> 258 24 25 -0.3720000 0.13309872 6.304000 5.932000 0.13034787 0.13584957 #> 259 24 26 -0.3440000 0.13110102 6.304000 5.960000 0.13034787 0.13185418 #> 260 25 26  0.0280000 0.13385187 5.932000 5.960000 0.13584957 0.13185418 #> 261  1 23 -0.2520000 0.13356838 5.278000 5.026000 0.13368325 0.13345351 #> 262  1 24 -0.2480000 0.13373965 5.278000 5.030000 0.13368325 0.13379605 #> 263  1 25 -0.7440000 0.13374725 5.278000 4.534000 0.13368325 0.13381126 #> 264  1 26 -0.6000000 0.13359101 5.278000 4.678000 0.13368325 0.13349877 #> 265 23 24  0.0040000 0.13362478 5.026000 5.030000 0.13345351 0.13379605 #> 266 23 25 -0.4920000 0.13363238 5.026000 4.534000 0.13345351 0.13381126 #> 267 23 26 -0.3480000 0.13347614 5.026000 4.678000 0.13345351 0.13349877 #> 268 24 25 -0.4960000 0.13380366 5.030000 4.534000 0.13379605 0.13381126 #> 269 24 26 -0.3520000 0.13364741 5.030000 4.678000 0.13379605 0.13349877 #> 270 25 26  0.1440000 0.13365502 4.534000 4.678000 0.13381126 0.13349877 #> 271  1 23 -0.1800000 0.13569724 4.846000 4.666000 0.13645321 0.13494127 #> 272  1 24 -0.3480000 0.13590599 4.846000 4.498000 0.13645321 0.13535877 #> 273  1 25 -0.7700000 0.13594255 4.846000 4.076000 0.13645321 0.13543190 #> 274  1 26 -0.6160000 0.13574792 4.846000 4.230000 0.13645321 0.13504263 #> 275 23 24 -0.1680000 0.13515002 4.666000 4.498000 0.13494127 0.13535877 #> 276 23 25 -0.5900000 0.13518659 4.666000 4.076000 0.13494127 0.13543190 #> 277 23 26 -0.4360000 0.13499195 4.666000 4.230000 0.13494127 0.13504263 #> 278 24 25 -0.4220000 0.13539534 4.498000 4.076000 0.13535877 0.13543190 #> 279 24 26 -0.2680000 0.13520070 4.498000 4.230000 0.13535877 0.13504263 #> 280 25 26  0.1540000 0.13523726 4.076000 4.230000 0.13543190 0.13504263 #> 281  1 23 -0.3000000 0.13751398 4.746000 4.446000 0.13873236 0.13629561 #> 282  1 24 -0.4460000 0.13785391 4.746000 4.300000 0.13873236 0.13697546 #> 283  1 25 -0.8260000 0.13766931 4.746000 3.920000 0.13873236 0.13660626 #> 284  1 26 -0.8480000 0.13759315 4.746000 3.898000 0.13873236 0.13645394 #> 285 23 24 -0.1460000 0.13663553 4.446000 4.300000 0.13629561 0.13697546 #> 286 23 25 -0.5260000 0.13645094 4.446000 3.920000 0.13629561 0.13660626 #> 287 23 26 -0.5480000 0.13637477 4.446000 3.898000 0.13629561 0.13645394 #> 288 24 25 -0.3800000 0.13679086 4.300000 3.920000 0.13697546 0.13660626 #> 289 24 26 -0.4020000 0.13671470 4.300000 3.898000 0.13697546 0.13645394 #> 290 25 26 -0.0220000 0.13653010 3.920000 3.898000 0.13660626 0.13645394 #> 291  1 23 -0.4620000 0.14255895 4.576000 4.114000 0.14503567 0.14008223 #> 292  1 24 -0.4040000 0.14275582 4.576000 4.172000 0.14503567 0.14047598 #> 293  1 25 -0.7860000 0.14268059 4.576000 3.790000 0.14503567 0.14032551 #> 294  1 26 -0.8760000 0.14249088 4.576000 3.700000 0.14503567 0.13994609 #> 295 23 24  0.0580000 0.14027910 4.114000 4.172000 0.14008223 0.14047598 #> 296 23 25 -0.3240000 0.14020387 4.114000 3.790000 0.14008223 0.14032551 #> 297 23 26 -0.4140000 0.14001416 4.114000 3.700000 0.14008223 0.13994609 #> 298 24 25 -0.3820000 0.14040074 4.172000 3.790000 0.14047598 0.14032551 #> 299 24 26 -0.4720000 0.14021103 4.172000 3.700000 0.14047598 0.13994609 #> 300 25 26 -0.0900000 0.14013580 3.790000 3.700000 0.14032551 0.13994609 #> 301  1 23 -0.5520000 0.14660262 4.604000 4.052000 0.14996109 0.14324415 #> 302  1 24 -0.4500000 0.14674173 4.604000 4.154000 0.14996109 0.14352237 #> 303  1 25 -0.7420000 0.14687378 4.604000 3.862000 0.14996109 0.14378647 #> 304  1 26 -0.8960000 0.14650890 4.604000 3.708000 0.14996109 0.14305671 #> 305 23 24  0.1020000 0.14338326 4.052000 4.154000 0.14324415 0.14352237 #> 306 23 25 -0.1900000 0.14351531 4.052000 3.862000 0.14324415 0.14378647 #> 307 23 26 -0.3440000 0.14315043 4.052000 3.708000 0.14324415 0.14305671 #> 308 24 25 -0.2920000 0.14365442 4.154000 3.862000 0.14352237 0.14378647 #> 309 24 26 -0.4460000 0.14328954 4.154000 3.708000 0.14352237 0.14305671 #> 310 25 26 -0.1540000 0.14342159 3.862000 3.708000 0.14378647 0.14305671 #> 311  1 23 -0.6140000 0.15024935 4.634000 4.020000 0.15451115 0.14598755 #> 312  1 24 -0.5600000 0.15032219 4.634000 4.074000 0.15451115 0.14613323 #> 313  1 25 -0.7800000 0.15037947 4.634000 3.854000 0.15451115 0.14624779 #> 314  1 26 -0.8300000 0.15018821 4.634000 3.804000 0.15451115 0.14586527 #> 315 23 24  0.0540000 0.14606039 4.020000 4.074000 0.14598755 0.14613323 #> 316 23 25 -0.1660000 0.14611767 4.020000 3.854000 0.14598755 0.14624779 #> 317 23 26 -0.2160000 0.14592641 4.020000 3.804000 0.14598755 0.14586527 #> 318 24 25 -0.2200000 0.14619051 4.074000 3.854000 0.14613323 0.14624779 #> 319 24 26 -0.2700000 0.14599925 4.074000 3.804000 0.14613323 0.14586527 #> 320 25 26 -0.0500000 0.14605653 3.854000 3.804000 0.14624779 0.14586527 #> 321  1  2 -0.0523950 0.11369034 5.296405 5.244010 0.11365985 0.11372082 #> 322  1  3  0.0074850 0.11480580 5.296405 5.303890 0.11365985 0.11595175 #> 323  1  4  0.1197650 0.11399197 5.296405 5.416170 0.11365985 0.11432410 #> 324  1 15 -0.0299400 0.11476825 5.296405 5.266465 0.11365985 0.11587666 #> 325  2  3  0.0598800 0.11483629 5.244010 5.303890 0.11372082 0.11595175 #> 326  2  4  0.1721600 0.11402246 5.244010 5.416170 0.11372082 0.11432410 #> 327  2 15  0.0224550 0.11479874 5.244010 5.266465 0.11372082 0.11587666 #> 328  3  4  0.1122800 0.11513793 5.303890 5.416170 0.11595175 0.11432410 #> 329  3 15 -0.0374250 0.11591421 5.303890 5.266465 0.11595175 0.11587666 #> 330  4 15 -0.1497050 0.11510038 5.416170 5.266465 0.11432410 0.11587666 #> 331  1  2 -0.5988025 0.13746929 4.997006 4.398204 0.12490734 0.15003125 #> 332  1  3 -0.9505990 0.12213665 4.997006 4.046407 0.12490734 0.11936596 #> 333  1  4 -0.8607785 0.12132247 4.997006 4.136228 0.12490734 0.11773760 #> 334  1 15 -1.1002995 0.10241893 4.997006 3.896707 0.12490734 0.07993053 #> 335  2  3 -0.3517965 0.13469860 4.398204 4.046407 0.15003125 0.11936596 #> 336  2  4 -0.2619760 0.13388442 4.398204 4.136228 0.15003125 0.11773760 #> 337  2 15 -0.5014970 0.11498089 4.398204 3.896707 0.15003125 0.07993053 #> 338  3  4  0.0898205 0.11855178 4.046407 4.136228 0.11936596 0.11773760 #> 339  3 15 -0.1497005 0.09964824 4.046407 3.896707 0.11936596 0.07993053 #> 340  4 15 -0.2395210 0.09883406 4.136228 3.896707 0.11773760 0.07993053 #> 341  1  2 -0.3667660 0.14748225 4.862275 4.495509 0.14493324 0.15003125 #> 342  1  3 -0.6062870 0.13753193 4.862275 4.255988 0.14493324 0.13013062 #> 343  1  4 -0.6137725 0.13658798 4.862275 4.248502 0.14493324 0.12824272 #> 344  1 15 -0.8682630 0.11747098 4.862275 3.994012 0.14493324 0.09000872 #> 345  2  3 -0.2395210 0.14008094 4.495509 4.255988 0.15003125 0.13013062 #> 346  2  4 -0.2470065 0.13913698 4.495509 4.248502 0.15003125 0.12824272 #> 347  2 15 -0.5014970 0.12001998 4.495509 3.994012 0.15003125 0.09000872 #> 348  3  4 -0.0074855 0.12918667 4.255988 4.248502 0.13013062 0.12824272 #> 349  3 15 -0.2619760 0.11006967 4.255988 3.994012 0.13013062 0.09000872 #> 350  4 15 -0.2544905 0.10912572 4.248502 3.994012 0.12824272 0.09000872 #> 351  1 15 -0.0500000 0.12002485 5.400000 5.350000 0.11993228 0.12011743 #> 352  1 27  0.1000000 0.11990698 5.400000 5.500000 0.11993228 0.11988167 #> 353  1 28 -0.0500000 0.12044472 5.400000 5.350000 0.11993228 0.12095716 #> 354  1 29  0.0000000 0.12050259 5.400000 5.400000 0.11993228 0.12107291 #> 355 15 27  0.1500000 0.11999955 5.350000 5.500000 0.12011743 0.11988167 #> 356 15 28  0.0000000 0.12053729 5.350000 5.350000 0.12011743 0.12095716 #> 357 15 29  0.0500000 0.12059517 5.350000 5.400000 0.12011743 0.12107291 #> 358 27 28 -0.1500000 0.12041942 5.500000 5.350000 0.11988167 0.12095716 #> 359 27 29 -0.1000000 0.12047729 5.500000 5.400000 0.11988167 0.12107291 #> 360 28 29  0.0500000 0.12101503 5.350000 5.400000 0.12095716 0.12107291 #> 361  1 15 -0.5000000 0.12421366 4.450000 3.950000 0.12534348 0.12308383 #> 362  1 27 -0.5000000 0.12418605 4.450000 3.950000 0.12534348 0.12302862 #> 363  1 28 -0.5500000 0.12495637 4.450000 3.900000 0.12534348 0.12456927 #> 364  1 29 -0.3500000 0.12471152 4.450000 4.100000 0.12534348 0.12407956 #> 365 15 27  0.0000000 0.12305623 3.950000 3.950000 0.12308383 0.12302862 #> 366 15 28 -0.0500000 0.12382655 3.950000 3.900000 0.12308383 0.12456927 #> 367 15 29  0.1500000 0.12358170 3.950000 4.100000 0.12308383 0.12407956 #> 368 27 28 -0.0500000 0.12379894 3.950000 3.900000 0.12302862 0.12456927 #> 369 27 29  0.1500000 0.12355409 3.950000 4.100000 0.12302862 0.12407956 #> 370 28 29  0.2000000 0.12432441 3.900000 4.100000 0.12456927 0.12407956 #> 371  1 15 -0.4000000 0.13118728 4.200000 3.800000 0.13397271 0.12840184 #> 372  1 27 -0.2500000 0.13094764 4.200000 3.950000 0.13397271 0.12792257 #> 373  1 28 -0.5000000 0.13163671 4.200000 3.700000 0.13397271 0.12930072 #> 374  1 29 -0.3500000 0.13171602 4.200000 3.850000 0.13397271 0.12945933 #> 375 15 27  0.1500000 0.12816221 3.800000 3.950000 0.12840184 0.12792257 #> 376 15 28 -0.1000000 0.12885128 3.800000 3.700000 0.12840184 0.12930072 #> 377 15 29  0.0500000 0.12893059 3.800000 3.850000 0.12840184 0.12945933 #> 378 27 28 -0.2500000 0.12861164 3.950000 3.700000 0.12792257 0.12930072 #> 379 27 29 -0.1000000 0.12869095 3.950000 3.850000 0.12792257 0.12945933 #> 380 28 29  0.1500000 0.12938002 3.700000 3.850000 0.12930072 0.12945933 #> 381  1 15 -0.4500000 0.13895979 4.150000 3.700000 0.14364307 0.13427651 #> 382  1 27 -0.2000000 0.13871312 4.150000 3.950000 0.14364307 0.13378317 #> 383  1 28 -0.4500000 0.13940422 4.150000 3.700000 0.14364307 0.13516536 #> 384  1 29 -0.3500000 0.13954039 4.150000 3.800000 0.14364307 0.13543772 #> 385 15 27  0.2500000 0.13402984 3.700000 3.950000 0.13427651 0.13378317 #> 386 15 28  0.0000000 0.13472094 3.700000 3.700000 0.13427651 0.13516536 #> 387 15 29  0.1000000 0.13485711 3.700000 3.800000 0.13427651 0.13543772 #> 388 27 28 -0.2500000 0.13447427 3.950000 3.700000 0.13378317 0.13516536 #> 389 27 29 -0.1500000 0.13461044 3.950000 3.800000 0.13378317 0.13543772 #> 390 28 29  0.1000000 0.13530154 3.700000 3.800000 0.13516536 0.13543772 #> 391  1 23 -0.2580000 0.13697594 6.014000 5.756000 0.11866399 0.15528789 #> 392  1 24 -0.3380000 0.13831437 6.014000 5.676000 0.11866399 0.15796474 #> 393  1 25  0.2740000 0.15409189 6.014000 6.288000 0.11866399 0.18951979 #> 394 23 24 -0.0800000 0.15662632 5.756000 5.676000 0.15528789 0.15796474 #> 395 23 25  0.5320000 0.17240384 5.756000 6.288000 0.15528789 0.18951979 #> 396 24 25  0.6120000 0.17374227 5.676000 6.288000 0.15796474 0.18951979 #> 397  1 23 -0.7099740 0.16418722 4.071478 3.361504 0.13816027 0.19021417 #> 398  1 24 -0.8248060 0.16282018 4.071478 3.246672 0.13816027 0.18748009 #> 399  1 25 -0.6759580 0.16332221 4.071478 3.395520 0.13816027 0.18848415 #> 400 23 24 -0.1148320 0.18884713 3.361504 3.246672 0.19021417 0.18748009 #> 401 23 25  0.0340160 0.18934916 3.361504 3.395520 0.19021417 0.18848415 #> 402 24 25  0.1488480 0.18798212 3.246672 3.395520 0.18748009 0.18848415 #> 403  1  3  0.2000000 0.09390836 4.950000 5.150000 0.10856203 0.07925469 #> 404  1 12  0.2000000 0.09196563 4.950000 5.150000 0.10856203 0.07536922 #> 405  1 13  0.0000000 0.09355150 4.950000 4.950000 0.10856203 0.07854096 #> 406  3 12  0.0000000 0.07731196 5.150000 5.150000 0.07925469 0.07536922 #> 407  3 13 -0.2000000 0.07889783 5.150000 4.950000 0.07925469 0.07854096 #> 408 12 13 -0.2000000 0.07695509 5.150000 4.950000 0.07536922 0.07854096 #> 409  1  3 -0.4500000 0.09777980 4.150000 3.700000 0.11449208 0.08106751 #> 410  1 12 -0.5500000 0.09709406 4.150000 3.600000 0.11449208 0.07969604 #> 411  1 13 -0.7500000 0.09700967 4.150000 3.400000 0.11449208 0.07952726 #> 412  3 12 -0.1000000 0.08038178 3.700000 3.600000 0.08106751 0.07969604 #> 413  3 13 -0.3000000 0.08029738 3.700000 3.400000 0.08106751 0.07952726 #> 414 12 13 -0.2000000 0.07961165 3.600000 3.400000 0.07969604 0.07952726 #> 415  1  3 -0.4000000 0.11094868 3.800000 3.400000 0.13292276 0.08897460 #> 416  1 12 -0.5000000 0.11009387 3.800000 3.300000 0.13292276 0.08726499 #> 417  1 13 -0.7000000 0.11012502 3.800000 3.100000 0.13292276 0.08732728 #> 418  3 12 -0.1000000 0.08811979 3.400000 3.300000 0.08897460 0.08726499 #> 419  3 13 -0.3000000 0.08815094 3.400000 3.100000 0.08897460 0.08732728 #> 420 12 13 -0.2000000 0.08729613 3.300000 3.100000 0.08726499 0.08732728 #> 421  1  3  0.2000000 0.07825340 4.900000 5.100000 0.07770287 0.07880393 #> 422  1 11  0.0500000 0.07825340 4.900000 4.950000 0.07770287 0.07880393 #> 423  1 12  0.0500000 0.07776545 4.900000 4.950000 0.07770287 0.07782803 #> 424  3 11 -0.1500000 0.07880393 5.100000 4.950000 0.07880393 0.07880393 #> 425  3 12 -0.1500000 0.07831598 5.100000 4.950000 0.07880393 0.07782803 #> 426 11 12  0.0000000 0.07831598 4.950000 4.950000 0.07880393 0.07782803 #> 427  1  3 -0.5000000 0.08176848 4.350000 3.850000 0.08237490 0.08116206 #> 428  1 11 -0.6000000 0.08180870 4.350000 3.750000 0.08237490 0.08124250 #> 429  1 12 -0.4500000 0.08175051 4.350000 3.900000 0.08237490 0.08112612 #> 430  3 11 -0.1000000 0.08120228 3.850000 3.750000 0.08116206 0.08124250 #> 431  3 12  0.0500000 0.08114409 3.850000 3.900000 0.08116206 0.08112612 #> 432 11 12  0.1500000 0.08118431 3.750000 3.900000 0.08124250 0.08112612 #> 433  1  3 -0.2500000 0.09256603 3.650000 3.400000 0.09589396 0.08923811 #> 434  1 11 -0.4000000 0.09256265 3.650000 3.250000 0.09589396 0.08923133 #> 435  1 12 -0.3000000 0.09255146 3.650000 3.350000 0.09589396 0.08920896 #> 436  3 11 -0.1500000 0.08923472 3.400000 3.250000 0.08923811 0.08923133 #> 437  3 12 -0.0500000 0.08922353 3.400000 3.350000 0.08923811 0.08920896 #> 438 11 12  0.1000000 0.08922015 3.250000 3.350000 0.08923133 0.08920896 #> 439  1 15 -0.1140000 0.11024929 7.215000 7.101000 0.10649083 0.11400775 #> 440  1 16  0.1010000 0.10246817 7.215000 7.316000 0.10649083 0.09844550 #> 441  1 18  0.1430000 0.10288415 7.215000 7.358000 0.10649083 0.09927747 #> 442 15 16  0.2150000 0.10622663 7.101000 7.316000 0.11400775 0.09844550 #> 443 15 18  0.2570000 0.10664261 7.101000 7.358000 0.11400775 0.09927747 #> 444 16 18  0.0420000 0.09886149 7.316000 7.358000 0.09844550 0.09927747 #> 445  1 15 -1.3940000 0.11158213 5.265000 3.871000 0.11319620 0.10996805 #> 446  1 16 -1.2490000 0.11119308 5.265000 4.016000 0.11319620 0.10918995 #> 447  1 18 -0.6370000 0.10992883 5.265000 4.628000 0.11319620 0.10666145 #> 448 15 16  0.1450000 0.10957900 3.871000 4.016000 0.10996805 0.10918995 #> 449 15 18  0.7570000 0.10831475 3.871000 4.628000 0.10996805 0.10666145 #> 450 16 18  0.6120000 0.10792570 4.016000 4.628000 0.10918995 0.10666145 #> 451  1 15 -1.3940000 0.11798808 4.945000 3.551000 0.12136624 0.11460991 #> 452  1 16 -1.3990000 0.11755586 4.945000 3.546000 0.12136624 0.11374548 #> 453  1 18 -0.8270000 0.11634858 4.945000 4.118000 0.12136624 0.11133092 #> 454 15 16 -0.0050000 0.11417770 3.551000 3.546000 0.11460991 0.11374548 #> 455 15 18  0.5670000 0.11297042 3.551000 4.118000 0.11460991 0.11133092 #> 456 16 18  0.5720000 0.11253820 3.546000 4.118000 0.11374548 0.11133092 #> 457  1 15 -1.3240000 0.12630932 4.655000 3.331000 0.13216957 0.12044908 #> 458  1 16 -1.0590000 0.12607879 4.655000 3.596000 0.13216957 0.11998801 #> 459  1 18 -0.7370000 0.12479121 4.655000 3.918000 0.13216957 0.11741286 #> 460 15 16  0.2650000 0.12021854 3.331000 3.596000 0.12044908 0.11998801 #> 461 15 18  0.5870000 0.11893097 3.331000 3.918000 0.12044908 0.11741286 #> 462 16 18  0.3220000 0.11870043 3.596000 3.918000 0.11998801 0.11741286 #> 463  1  3 -0.1000000 0.07782541 5.500000 5.400000 0.07393263 0.08171819 #> 464  1 11 -0.1000000 0.07603332 5.500000 5.400000 0.07393263 0.07813401 #> 465  1 14 -0.1000000 0.07735586 5.500000 5.400000 0.07393263 0.08077908 #> 466  3 11  0.0000000 0.07992610 5.400000 5.400000 0.08171819 0.07813401 #> 467  3 14  0.0000000 0.08124863 5.400000 5.400000 0.08171819 0.08077908 #> 468 11 14  0.0000000 0.07945654 5.400000 5.400000 0.07813401 0.08077908 #> 469  1  3 -0.6500000 0.09421929 4.350000 3.700000 0.09856959 0.08986899 #> 470  1 11 -0.7500000 0.09439801 4.350000 3.600000 0.09856959 0.09022642 #> 471  1 14 -0.8000000 0.09461391 4.350000 3.550000 0.09856959 0.09065824 #> 472  3 11 -0.1000000 0.09004771 3.700000 3.600000 0.08986899 0.09022642 #> 473  3 14 -0.1500000 0.09026362 3.700000 3.550000 0.08986899 0.09065824 #> 474 11 14 -0.0500000 0.09044233 3.600000 3.550000 0.09022642 0.09065824 #> 475  1  3 -0.1000000 0.08572928 5.150000 5.050000 0.09622504 0.07523352 #> 476  1 12 -0.1000000 0.08662970 5.150000 5.050000 0.09622504 0.07703435 #> 477  1 13 -0.1500000 0.08534425 5.150000 5.000000 0.09622504 0.07446346 #> 478  3 12  0.0000000 0.07613394 5.050000 5.050000 0.07523352 0.07703435 #> 479  3 13 -0.0500000 0.07484849 5.050000 5.000000 0.07523352 0.07446346 #> 480 12 13 -0.0500000 0.07574891 5.050000 5.000000 0.07703435 0.07446346 #> 481  1  3 -0.6000000 0.09411812 4.450000 3.850000 0.11095877 0.07727746 #> 482  1 12 -0.7000000 0.09397274 4.450000 3.750000 0.11095877 0.07698671 #> 483  1 13 -0.7500000 0.09372504 4.450000 3.700000 0.11095877 0.07649130 #> 484  3 12 -0.1000000 0.07713209 3.850000 3.750000 0.07727746 0.07698671 #> 485  3 13 -0.1500000 0.07688438 3.850000 3.700000 0.07727746 0.07649130 #> 486 12 13 -0.0500000 0.07673901 3.750000 3.700000 0.07698671 0.07649130 #> 487  1  3 -0.4500000 0.10684547 3.950000 3.500000 0.12879815 0.08489279 #> 488  1 12 -0.5000000 0.10661317 3.950000 3.450000 0.12879815 0.08442820 #> 489  1 13 -0.5500000 0.10646593 3.950000 3.400000 0.12879815 0.08413371 #> 490  3 12 -0.0500000 0.08466049 3.500000 3.450000 0.08489279 0.08442820 #> 491  3 13 -0.1000000 0.08451325 3.500000 3.400000 0.08489279 0.08413371 #> 492 12 13 -0.0500000 0.08428095 3.450000 3.400000 0.08442820 0.08413371 #> 493  1 15 -0.1490000 0.10675878 6.548000 6.399000 0.08613561 0.12738195 #> 494  1 16  0.0770000 0.08808455 6.548000 6.625000 0.08613561 0.09003349 #> 495 15 16  0.2260000 0.10870772 6.399000 6.625000 0.12738195 0.09003349 #> 496  1 15 -1.3690000 0.11327226 5.398000 4.029000 0.09317367 0.13337086 #> 497  1 16 -0.9630000 0.09287718 5.398000 4.435000 0.09317367 0.09258069 #> 498 15 16  0.4060000 0.11297578 4.029000 4.435000 0.13337086 0.09258069 #> 499  1 15 -1.2490000 0.11915230 4.968000 3.719000 0.09969241 0.13861218 #> 500  1 16 -0.8830000 0.09807585 4.968000 4.085000 0.09969241 0.09645929 #> 501 15 16  0.3660000 0.11753573 3.719000 4.085000 0.13861218 0.09645929 #> 502  1 15 -0.7830000 0.12748552 4.751000 3.968000 0.10850034 0.14647069 #> 503  1 16 -0.7070000 0.10512964 4.751000 4.044000 0.10850034 0.10175895 #> 504 15 16  0.0760000 0.12411482 3.968000 4.044000 0.14647069 0.10175895 #> 505  1  3  0.0900000 0.12437464 6.660000 6.750000 0.14375175 0.10499753 #> 506  1  7  0.0800000 0.12516996 6.660000 6.740000 0.14375175 0.10658817 #> 507  3  7 -0.0100000 0.10579285 6.750000 6.740000 0.10499753 0.10658817 #> 508  1  3 -1.2987705 0.13095036 5.905123 4.606352 0.15295812 0.10894260 #> 509  1  7 -1.6598215 0.13209492 5.905123 4.245301 0.15295812 0.11123171 #> 510  3  7 -0.3610510 0.11008716 4.606352 4.245301 0.10894260 0.11123171 #> 511  1  3 -1.3268670 0.13506309 5.597386 4.270519 0.15878729 0.11133890 #> 512  1  7 -1.5756380 0.13632510 5.597386 4.021748 0.15878729 0.11386291 #> 513  3  7 -0.2487710 0.11260091 4.270519 4.021748 0.11133890 0.11386291 #> 514  1  3 -1.0743180 0.14188306 5.374769 4.300451 0.16812945 0.11563667 #> 515  1  7 -1.3371910 0.14307904 5.374769 4.037578 0.16812945 0.11802862 #> 516  3  7 -0.2628730 0.11683265 4.300451 4.037578 0.11563667 0.11802862 #> 517  1  3 -0.8497570 0.14758421 5.124054 4.274297 0.17621052 0.11895791 #> 518  1  7 -1.2248030 0.14888977 5.124054 3.899251 0.17621052 0.12156902 #> 519  3  7 -0.3750460 0.12026346 4.274297 3.899251 0.11895791 0.12156902 #> 520  1  3  0.0900000 0.13945842 6.640000 6.730000 0.15968999 0.11922685 #> 521  1  7  0.2300000 0.13244802 6.640000 6.870000 0.15968999 0.10520605 #> 522  3  7  0.1400000 0.11221645 6.730000 6.870000 0.11922685 0.10520605 #> 523  1  3 -1.1352320 0.14236403 5.519577 4.384345 0.17109473 0.11363334 #> 524  1  7 -1.0538110 0.14269630 5.519577 4.465766 0.17109473 0.11429788 #> 525  3  7  0.0814210 0.11396561 4.384345 4.465766 0.11363334 0.11429788 #> 526  1  3 -0.9601670 0.14671279 5.097473 4.137306 0.17758313 0.11584245 #> 527  1  7 -0.8641570 0.14715385 5.097473 4.233316 0.17758313 0.11672457 #> 528  3  7  0.0960100 0.11628351 4.137306 4.233316 0.11584245 0.11672457 #> 529  1  3 -0.9893070 0.15356265 5.011880 4.022573 0.18711207 0.12001322 #> 530  1  7 -0.9225120 0.15399184 5.011880 4.089368 0.18711207 0.12087161 #> 531  3  7  0.0667950 0.12044241 4.022573 4.089368 0.12001322 0.12087161 #> 532  1  3 -1.0623260 0.15962039 4.999232 3.936906 0.19569508 0.12354571 #> 533  1  7 -0.9079610 0.16001683 4.999232 4.091271 0.19569508 0.12433858 #> 534  3  7  0.1543650 0.12394214 3.936906 4.091271 0.12354571 0.12433858 #> 535  1  3 -0.0200000 0.16408093 6.850000 6.830000 0.19248710 0.13567477 #> 536  1 20  0.2000000 0.15909382 6.850000 7.050000 0.19248710 0.12570054 #> 537  3 20  0.2200000 0.13068765 6.830000 7.050000 0.13567477 0.12570054 #> 538  1  3 -0.7600000 0.16780705 5.050000 4.290000 0.19825783 0.13735626 #> 539  1 20 -0.4000000 0.16703645 5.050000 4.650000 0.19825783 0.13581507 #> 540  3 20  0.3600000 0.13658566 4.290000 4.650000 0.13735626 0.13581507 #> 541  1  3 -0.8100000 0.17283334 4.900000 4.090000 0.20546535 0.14020133 #> 542  1 20 -0.5400000 0.17232798 4.900000 4.360000 0.20546535 0.13919061 #> 543  3 20  0.2700000 0.13969597 4.090000 4.360000 0.14020133 0.13919061 #> 544  1  3 -0.8100000 0.17747931 4.740000 3.930000 0.21210711 0.14285150 #> 545  1 20 -0.5500000 0.17687103 4.740000 4.190000 0.21210711 0.14163496 #> 546  3 20  0.2600000 0.14224323 3.930000 4.190000 0.14285150 0.14163496 #> 547  1  3 -0.1900000 0.16198786 6.870000 6.680000 0.19089880 0.13307692 #> 548  1 20 -0.1700000 0.15889353 6.870000 6.700000 0.19089880 0.12688825 #> 549  3 20  0.0200000 0.12998259 6.680000 6.700000 0.13307692 0.12688825 #> 550  1  3 -0.7400000 0.16316042 4.930000 4.190000 0.19254502 0.13377582 #> 551  1 20 -1.2100000 0.16546241 4.930000 3.720000 0.19254502 0.13837981 #> 552  3 20 -0.4700000 0.13607781 4.190000 3.720000 0.13377582 0.13837981 #> 553  1  3 -1.0600000 0.16797515 4.760000 3.700000 0.19892926 0.13702105 #> 554  1 20 -1.0400000 0.17015955 4.760000 3.720000 0.19892926 0.14138984 #> 555  3 20  0.0200000 0.13920544 3.700000 3.720000 0.13702105 0.14138984 #> 556  1  3 -1.0500000 0.17291585 4.590000 3.540000 0.20627513 0.13955657 #> 557  1 20 -0.9700000 0.17518877 4.590000 3.620000 0.20627513 0.14410240 #> 558  3 20  0.0800000 0.14182949 3.540000 3.620000 0.13955657 0.14410240 #> 559  1 21 -0.0590000 0.20030464 6.003000 5.944000 0.20107522 0.19953406 #> 560  1 22  0.4330000 0.20053629 6.003000 6.436000 0.20107522 0.19999737 #> 561 21 22  0.4920000 0.19976572 5.944000 6.436000 0.19953406 0.19999737 #> 562  1 21 -2.1590000 0.20422009 5.643000 3.484000 0.20685093 0.20158925 #> 563  1 22 -1.4970000 0.20520553 5.643000 4.146000 0.20685093 0.20356012 #> 564 21 22  0.6620000 0.20257469 3.484000 4.146000 0.20158925 0.20356012 #> 565  1 21 -2.2590000 0.20690937 5.273000 3.014000 0.20991297 0.20390576 #> 566  1 22 -1.6270000 0.20766191 5.273000 3.646000 0.20991297 0.20541085 #> 567 21 22  0.6320000 0.20465831 3.014000 3.646000 0.20390576 0.20541085 #> 568  1 21 -2.1090000 0.21350139 5.233000 3.124000 0.21850685 0.20849592 #> 569  1 22 -1.3270000 0.21443913 5.233000 3.906000 0.21850685 0.21037141 #> 570 21 22  0.7820000 0.20943366 3.124000 3.906000 0.20849592 0.21037141 #> 571  1 21 -2.2990000 0.21922987 5.123000 2.824000 0.22585766 0.21260208 #> 572  1 22 -1.5470000 0.22013150 5.123000 3.576000 0.22585766 0.21440533 #> 573 21 22  0.7520000 0.21350370 2.824000 3.576000 0.21260208 0.21440533 #> 574  1  9 -0.3790000 0.16069082 6.870000 6.491000 0.20939918 0.11198246 #> 575  1 15 -0.3060000 0.16231402 6.870000 6.564000 0.20939918 0.11522885 #> 576  9 15  0.0730000 0.11360565 6.491000 6.564000 0.11198246 0.11522885 #> 577  1  9 -1.4890000 0.17609174 5.530000 4.041000 0.23627637 0.11590711 #> 578  1 15 -1.5560000 0.17652499 5.530000 3.974000 0.23627637 0.11677361 #> 579  9 15 -0.0670000 0.11634036 4.041000 3.974000 0.11590711 0.11677361 #> 580  1  9 -1.3790000 0.18208872 5.400000 4.021000 0.24560040 0.11857705 #> 581  1 15 -1.3660000 0.18237427 5.400000 4.034000 0.24560040 0.11914814 #> 582  9 15  0.0130000 0.11886260 4.021000 4.034000 0.11857705 0.11914814 #> 583  1  9 -1.2590000 0.19136418 5.160000 3.901000 0.25982124 0.12290712 #> 584  1 15 -1.1260000 0.19174497 5.160000 4.034000 0.25982124 0.12366869 #> 585  9 15  0.1330000 0.12328791 3.901000 4.034000 0.12290712 0.12366869 #> 586  1  9 -1.5390000 0.19869980 5.340000 3.801000 0.27087539 0.12652421 #> 587  1 15 -1.2560000 0.19901329 5.340000 4.084000 0.27087539 0.12715119 #> 588  9 15  0.2830000 0.12683770 3.801000 4.084000 0.12652421 0.12715119 #> 589  1  3  0.1000000 0.07304483 5.300000 5.400000 0.07329841 0.07279126 #> 590  1 11  0.1000000 0.07596883 5.300000 5.400000 0.07329841 0.07863926 #> 591  3 11  0.0000000 0.07571526 5.400000 5.400000 0.07279126 0.07863926 #> 592  1  3 -0.5600000 0.08210047 4.420000 3.860000 0.08359282 0.08060813 #> 593  1 11 -0.5400000 0.08170377 4.420000 3.880000 0.08359282 0.07981473 #> 594  3 11  0.0200000 0.08021143 3.860000 3.880000 0.08060813 0.07981473 #> 595  1  3 -0.6750000 0.08624366 4.255000 3.580000 0.08894068 0.08354665 #> 596  1 11 -0.6700000 0.08589334 4.255000 3.585000 0.08894068 0.08284601 #> 597  3 11  0.0050000 0.08319633 3.580000 3.585000 0.08354665 0.08284601 #> 598  1  3 -0.5950000 0.09039655 4.140000 3.545000 0.09407760 0.08671550 #> 599  1 11 -0.5550000 0.08999412 4.140000 3.585000 0.09407760 0.08591064 #> 600  3 11  0.0400000 0.08631307 3.545000 3.585000 0.08671550 0.08591064 #> 601  3 15  0.5200000 0.19002769 4.280000 4.800000 0.19002043 0.19003495 #> 602  3 22  0.5700000 0.19001310 4.280000 4.850000 0.19002043 0.19000576 #> 603 15 22  0.0500000 0.19002035 4.800000 4.850000 0.19003495 0.19000576 #> 604  3 15  0.5100000 0.20001557 2.970000 3.480000 0.19002043 0.21001071 #> 605  3 22  0.3900000 0.19501783 2.970000 3.360000 0.19002043 0.20001523 #> 606 15 22 -0.1200000 0.20501297 3.480000 3.360000 0.21001071 0.20001523 #> 607  3 15  0.5600000 0.21997086 2.780000 3.340000 0.19996735 0.23997436 #> 608  3 22  0.4000000 0.21000075 2.780000 3.180000 0.19996735 0.22003416 #> 609 15 22 -0.1600000 0.23000426 3.340000 3.180000 0.23997436 0.22003416 #> 610  1  5 -0.0550000 0.11468731 5.175000 5.120000 0.11801842 0.11135620 #> 611  1  5 -0.4450000 0.15725473 3.430000 2.985000 0.16255069 0.15195876 #> 612  1  5  0.0150000 0.14981834 5.475000 5.490000 0.13867505 0.16096163 #> 613  1  5 -0.7000000 0.18232254 3.880000 3.180000 0.18527144 0.17937364 #> 614  1  3 -0.0440000 0.08360569 4.742000 4.698000 0.08388064 0.08333074 #> 615  1  3 -0.3060000 0.12465952 3.020000 2.714000 0.12785580 0.12146325 #> 616  1 19  0.1800000 0.29498908 6.130000 6.310000 0.31002201 0.27995615 #> 617  1 19 -1.0000000 0.29498908 5.830000 4.830000 0.31002201 0.27995615 #> 618  1 19 -0.7000000 0.29498908 5.720000 5.020000 0.31002201 0.27995615 #> 619  1 19 -1.1800000 0.29498908 5.940000 4.760000 0.31002201 0.27995615 #> 620  1 19 -1.2600000 0.29498908 5.980000 4.720000 0.31002201 0.27995615 #> 621  1 19 -1.0400000 0.29498908 5.980000 4.940000 0.31002201 0.27995615 #> 622  1  3 -0.0500000 0.11327460 5.350000 5.300000 0.11667262 0.10987659 #> 623  1  3 -0.0500000 0.12585508 5.350000 5.300000 0.12868684 0.12302332 #> 624  1  7  0.1800000 0.13950515 6.466000 6.646000 0.16356491 0.11544539 #> 625  1  7 -0.8200000 0.14504395 5.236000 4.416000 0.17148452 0.11860337 #> 626  1  7 -1.0400000 0.14947612 5.186000 4.146000 0.17771766 0.12123458 #> 627  1  7 -1.0400000 0.15711534 4.686000 3.646000 0.18879059 0.12544008 #> 628  1  7 -1.0600000 0.16244692 4.716000 3.656000 0.19583685 0.12905699 #> 629  1  3 -0.1300000 0.14691939 4.790000 4.660000 0.14954087 0.14429790 #> 630  1  3 -0.3400000 0.15749590 3.420000 3.080000 0.16328616 0.15170564 #> 631  1  3 -0.4500000 0.16950866 3.080000 2.630000 0.17919315 0.15982418 #> 632  1  3 -0.1900000 0.18570955 2.790000 2.600000 0.19864814 0.17277095 #> 633  1  3 -0.5600000 0.19609402 2.700000 2.140000 0.20921215 0.18297588 #> 634  1  3 -0.2500000 0.12508127 5.300000 5.050000 0.10007405 0.15008849 #> 635  1  3 -0.6500000 0.10012020 4.400000 3.750000 0.10007405 0.10016636 #>     fupcount   time studyID #> 1          1  0.000      18 #> 2          1  0.000      18 #> 3          1  0.000      18 #> 4          1  0.000      18 #> 5          1  0.000      18 #> 6          1  0.000      18 #> 7          1  0.000      18 #> 8          1  0.000      18 #> 9          1  0.000      18 #> 10         1  0.000      18 #> 11         1  0.000      18 #> 12         1  0.000      18 #> 13         1  0.000      18 #> 14         1  0.000      18 #> 15         1  0.000      18 #> 16         2  1.000      18 #> 17         2  1.000      18 #> 18         2  1.000      18 #> 19         2  1.000      18 #> 20         2  1.000      18 #> 21         2  1.000      18 #> 22         2  1.000      18 #> 23         2  1.000      18 #> 24         2  1.000      18 #> 25         2  1.000      18 #> 26         2  1.000      18 #> 27         2  1.000      18 #> 28         2  1.000      18 #> 29         2  1.000      18 #> 30         2  1.000      18 #> 31         3  2.000      18 #> 32         3  2.000      18 #> 33         3  2.000      18 #> 34         3  2.000      18 #> 35         3  2.000      18 #> 36         3  2.000      18 #> 37         3  2.000      18 #> 38         3  2.000      18 #> 39         3  2.000      18 #> 40         3  2.000      18 #> 41         3  2.000      18 #> 42         3  2.000      18 #> 43         3  2.000      18 #> 44         3  2.000      18 #> 45         3  2.000      18 #> 46         4  4.000      18 #> 47         4  4.000      18 #> 48         4  4.000      18 #> 49         4  4.000      18 #> 50         4  4.000      18 #> 51         4  4.000      18 #> 52         4  4.000      18 #> 53         4  4.000      18 #> 54         4  4.000      18 #> 55         4  4.000      18 #> 56         4  4.000      18 #> 57         4  4.000      18 #> 58         4  4.000      18 #> 59         4  4.000      18 #> 60         4  4.000      18 #> 61         5  6.000      18 #> 62         5  6.000      18 #> 63         5  6.000      18 #> 64         5  6.000      18 #> 65         5  6.000      18 #> 66         5  6.000      18 #> 67         5  6.000      18 #> 68         5  6.000      18 #> 69         5  6.000      18 #> 70         5  6.000      18 #> 71         5  6.000      18 #> 72         5  6.000      18 #> 73         5  6.000      18 #> 74         5  6.000      18 #> 75         5  6.000      18 #> 76         1  0.000      28 #> 77         1  0.000      28 #> 78         1  0.000      28 #> 79         1  0.000      28 #> 80         1  0.000      28 #> 81         1  0.000      28 #> 82         1  0.000      28 #> 83         1  0.000      28 #> 84         1  0.000      28 #> 85         1  0.000      28 #> 86         1  0.000      28 #> 87         1  0.000      28 #> 88         1  0.000      28 #> 89         1  0.000      28 #> 90         1  0.000      28 #> 91         2  1.000      28 #> 92         2  1.000      28 #> 93         2  1.000      28 #> 94         2  1.000      28 #> 95         2  1.000      28 #> 96         2  1.000      28 #> 97         2  1.000      28 #> 98         2  1.000      28 #> 99         2  1.000      28 #> 100        2  1.000      28 #> 101        2  1.000      28 #> 102        2  1.000      28 #> 103        2  1.000      28 #> 104        2  1.000      28 #> 105        2  1.000      28 #> 106        3  2.000      28 #> 107        3  2.000      28 #> 108        3  2.000      28 #> 109        3  2.000      28 #> 110        3  2.000      28 #> 111        3  2.000      28 #> 112        3  2.000      28 #> 113        3  2.000      28 #> 114        3  2.000      28 #> 115        3  2.000      28 #> 116        3  2.000      28 #> 117        3  2.000      28 #> 118        3  2.000      28 #> 119        3  2.000      28 #> 120        3  2.000      28 #> 121        4  4.000      28 #> 122        4  4.000      28 #> 123        4  4.000      28 #> 124        4  4.000      28 #> 125        4  4.000      28 #> 126        4  4.000      28 #> 127        4  4.000      28 #> 128        4  4.000      28 #> 129        4  4.000      28 #> 130        4  4.000      28 #> 131        4  4.000      28 #> 132        4  4.000      28 #> 133        4  4.000      28 #> 134        4  4.000      28 #> 135        4  4.000      28 #> 136        5  6.000      28 #> 137        5  6.000      28 #> 138        5  6.000      28 #> 139        5  6.000      28 #> 140        5  6.000      28 #> 141        5  6.000      28 #> 142        5  6.000      28 #> 143        5  6.000      28 #> 144        5  6.000      28 #> 145        5  6.000      28 #> 146        5  6.000      28 #> 147        5  6.000      28 #> 148        5  6.000      28 #> 149        5  6.000      28 #> 150        5  6.000      28 #> 151        1  0.000       3 #> 152        1  0.000       3 #> 153        1  0.000       3 #> 154        1  0.000       3 #> 155        1  0.000       3 #> 156        1  0.000       3 #> 157        1  0.000       3 #> 158        1  0.000       3 #> 159        1  0.000       3 #> 160        1  0.000       3 #> 161        2  2.000       3 #> 162        2  2.000       3 #> 163        2  2.000       3 #> 164        2  2.000       3 #> 165        2  2.000       3 #> 166        2  2.000       3 #> 167        2  2.000       3 #> 168        2  2.000       3 #> 169        2  2.000       3 #> 170        2  2.000       3 #> 171        3 12.000       3 #> 172        3 12.000       3 #> 173        3 12.000       3 #> 174        3 12.000       3 #> 175        3 12.000       3 #> 176        3 12.000       3 #> 177        3 12.000       3 #> 178        3 12.000       3 #> 179        3 12.000       3 #> 180        3 12.000       3 #> 181        1  0.000      13 #> 182        1  0.000      13 #> 183        1  0.000      13 #> 184        1  0.000      13 #> 185        1  0.000      13 #> 186        1  0.000      13 #> 187        1  0.000      13 #> 188        1  0.000      13 #> 189        1  0.000      13 #> 190        1  0.000      13 #> 191        2  1.000      13 #> 192        2  1.000      13 #> 193        2  1.000      13 #> 194        2  1.000      13 #> 195        2  1.000      13 #> 196        2  1.000      13 #> 197        2  1.000      13 #> 198        2  1.000      13 #> 199        2  1.000      13 #> 200        2  1.000      13 #> 201        3  2.000      13 #> 202        3  2.000      13 #> 203        3  2.000      13 #> 204        3  2.000      13 #> 205        3  2.000      13 #> 206        3  2.000      13 #> 207        3  2.000      13 #> 208        3  2.000      13 #> 209        3  2.000      13 #> 210        3  2.000      13 #> 211        4  3.000      13 #> 212        4  3.000      13 #> 213        4  3.000      13 #> 214        4  3.000      13 #> 215        4  3.000      13 #> 216        4  3.000      13 #> 217        4  3.000      13 #> 218        4  3.000      13 #> 219        4  3.000      13 #> 220        4  3.000      13 #> 221        5  6.000      13 #> 222        5  6.000      13 #> 223        5  6.000      13 #> 224        5  6.000      13 #> 225        5  6.000      13 #> 226        5  6.000      13 #> 227        5  6.000      13 #> 228        5  6.000      13 #> 229        5  6.000      13 #> 230        5  6.000      13 #> 231        6  9.000      13 #> 232        6  9.000      13 #> 233        6  9.000      13 #> 234        6  9.000      13 #> 235        6  9.000      13 #> 236        6  9.000      13 #> 237        6  9.000      13 #> 238        6  9.000      13 #> 239        6  9.000      13 #> 240        6  9.000      13 #> 241        7 12.000      13 #> 242        7 12.000      13 #> 243        7 12.000      13 #> 244        7 12.000      13 #> 245        7 12.000      13 #> 246        7 12.000      13 #> 247        7 12.000      13 #> 248        7 12.000      13 #> 249        7 12.000      13 #> 250        7 12.000      13 #> 251        1  0.000      17 #> 252        1  0.000      17 #> 253        1  0.000      17 #> 254        1  0.000      17 #> 255        1  0.000      17 #> 256        1  0.000      17 #> 257        1  0.000      17 #> 258        1  0.000      17 #> 259        1  0.000      17 #> 260        1  0.000      17 #> 261        2  1.000      17 #> 262        2  1.000      17 #> 263        2  1.000      17 #> 264        2  1.000      17 #> 265        2  1.000      17 #> 266        2  1.000      17 #> 267        2  1.000      17 #> 268        2  1.000      17 #> 269        2  1.000      17 #> 270        2  1.000      17 #> 271        3  2.000      17 #> 272        3  2.000      17 #> 273        3  2.000      17 #> 274        3  2.000      17 #> 275        3  2.000      17 #> 276        3  2.000      17 #> 277        3  2.000      17 #> 278        3  2.000      17 #> 279        3  2.000      17 #> 280        3  2.000      17 #> 281        4  3.000      17 #> 282        4  3.000      17 #> 283        4  3.000      17 #> 284        4  3.000      17 #> 285        4  3.000      17 #> 286        4  3.000      17 #> 287        4  3.000      17 #> 288        4  3.000      17 #> 289        4  3.000      17 #> 290        4  3.000      17 #> 291        5  6.000      17 #> 292        5  6.000      17 #> 293        5  6.000      17 #> 294        5  6.000      17 #> 295        5  6.000      17 #> 296        5  6.000      17 #> 297        5  6.000      17 #> 298        5  6.000      17 #> 299        5  6.000      17 #> 300        5  6.000      17 #> 301        6  9.000      17 #> 302        6  9.000      17 #> 303        6  9.000      17 #> 304        6  9.000      17 #> 305        6  9.000      17 #> 306        6  9.000      17 #> 307        6  9.000      17 #> 308        6  9.000      17 #> 309        6  9.000      17 #> 310        6  9.000      17 #> 311        7 12.000      17 #> 312        7 12.000      17 #> 313        7 12.000      17 #> 314        7 12.000      17 #> 315        7 12.000      17 #> 316        7 12.000      17 #> 317        7 12.000      17 #> 318        7 12.000      17 #> 319        7 12.000      17 #> 320        7 12.000      17 #> 321        1  0.000      19 #> 322        1  0.000      19 #> 323        1  0.000      19 #> 324        1  0.000      19 #> 325        1  0.000      19 #> 326        1  0.000      19 #> 327        1  0.000      19 #> 328        1  0.000      19 #> 329        1  0.000      19 #> 330        1  0.000      19 #> 331        2  2.000      19 #> 332        2  2.000      19 #> 333        2  2.000      19 #> 334        2  2.000      19 #> 335        2  2.000      19 #> 336        2  2.000      19 #> 337        2  2.000      19 #> 338        2  2.000      19 #> 339        2  2.000      19 #> 340        2  2.000      19 #> 341        3 12.000      19 #> 342        3 12.000      19 #> 343        3 12.000      19 #> 344        3 12.000      19 #> 345        3 12.000      19 #> 346        3 12.000      19 #> 347        3 12.000      19 #> 348        3 12.000      19 #> 349        3 12.000      19 #> 350        3 12.000      19 #> 351        1  0.000      20 #> 352        1  0.000      20 #> 353        1  0.000      20 #> 354        1  0.000      20 #> 355        1  0.000      20 #> 356        1  0.000      20 #> 357        1  0.000      20 #> 358        1  0.000      20 #> 359        1  0.000      20 #> 360        1  0.000      20 #> 361        2  2.000      20 #> 362        2  2.000      20 #> 363        2  2.000      20 #> 364        2  2.000      20 #> 365        2  2.000      20 #> 366        2  2.000      20 #> 367        2  2.000      20 #> 368        2  2.000      20 #> 369        2  2.000      20 #> 370        2  2.000      20 #> 371        3  6.000      20 #> 372        3  6.000      20 #> 373        3  6.000      20 #> 374        3  6.000      20 #> 375        3  6.000      20 #> 376        3  6.000      20 #> 377        3  6.000      20 #> 378        3  6.000      20 #> 379        3  6.000      20 #> 380        3  6.000      20 #> 381        4 12.000      20 #> 382        4 12.000      20 #> 383        4 12.000      20 #> 384        4 12.000      20 #> 385        4 12.000      20 #> 386        4 12.000      20 #> 387        4 12.000      20 #> 388        4 12.000      20 #> 389        4 12.000      20 #> 390        4 12.000      20 #> 391        1  0.000      15 #> 392        1  0.000      15 #> 393        1  0.000      15 #> 394        1  0.000      15 #> 395        1  0.000      15 #> 396        1  0.000      15 #> 397        2 12.000      15 #> 398        2 12.000      15 #> 399        2 12.000      15 #> 400        2 12.000      15 #> 401        2 12.000      15 #> 402        2 12.000      15 #> 403        1  0.000      16 #> 404        1  0.000      16 #> 405        1  0.000      16 #> 406        1  0.000      16 #> 407        1  0.000      16 #> 408        1  0.000      16 #> 409        2  2.000      16 #> 410        2  2.000      16 #> 411        2  2.000      16 #> 412        2  2.000      16 #> 413        2  2.000      16 #> 414        2  2.000      16 #> 415        3 13.000      16 #> 416        3 13.000      16 #> 417        3 13.000      16 #> 418        3 13.000      16 #> 419        3 13.000      16 #> 420        3 13.000      16 #> 421        1  0.000      21 #> 422        1  0.000      21 #> 423        1  0.000      21 #> 424        1  0.000      21 #> 425        1  0.000      21 #> 426        1  0.000      21 #> 427        2  2.000      21 #> 428        2  2.000      21 #> 429        2  2.000      21 #> 430        2  2.000      21 #> 431        2  2.000      21 #> 432        2  2.000      21 #> 433        3 13.000      21 #> 434        3 13.000      21 #> 435        3 13.000      21 #> 436        3 13.000      21 #> 437        3 13.000      21 #> 438        3 13.000      21 #> 439        1  0.000      29 #> 440        1  0.000      29 #> 441        1  0.000      29 #> 442        1  0.000      29 #> 443        1  0.000      29 #> 444        1  0.000      29 #> 445        2  2.000      29 #> 446        2  2.000      29 #> 447        2  2.000      29 #> 448        2  2.000      29 #> 449        2  2.000      29 #> 450        2  2.000      29 #> 451        3  6.000      29 #> 452        3  6.000      29 #> 453        3  6.000      29 #> 454        3  6.000      29 #> 455        3  6.000      29 #> 456        3  6.000      29 #> 457        4 13.000      29 #> 458        4 13.000      29 #> 459        4 13.000      29 #> 460        4 13.000      29 #> 461        4 13.000      29 #> 462        4 13.000      29 #> 463        1  0.000      31 #> 464        1  0.000      31 #> 465        1  0.000      31 #> 466        1  0.000      31 #> 467        1  0.000      31 #> 468        1  0.000      31 #> 469        2 13.000      31 #> 470        2 13.000      31 #> 471        2 13.000      31 #> 472        2 13.000      31 #> 473        2 13.000      31 #> 474        2 13.000      31 #> 475        1  0.000      33 #> 476        1  0.000      33 #> 477        1  0.000      33 #> 478        1  0.000      33 #> 479        1  0.000      33 #> 480        1  0.000      33 #> 481        2  2.000      33 #> 482        2  2.000      33 #> 483        2  2.000      33 #> 484        2  2.000      33 #> 485        2  2.000      33 #> 486        2  2.000      33 #> 487        3 13.000      33 #> 488        3 13.000      33 #> 489        3 13.000      33 #> 490        3 13.000      33 #> 491        3 13.000      33 #> 492        3 13.000      33 #> 493        1  0.000       2 #> 494        1  0.000       2 #> 495        1  0.000       2 #> 496        2  2.000       2 #> 497        2  2.000       2 #> 498        2  2.000       2 #> 499        3  6.000       2 #> 500        3  6.000       2 #> 501        3  6.000       2 #> 502        4 13.000       2 #> 503        4 13.000       2 #> 504        4 13.000       2 #> 505        1  0.000       4 #> 506        1  0.000       4 #> 507        1  0.000       4 #> 508        2  2.000       4 #> 509        2  2.000       4 #> 510        2  2.000       4 #> 511        3  4.000       4 #> 512        3  4.000       4 #> 513        3  4.000       4 #> 514        4  8.000       4 #> 515        4  8.000       4 #> 516        4  8.000       4 #> 517        5 12.000       4 #> 518        5 12.000       4 #> 519        5 12.000       4 #> 520        1  0.000       5 #> 521        1  0.000       5 #> 522        1  0.000       5 #> 523        2  2.000       5 #> 524        2  2.000       5 #> 525        2  2.000       5 #> 526        3  4.000       5 #> 527        3  4.000       5 #> 528        3  4.000       5 #> 529        4  8.000       5 #> 530        4  8.000       5 #> 531        4  8.000       5 #> 532        5 12.000       5 #> 533        5 12.000       5 #> 534        5 12.000       5 #> 535        1  0.000       6 #> 536        1  0.000       6 #> 537        1  0.000       6 #> 538        2  2.000       6 #> 539        2  2.000       6 #> 540        2  2.000       6 #> 541        3  4.000       6 #> 542        3  4.000       6 #> 543        3  4.000       6 #> 544        4  6.000       6 #> 545        4  6.000       6 #> 546        4  6.000       6 #> 547        1  0.000       7 #> 548        1  0.000       7 #> 549        1  0.000       7 #> 550        2  2.000       7 #> 551        2  2.000       7 #> 552        2  2.000       7 #> 553        3  4.000       7 #> 554        3  4.000       7 #> 555        3  4.000       7 #> 556        4  6.000       7 #> 557        4  6.000       7 #> 558        4  6.000       7 #> 559        1  0.000      14 #> 560        1  0.000      14 #> 561        1  0.000      14 #> 562        2  1.000      14 #> 563        2  1.000      14 #> 564        2  1.000      14 #> 565        3  2.000      14 #> 566        3  2.000      14 #> 567        3  2.000      14 #> 568        4  4.000      14 #> 569        4  4.000      14 #> 570        4  4.000      14 #> 571        5  6.000      14 #> 572        5  6.000      14 #> 573        5  6.000      14 #> 574        1  0.000      22 #> 575        1  0.000      22 #> 576        1  0.000      22 #> 577        2  2.000      22 #> 578        2  2.000      22 #> 579        2  2.000      22 #> 580        3  4.000      22 #> 581        3  4.000      22 #> 582        3  4.000      22 #> 583        4  8.000      22 #> 584        4  8.000      22 #> 585        4  8.000      22 #> 586        5 12.000      22 #> 587        5 12.000      22 #> 588        5 12.000      22 #> 589        1  0.000      30 #> 590        1  0.000      30 #> 591        1  0.000      30 #> 592        2  4.000      30 #> 593        2  4.000      30 #> 594        2  4.000      30 #> 595        3  8.000      30 #> 596        3  8.000      30 #> 597        3  8.000      30 #> 598        4 13.000      30 #> 599        4 13.000      30 #> 600        4 13.000      30 #> 601        1  0.000      32 #> 602        1  0.000      32 #> 603        1  0.000      32 #> 604        2  6.000      32 #> 605        2  6.000      32 #> 606        2  6.000      32 #> 607        3 12.000      32 #> 608        3 12.000      32 #> 609        3 12.000      32 #> 610        1  0.000      10 #> 611        2 13.000      10 #> 612        1  0.000      11 #> 613        2 13.000      11 #> 614        1  0.000      12 #> 615        2 24.000      12 #> 616        1  0.000      24 #> 617        2  2.142      24 #> 618        3  4.286      24 #> 619        4  6.429      24 #> 620        5  8.571      24 #> 621        6 12.857      24 #> 622        1  0.000      25 #> 623        2  6.000      25 #> 624        1  0.000      26 #> 625        2  2.000      26 #> 626        3  4.000      26 #> 627        4  8.000      26 #> 628        5 12.000      26 #> 629        1  0.000      27 #> 630        2  4.000      27 #> 631        3  8.000      27 #> 632        4 16.000      27 #> 633        5 24.000      27 #> 634        1  0.000      35 #> 635        2  6.000      35  # Convert to long contrast data mb.make.contrast(network, format=\"long\") #> Warning: Data type not specified and data frame contains y - data are assumed to be normal #> Warning: studyID has been changed to allow separate ID for each contrast rather than study #> # A tibble: 1,270 × 7 #> # Groups:   studyID, fupcount [635] #>    studyID treatment  time     y    se   arm fupcount #>      <dbl>     <dbl> <dbl> <dbl> <dbl> <dbl>    <int> #>  1       1         1     0  7.06 0.222     1        1 #>  2       1         6     0  7.01 0.161     2        1 #>  3       2         1     0  7.06 0.222     1        1 #>  4       2         7     0  6.76 0.170     2        1 #>  5       3         1     0  7.06 0.222     1        1 #>  6       3         8     0  6.87 0.158     2        1 #>  7       4         1     0  7.06 0.222     1        1 #>  8       4         9     0  6.69 0.162     2        1 #>  9       5         1     0  7.06 0.222     1        1 #> 10       5        10     0  6.85 0.162     2        1 #> # … with 1,260 more rows"},{"path":"/reference/mb.network.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an mb.network object — plot.mb.network","title":"Create an mb.network object — plot.mb.network","text":"Creates object class(\"mb.network\"). Various MBNMA functions can subsequently applied object.","code":""},{"path":"/reference/mb.network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an mb.network object — plot.mb.network","text":"","code":"# S3 method for mb.network plot(   x,   edge.scale = 1,   label.distance = 0,   level = \"treatment\",   remove.loops = FALSE,   v.color = \"connect\",   v.scale = NULL,   layout = igraph::in_circle(),   legend = TRUE,   legend.x = \"bottomleft\",   legend.y = NULL,   ... )  mb.network(data.ab, reference = 1, cfb = NULL, description = \"Network\")"},{"path":"/reference/mb.network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an mb.network object — plot.mb.network","text":"x object class mb.network. edge.scale number scale thickness connecting lines (edges). Line thickness proportional number studies given comparison. Set 0 make thickness equal comparisons. label.distance number scaling distance labels nodes improve readability. labels directly top nodes default 0 used. Option applicable layout_in_circle set TRUE. level string indicating whether nodes/facets represent treatment class plot. Can used examine expected impact modelling class/agent effects. remove.loops boolean value indicating whether include loops indicate comparisons within node. v.color Can take either \"connect\" (default) indicate nodes coloured connected network reference treatment (indicates network connectivity) \"class\" colour nodes class (requires variable class included dataset). v.scale number scale size nodes. variable N (indicate numbers participants observation) included dataset size nodes proportional number participants within treatment/class network earliest time point reported study. layout igraph layout specification. function specifying igraph layout determines arrangement vertices (nodes). default igraph::as_circle() arranged vertices circle. Two useful layouts network plots : igraph::as_star(), igraph::with_fr(). Others can found layout_ legend boolean value indicating whether plot legend class names v.color=\"class\" legend.x Can either string numerical x-coordinate indicating legend plotted (see legend). legend.y numerical y-coordinate indicating legend plotted - required legend.x also numeric co-ordinate. ... Options plotting igraph. data.ab data frame arm-level data \"long\" format containing columns: studyID Study identifiers time Numeric data indicating follow-times y Numeric data indicating aggregate response given observation (e.g. mean) se Numeric data indicating standard error given observation treatment Treatment identifiers (can numeric, factor character) class optional column indicating particular class identifier. Observations treatment identifier must also class identifier. n optional column indicating number participants used calculate response given observation (required modelling using Standardised Mean Differences) reference number character (depending format treatment within data.ab) indicating reference treatment network (.e. estimated relative treatment effects estimated model compared ). cfb logical vector whose length equal unique number studies data.ab, element TRUE study data reported change--baseline FALSE otherwise. left NULL (default) identified data assuming study data time=0 reports change--baseline. description Optional. Short description network.","code":""},{"path":"/reference/mb.network.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an mb.network object — plot.mb.network","text":"object class(\"mb.network\") list containing: description short description network data.ab data frame containing arm-level network data (treatment identifiers recoded sequential numeric code) studyID character vector IDs included studies. cfb logical vector indicating studies report change baseline data treatments character vector indicating treatment identifiers correspond new treatment codes. classes character vector indicating class identifiers (included original data) correspond new class codes.","code":""},{"path":"/reference/mb.network.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create an mb.network object — plot.mb.network","text":"S3 method plot() mb.network object generates network plot shows different treatments connected within network via study comparisons. can used identify direct indirect evidence informing different treatment comparisons. Depends igraph. Missing values (NA) included dataset. Studies must baseline measurement single follow-time (unless change baseline data used). Data must present arms within study follow-time.","code":""},{"path":"/reference/mb.network.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Create an mb.network object — plot.mb.network","text":"plot(mb.network): Generate network plot","code":""},{"path":"/reference/mb.network.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an mb.network object — plot.mb.network","text":"","code":"# \\donttest{  # Create an mb.network object from the data network <- mb.network(osteopain) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Arrange network plot in a star with the reference treatment in the centre plot(network, layout=igraph::as_star())   # Generate a network plot at the class level that removes loops indicating comparisons #within a node goutnet <- mb.network(goutSUA_CFB) #> Reference treatment is `Plac` #> Studies reporting change from baseline automatically identified from the data plot(goutnet, level=\"class\", remove.loops=TRUE)   # Generate a network plot at the treatment level that colours nodes by class plot(goutnet, v.color=\"class\", remove.loops=TRUE) #> Warning: The following treatments/agents are not connected to the network reference: #> Allo_245 #> Allo_256 #> Allo_265 #> Allo_278 #> Allo_400 #> Benz_139 #> Benz_143 #> Benz_50 #> Benz_82.97   # Plot network in which node size is proportional to number of participants alognet <- mb.network(alog_pcfb) #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data plot(alognet, v.scale=2)   # }  # Using the osteoarthritis dataset print(osteopain) #>               studyID   time        y         se treatment arm        treatname #> 1       Baerwald 2010  0.000 6.548000 0.08613561      Pl_0   1        Placebo_0 #> 2       Baerwald 2010  2.000 5.398000 0.09317367      Pl_0   1        Placebo_0 #> 3       Baerwald 2010  6.000 4.968000 0.09969241      Pl_0   1        Placebo_0 #> 4       Baerwald 2010 13.000 4.751000 0.10850034      Pl_0   1        Placebo_0 #> 5       Baerwald 2010  0.000 6.399000 0.12738195   Na_1000   2    Naproxen_1000 #> 6       Baerwald 2010  2.000 4.029000 0.13337086   Na_1000   2    Naproxen_1000 #> 7       Baerwald 2010  6.000 3.719000 0.13861218   Na_1000   2    Naproxen_1000 #> 8       Baerwald 2010 13.000 3.968000 0.14647069   Na_1000   2    Naproxen_1000 #> 9       Baerwald 2010  0.000 6.625000 0.09003349   Na_1500   3 Naproxcinod_1500 #> 10      Baerwald 2010  2.000 4.435000 0.09258069   Na_1500   3 Naproxcinod_1500 #> 11      Baerwald 2010  6.000 4.085000 0.09645929   Na_1500   3 Naproxcinod_1500 #> 12      Baerwald 2010 13.000 4.044000 0.10175895   Na_1500   3 Naproxcinod_1500 #> 13        Bensen 1999  0.000 5.405620 0.12743652      Pl_0   1        Placebo_0 #> 14        Bensen 1999  2.000 5.020210 0.13967062      Pl_0   1        Placebo_0 #> 15        Bensen 1999 12.000 4.720889 0.15125135      Pl_0   1        Placebo_0 #> 16        Bensen 1999  0.000 5.545080 0.12875036   Na_1000   2    Naproxen_1000 #> 17        Bensen 1999  2.000 4.124826 0.13193069   Na_1000   2    Naproxen_1000 #> 18        Bensen 1999 12.000 4.267348 0.14313626   Na_1000   2    Naproxen_1000 #> 19        Bensen 1999  0.000 5.405620 0.12756608    Ce_400   3     Celebrex_400 #> 20        Bensen 1999  2.000 3.962108 0.13072450    Ce_400   3     Celebrex_400 #> 21        Bensen 1999 12.000 3.965032 0.14176423    Ce_400   3     Celebrex_400 #> 22        Bensen 1999  0.000 5.266090 0.12930813    Ce_200   4     Celebrex_200 #> 23        Bensen 1999  2.000 3.822510 0.13230924    Ce_200   4     Celebrex_200 #> 24        Bensen 1999 12.000 3.720855 0.14325486    Ce_200   4     Celebrex_200 #> 25        Bensen 1999  0.000 5.382295 0.12702820    Ce_100   5     Celebrex_100 #> 26        Bensen 1999  2.000 4.345749 0.13030080    Ce_100   5     Celebrex_100 #> 27        Bensen 1999 12.000 4.325553 0.14135801    Ce_100   5     Celebrex_100 #> 28      Bingham 2007a  0.000 6.660000 0.14375175      Pl_0   1        Placebo_0 #> 29      Bingham 2007a  2.000 5.905123 0.15295812      Pl_0   1        Placebo_0 #> 30      Bingham 2007a  4.000 5.597386 0.15878729      Pl_0   1        Placebo_0 #> 31      Bingham 2007a  8.000 5.374769 0.16812945      Pl_0   1        Placebo_0 #> 32      Bingham 2007a 12.000 5.124054 0.17621052      Pl_0   1        Placebo_0 #> 33      Bingham 2007a  0.000 6.750000 0.10499753    Ce_200   2     Celebrex_200 #> 34      Bingham 2007a  2.000 4.606352 0.10894260    Ce_200   2     Celebrex_200 #> 35      Bingham 2007a  4.000 4.270519 0.11133890    Ce_200   2     Celebrex_200 #> 36      Bingham 2007a  8.000 4.300451 0.11563667    Ce_200   2     Celebrex_200 #> 37      Bingham 2007a 12.000 4.274297 0.11895791    Ce_200   2     Celebrex_200 #> 38      Bingham 2007a  0.000 6.740000 0.10658817     Et_30   3    Etoricoxib_30 #> 39      Bingham 2007a  2.000 4.245301 0.11123171     Et_30   3    Etoricoxib_30 #> 40      Bingham 2007a  4.000 4.021748 0.11386291     Et_30   3    Etoricoxib_30 #> 41      Bingham 2007a  8.000 4.037578 0.11802862     Et_30   3    Etoricoxib_30 #> 42      Bingham 2007a 12.000 3.899251 0.12156902     Et_30   3    Etoricoxib_30 #> 43      Bingham 2007b  0.000 6.640000 0.15968999      Pl_0   1        Placebo_0 #> 44      Bingham 2007b  2.000 5.519577 0.17109473      Pl_0   1        Placebo_0 #> 45      Bingham 2007b  4.000 5.097473 0.17758313      Pl_0   1        Placebo_0 #> 46      Bingham 2007b  8.000 5.011880 0.18711207      Pl_0   1        Placebo_0 #> 47      Bingham 2007b 12.000 4.999232 0.19569508      Pl_0   1        Placebo_0 #> 48      Bingham 2007b  0.000 6.730000 0.11922685    Ce_200   2     Celebrex_200 #> 49      Bingham 2007b  2.000 4.384345 0.11363334    Ce_200   2     Celebrex_200 #> 50      Bingham 2007b  4.000 4.137306 0.11584245    Ce_200   2     Celebrex_200 #> 51      Bingham 2007b  8.000 4.022573 0.12001322    Ce_200   2     Celebrex_200 #> 52      Bingham 2007b 12.000 3.936906 0.12354571    Ce_200   2     Celebrex_200 #> 53      Bingham 2007b  0.000 6.870000 0.10520605     Et_30   3    Etoricoxib_30 #> 54      Bingham 2007b  2.000 4.465766 0.11429788     Et_30   3    Etoricoxib_30 #> 55      Bingham 2007b  4.000 4.233316 0.11672457     Et_30   3    Etoricoxib_30 #> 56      Bingham 2007b  8.000 4.089368 0.12087161     Et_30   3    Etoricoxib_30 #> 57      Bingham 2007b 12.000 4.091271 0.12433858     Et_30   3    Etoricoxib_30 #> 58     Birbara 2006_1  0.000 6.850000 0.19248710      Pl_0   1        Placebo_0 #> 59     Birbara 2006_1  2.000 5.050000 0.19825783      Pl_0   1        Placebo_0 #> 60     Birbara 2006_1  4.000 4.900000 0.20546535      Pl_0   1        Placebo_0 #> 61     Birbara 2006_1  6.000 4.740000 0.21210711      Pl_0   1        Placebo_0 #> 62     Birbara 2006_1  0.000 6.830000 0.13567477    Ce_200   2     Celebrex_200 #> 63     Birbara 2006_1  2.000 4.290000 0.13735626    Ce_200   2     Celebrex_200 #> 64     Birbara 2006_1  4.000 4.090000 0.14020133    Ce_200   2     Celebrex_200 #> 65     Birbara 2006_1  6.000 3.930000 0.14285150    Ce_200   2     Celebrex_200 #> 66     Birbara 2006_1  0.000 7.050000 0.12570054     Ro_12   3     Rofecoxib_12 #> 67     Birbara 2006_1  2.000 4.650000 0.13581507     Ro_12   3     Rofecoxib_12 #> 68     Birbara 2006_1  4.000 4.360000 0.13919061     Ro_12   3     Rofecoxib_12 #> 69     Birbara 2006_1  6.000 4.190000 0.14163496     Ro_12   3     Rofecoxib_12 #> 70     Birbara 2006_2  0.000 6.870000 0.19089880      Pl_0   1        Placebo_0 #> 71     Birbara 2006_2  2.000 4.930000 0.19254502      Pl_0   1        Placebo_0 #> 72     Birbara 2006_2  4.000 4.760000 0.19892926      Pl_0   1        Placebo_0 #> 73     Birbara 2006_2  6.000 4.590000 0.20627513      Pl_0   1        Placebo_0 #> 74     Birbara 2006_2  0.000 6.680000 0.13307692    Ce_200   2     Celebrex_200 #> 75     Birbara 2006_2  2.000 4.190000 0.13377582    Ce_200   2     Celebrex_200 #> 76     Birbara 2006_2  4.000 3.700000 0.13702105    Ce_200   2     Celebrex_200 #> 77     Birbara 2006_2  6.000 3.540000 0.13955657    Ce_200   2     Celebrex_200 #> 78     Birbara 2006_2  0.000 6.700000 0.12688825     Ro_12   3     Rofecoxib_12 #> 79     Birbara 2006_2  2.000 3.720000 0.13837981     Ro_12   3     Rofecoxib_12 #> 80     Birbara 2006_2  4.000 3.720000 0.14138984     Ro_12   3     Rofecoxib_12 #> 81     Birbara 2006_2  6.000 3.620000 0.14410240     Ro_12   3     Rofecoxib_12 #> 88      Chappell 2009  0.000 5.175000 0.11801842      Pl_0   1        Placebo_0 #> 89      Chappell 2009 13.000 3.430000 0.16255069      Pl_0   1        Placebo_0 #> 90      Chappell 2009  0.000 5.120000 0.11135620     Du_90   2    Duloxetine_90 #> 91      Chappell 2009 13.000 2.985000 0.15195876     Du_90   2    Duloxetine_90 #> 92      Chappell 2011  0.000 5.475000 0.13867505      Pl_0   1        Placebo_0 #> 93      Chappell 2011 13.000 3.880000 0.18527144      Pl_0   1        Placebo_0 #> 94      Chappell 2011  0.000 5.490000 0.16096163     Du_90   2    Duloxetine_90 #> 95      Chappell 2011 13.000 3.180000 0.17937364     Du_90   2    Duloxetine_90 #> 96         Clegg 2006  0.000 4.742000 0.08388064      Pl_0   1        Placebo_0 #> 97         Clegg 2006 24.000 3.020000 0.12785580      Pl_0   1        Placebo_0 #> 98         Clegg 2006  0.000 4.698000 0.08333074    Ce_200   2     Celebrex_200 #> 99         Clegg 2006 24.000 2.714000 0.12146325    Ce_200   2     Celebrex_200 #> 100      DeLemos 2011  0.000 6.016000 0.14637110      Pl_0   1        Placebo_0 #> 101      DeLemos 2011  1.000 4.660234 0.14174890      Pl_0   1        Placebo_0 #> 102      DeLemos 2011  2.000 4.265908 0.14423560      Pl_0   1        Placebo_0 #> 103      DeLemos 2011  3.000 3.980672 0.14662378      Pl_0   1        Placebo_0 #> 104      DeLemos 2011  6.000 3.643174 0.15307332      Pl_0   1        Placebo_0 #> 105      DeLemos 2011  9.000 3.292040 0.15809206      Pl_0   1        Placebo_0 #> 106      DeLemos 2011 12.000 3.268146 0.16279536      Pl_0   1        Placebo_0 #> 107      DeLemos 2011  0.000 5.738000 0.13523145    Ce_200   2     Celebrex_200 #> 108      DeLemos 2011  1.000 3.746574 0.13973694    Ce_200   2     Celebrex_200 #> 109      DeLemos 2011  2.000 3.284066 0.14128381    Ce_200   2     Celebrex_200 #> 110      DeLemos 2011  3.000 2.930678 0.14255246    Ce_200   2     Celebrex_200 #> 111      DeLemos 2011  6.000 2.511332 0.14627650    Ce_200   2     Celebrex_200 #> 112      DeLemos 2011  9.000 2.555680 0.14916326    Ce_200   2     Celebrex_200 #> 113      DeLemos 2011 12.000 2.545424 0.15202178    Ce_200   2     Celebrex_200 #> 114      DeLemos 2011  0.000 6.124000 0.15212591    Tr_300   3     Tramadol_300 #> 115      DeLemos 2011  1.000 4.332964 0.14113504    Tr_300   3     Tramadol_300 #> 116      DeLemos 2011  2.000 3.693184 0.14233657    Tr_300   3     Tramadol_300 #> 117      DeLemos 2011  3.000 3.230648 0.14383500    Tr_300   3     Tramadol_300 #> 118      DeLemos 2011  6.000 2.879542 0.14753666    Tr_300   3     Tramadol_300 #> 119      DeLemos 2011  9.000 2.828406 0.15064388    Tr_300   3     Tramadol_300 #> 120      DeLemos 2011 12.000 2.777240 0.15325220    Tr_300   3     Tramadol_300 #> 121      DeLemos 2011  0.000 6.058000 0.13624697    Tr_200   4     Tramadol_200 #> 122      DeLemos 2011  1.000 4.346600 0.14061110    Tr_200   4     Tramadol_200 #> 123      DeLemos 2011  2.000 3.993182 0.14238944    Tr_200   4     Tramadol_200 #> 124      DeLemos 2011  3.000 3.762492 0.14390273    Tr_200   4     Tramadol_200 #> 125      DeLemos 2011  6.000 3.302266 0.14727855    Tr_200   4     Tramadol_200 #> 126      DeLemos 2011  9.000 3.223858 0.15077558    Tr_200   4     Tramadol_200 #> 127      DeLemos 2011 12.000 3.240874 0.15337054    Tr_200   4     Tramadol_200 #> 128      DeLemos 2011  0.000 5.968000 0.14290302    Tr_100   5     Tramadol_100 #> 129      DeLemos 2011  1.000 4.701114 0.14013124    Tr_100   5     Tramadol_100 #> 130      DeLemos 2011  2.000 4.115910 0.14149865    Tr_100   5     Tramadol_100 #> 131      DeLemos 2011  3.000 3.667038 0.14301421    Tr_100   5     Tramadol_100 #> 132      DeLemos 2011  6.000 3.479538 0.14674325    Tr_100   5     Tramadol_100 #> 133      DeLemos 2011  9.000 3.605646 0.14999098    Tr_100   5     Tramadol_100 #> 134      DeLemos 2011 12.000 3.349994 0.15257853    Tr_100   5     Tramadol_100 #> 135       Enrich 1999  0.000 6.003000 0.20107522      Pl_0   1        Placebo_0 #> 136       Enrich 1999  1.000 5.643000 0.20685093      Pl_0   1        Placebo_0 #> 137       Enrich 1999  2.000 5.273000 0.20991297      Pl_0   1        Placebo_0 #> 138       Enrich 1999  4.000 5.233000 0.21850685      Pl_0   1        Placebo_0 #> 139       Enrich 1999  6.000 5.123000 0.22585766      Pl_0   1        Placebo_0 #> 140       Enrich 1999  0.000 6.436000 0.19999737     Ro_25   2     Rofecoxib_25 #> 141       Enrich 1999  1.000 4.146000 0.20356012     Ro_25   2     Rofecoxib_25 #> 142       Enrich 1999  2.000 3.646000 0.20541085     Ro_25   2     Rofecoxib_25 #> 143       Enrich 1999  4.000 3.906000 0.21037141     Ro_25   2     Rofecoxib_25 #> 144       Enrich 1999  6.000 3.576000 0.21440533     Ro_25   2     Rofecoxib_25 #> 145       Enrich 1999  0.000 5.944000 0.19953406    Ro_125   3    Rofecoxib_125 #> 146       Enrich 1999  1.000 3.484000 0.20158925    Ro_125   3    Rofecoxib_125 #> 147       Enrich 1999  2.000 3.014000 0.20390576    Ro_125   3    Rofecoxib_125 #> 148       Enrich 1999  4.000 3.124000 0.20849592    Ro_125   3    Rofecoxib_125 #> 149       Enrich 1999  6.000 2.824000 0.21260208    Ro_125   3    Rofecoxib_125 #> 150      Fishman 2007  0.000 6.014000 0.11866399      Pl_0   1        Placebo_0 #> 151      Fishman 2007 12.000 4.071478 0.13816027      Pl_0   1        Placebo_0 #> 152      Fishman 2007  0.000 6.288000 0.18951979    Tr_300   2     Tramadol_300 #> 153      Fishman 2007 12.000 3.395520 0.18848415    Tr_300   2     Tramadol_300 #> 154      Fishman 2007  0.000 5.676000 0.15796474    Tr_200   3     Tramadol_200 #> 155      Fishman 2007 12.000 3.246672 0.18748009    Tr_200   3     Tramadol_200 #> 156      Fishman 2007  0.000 5.756000 0.15528789    Tr_100   4     Tramadol_100 #> 157      Fishman 2007 12.000 3.361504 0.19021417    Tr_100   4     Tramadol_100 #> 158  Fleischmann 2005  0.000 4.950000 0.10856203      Pl_0   1        Placebo_0 #> 159  Fleischmann 2005  2.000 4.150000 0.11449208      Pl_0   1        Placebo_0 #> 160  Fleischmann 2005 13.000 3.800000 0.13292276      Pl_0   1        Placebo_0 #> 161  Fleischmann 2005  0.000 5.150000 0.07925469    Ce_200   2     Celebrex_200 #> 162  Fleischmann 2005  2.000 3.700000 0.08106751    Ce_200   2     Celebrex_200 #> 163  Fleischmann 2005 13.000 3.400000 0.08897460    Ce_200   2     Celebrex_200 #> 164  Fleischmann 2005  0.000 4.950000 0.07854096    Lu_400   3  Lumiracoxib_400 #> 165  Fleischmann 2005  2.000 3.400000 0.07952726    Lu_400   3  Lumiracoxib_400 #> 166  Fleischmann 2005 13.000 3.100000 0.08732728    Lu_400   3  Lumiracoxib_400 #> 167  Fleischmann 2005  0.000 5.150000 0.07536922    Lu_200   4  Lumiracoxib_200 #> 168  Fleischmann 2005  2.000 3.600000 0.07969604    Lu_200   4  Lumiracoxib_200 #> 169  Fleischmann 2005 13.000 3.300000 0.08726499    Lu_200   4  Lumiracoxib_200 #> 170         Gana 2006  0.000 6.118000 0.13298113      Pl_0   1        Placebo_0 #> 171         Gana 2006  1.000 5.278000 0.13368325      Pl_0   1        Placebo_0 #> 172         Gana 2006  2.000 4.846000 0.13645321      Pl_0   1        Placebo_0 #> 173         Gana 2006  3.000 4.746000 0.13873236      Pl_0   1        Placebo_0 #> 174         Gana 2006  6.000 4.576000 0.14503567      Pl_0   1        Placebo_0 #> 175         Gana 2006  9.000 4.604000 0.14996109      Pl_0   1        Placebo_0 #> 176         Gana 2006 12.000 4.634000 0.15451115      Pl_0   1        Placebo_0 #> 177         Gana 2006  0.000 5.932000 0.13584957    Tr_300   2     Tramadol_300 #> 178         Gana 2006  1.000 4.534000 0.13381126    Tr_300   2     Tramadol_300 #> 179         Gana 2006  2.000 4.076000 0.13543190    Tr_300   2     Tramadol_300 #> 180         Gana 2006  3.000 3.920000 0.13660626    Tr_300   2     Tramadol_300 #> 181         Gana 2006  6.000 3.790000 0.14032551    Tr_300   2     Tramadol_300 #> 182         Gana 2006  9.000 3.862000 0.14378647    Tr_300   2     Tramadol_300 #> 183         Gana 2006 12.000 3.854000 0.14624779    Tr_300   2     Tramadol_300 #> 184         Gana 2006  0.000 6.304000 0.13034787    Tr_200   3     Tramadol_200 #> 185         Gana 2006  1.000 5.030000 0.13379605    Tr_200   3     Tramadol_200 #> 186         Gana 2006  2.000 4.498000 0.13535877    Tr_200   3     Tramadol_200 #> 187         Gana 2006  3.000 4.300000 0.13697546    Tr_200   3     Tramadol_200 #> 188         Gana 2006  6.000 4.172000 0.14047598    Tr_200   3     Tramadol_200 #> 189         Gana 2006  9.000 4.154000 0.14352237    Tr_200   3     Tramadol_200 #> 190         Gana 2006 12.000 4.074000 0.14613323    Tr_200   3     Tramadol_200 #> 191         Gana 2006  0.000 6.164000 0.13973447    Tr_100   4     Tramadol_100 #> 192         Gana 2006  1.000 5.026000 0.13345351    Tr_100   4     Tramadol_100 #> 193         Gana 2006  2.000 4.666000 0.13494127    Tr_100   4     Tramadol_100 #> 194         Gana 2006  3.000 4.446000 0.13629561    Tr_100   4     Tramadol_100 #> 195         Gana 2006  6.000 4.114000 0.14008223    Tr_100   4     Tramadol_100 #> 196         Gana 2006  9.000 4.052000 0.14324415    Tr_100   4     Tramadol_100 #> 197         Gana 2006 12.000 4.020000 0.14598755    Tr_100   4     Tramadol_100 #> 198         Gana 2006  0.000 5.960000 0.13185418    Tr_400   5     Tramadol_400 #> 199         Gana 2006  1.000 4.678000 0.13349877    Tr_400   5     Tramadol_400 #> 200         Gana 2006  2.000 4.230000 0.13504263    Tr_400   5     Tramadol_400 #> 201         Gana 2006  3.000 3.898000 0.13645394    Tr_400   5     Tramadol_400 #> 202         Gana 2006  6.000 3.700000 0.13994609    Tr_400   5     Tramadol_400 #> 203         Gana 2006  9.000 3.708000 0.14305671    Tr_400   5     Tramadol_400 #> 204         Gana 2006 12.000 3.804000 0.14586527    Tr_400   5     Tramadol_400 #> 205 Gottesdiener 2002  0.000 7.062000 0.22216747      Pl_0   1        Placebo_0 #> 206 Gottesdiener 2002  1.000 6.362000 0.22671752      Pl_0   1        Placebo_0 #> 207 Gottesdiener 2002  2.000 6.262000 0.23247437      Pl_0   1        Placebo_0 #> 208 Gottesdiener 2002  4.000 6.052000 0.24012258      Pl_0   1        Placebo_0 #> 209 Gottesdiener 2002  6.000 5.902000 0.24781410      Pl_0   1        Placebo_0 #> 210 Gottesdiener 2002  0.000 6.756000 0.16960703     Et_30   2    Etoricoxib_30 #> 211 Gottesdiener 2002  1.000 4.796000 0.17227052     Et_30   2    Etoricoxib_30 #> 212 Gottesdiener 2002  2.000 4.416000 0.17432054     Et_30   2    Etoricoxib_30 #> 213 Gottesdiener 2002  4.000 4.476000 0.17798345     Et_30   2    Etoricoxib_30 #> 214 Gottesdiener 2002  6.000 4.106000 0.18209630     Et_30   2    Etoricoxib_30 #> 215 Gottesdiener 2002  0.000 6.854000 0.16202815     Et_90   3    Etoricoxib_90 #> 216 Gottesdiener 2002  1.000 4.134000 0.16437693     Et_90   3    Etoricoxib_90 #> 217 Gottesdiener 2002  2.000 4.084000 0.16637489     Et_90   3    Etoricoxib_90 #> 218 Gottesdiener 2002  4.000 3.914000 0.16972969     Et_90   3    Etoricoxib_90 #> 219 Gottesdiener 2002  6.000 3.794000 0.17288616     Et_90   3    Etoricoxib_90 #> 220 Gottesdiener 2002  0.000 6.686000 0.16193198     Et_60   4    Etoricoxib_60 #> 221 Gottesdiener 2002  1.000 3.866000 0.16433909     Et_60   4    Etoricoxib_60 #> 222 Gottesdiener 2002  2.000 3.616000 0.16650567     Et_60   4    Etoricoxib_60 #> 223 Gottesdiener 2002  4.000 3.576000 0.17027961     Et_60   4    Etoricoxib_60 #> 224 Gottesdiener 2002  6.000 3.406000 0.17343517     Et_60   4    Etoricoxib_60 #> 225 Gottesdiener 2002  0.000 6.873000 0.15841042      Et_5   5     Etoricoxib_5 #> 226 Gottesdiener 2002  1.000 5.823000 0.16082866      Et_5   5     Etoricoxib_5 #> 227 Gottesdiener 2002  2.000 5.343000 0.16260877      Et_5   5     Etoricoxib_5 #> 228 Gottesdiener 2002  4.000 5.203000 0.16620577      Et_5   5     Etoricoxib_5 #> 229 Gottesdiener 2002  6.000 4.823000 0.16929977      Et_5   5     Etoricoxib_5 #> 230 Gottesdiener 2002  0.000 7.009000 0.16055675     Et_10   6    Etoricoxib_10 #> 231 Gottesdiener 2002  1.000 5.599000 0.16276707     Et_10   6    Etoricoxib_10 #> 232 Gottesdiener 2002  2.000 5.079000 0.16477139     Et_10   6    Etoricoxib_10 #> 233 Gottesdiener 2002  4.000 5.239000 0.16891879     Et_10   6    Etoricoxib_10 #> 234 Gottesdiener 2002  6.000 5.219000 0.17199388     Et_10   6    Etoricoxib_10 #> 235       Kivitz 2001  0.000 5.296405 0.11365985      Pl_0   1        Placebo_0 #> 236       Kivitz 2001  2.000 4.997006 0.12490734      Pl_0   1        Placebo_0 #> 237       Kivitz 2001 12.000 4.862275 0.14493324      Pl_0   1        Placebo_0 #> 238       Kivitz 2001  0.000 5.266465 0.11587666   Na_1000   2    Naproxen_1000 #> 239       Kivitz 2001  2.000 3.896707 0.07993053   Na_1000   2    Naproxen_1000 #> 240       Kivitz 2001 12.000 3.994012 0.09000872   Na_1000   2    Naproxen_1000 #> 241       Kivitz 2001  0.000 5.416170 0.11432410    Ce_400   3     Celebrex_400 #> 242       Kivitz 2001  2.000 4.136228 0.11773760    Ce_400   3     Celebrex_400 #> 243       Kivitz 2001 12.000 4.248502 0.12824272    Ce_400   3     Celebrex_400 #> 244       Kivitz 2001  0.000 5.303890 0.11595175    Ce_200   4     Celebrex_200 #> 245       Kivitz 2001  2.000 4.046407 0.11936596    Ce_200   4     Celebrex_200 #> 246       Kivitz 2001 12.000 4.255988 0.13013062    Ce_200   4     Celebrex_200 #> 247       Kivitz 2001  0.000 5.244010 0.11372082    Ce_100   5     Celebrex_100 #> 248       Kivitz 2001  2.000 4.398204 0.15003125    Ce_100   5     Celebrex_100 #> 249       Kivitz 2001 12.000 4.495509 0.15003125    Ce_100   5     Celebrex_100 #> 250       Kivitz 2002  0.000 5.400000 0.11993228      Pl_0   1        Placebo_0 #> 251       Kivitz 2002  2.000 4.450000 0.12534348      Pl_0   1        Placebo_0 #> 252       Kivitz 2002  6.000 4.200000 0.13397271      Pl_0   1        Placebo_0 #> 253       Kivitz 2002 12.000 4.150000 0.14364307      Pl_0   1        Placebo_0 #> 254       Kivitz 2002  0.000 5.350000 0.12011743   Na_1000   2    Naproxen_1000 #> 255       Kivitz 2002  2.000 3.950000 0.12308383   Na_1000   2    Naproxen_1000 #> 256       Kivitz 2002  6.000 3.800000 0.12840184   Na_1000   2    Naproxen_1000 #> 257       Kivitz 2002 12.000 3.700000 0.13427651   Na_1000   2    Naproxen_1000 #> 258       Kivitz 2002  0.000 5.400000 0.12107291      Va_5   3     Valdecoxib_5 #> 259       Kivitz 2002  2.000 4.100000 0.12407956      Va_5   3     Valdecoxib_5 #> 260       Kivitz 2002  6.000 3.850000 0.12945933      Va_5   3     Valdecoxib_5 #> 261       Kivitz 2002 12.000 3.800000 0.13543772      Va_5   3     Valdecoxib_5 #> 262       Kivitz 2002  0.000 5.350000 0.12095716     Va_20   4    Valdecoxib_20 #> 263       Kivitz 2002  2.000 3.900000 0.12456927     Va_20   4    Valdecoxib_20 #> 264       Kivitz 2002  6.000 3.700000 0.12930072     Va_20   4    Valdecoxib_20 #> 265       Kivitz 2002 12.000 3.700000 0.13516536     Va_20   4    Valdecoxib_20 #> 266       Kivitz 2002  0.000 5.500000 0.11988167     Va_10   5    Valdecoxib_10 #> 267       Kivitz 2002  2.000 3.950000 0.12302862     Va_10   5    Valdecoxib_10 #> 268       Kivitz 2002  6.000 3.950000 0.12792257     Va_10   5    Valdecoxib_10 #> 269       Kivitz 2002 12.000 3.950000 0.13378317     Va_10   5    Valdecoxib_10 #> 270      Lehmann 2005  0.000 4.900000 0.07770287      Pl_0   1        Placebo_0 #> 271      Lehmann 2005  2.000 4.350000 0.08237490      Pl_0   1        Placebo_0 #> 272      Lehmann 2005 13.000 3.650000 0.09589396      Pl_0   1        Placebo_0 #> 273      Lehmann 2005  0.000 5.100000 0.07880393    Ce_200   2     Celebrex_200 #> 274      Lehmann 2005  2.000 3.850000 0.08116206    Ce_200   2     Celebrex_200 #> 275      Lehmann 2005 13.000 3.400000 0.08923811    Ce_200   2     Celebrex_200 #> 276      Lehmann 2005  0.000 4.950000 0.07782803    Lu_200   3  Lumiracoxib_200 #> 277      Lehmann 2005  2.000 3.900000 0.08112612    Lu_200   3  Lumiracoxib_200 #> 278      Lehmann 2005 13.000 3.350000 0.08920896    Lu_200   3  Lumiracoxib_200 #> 279      Lehmann 2005  0.000 4.950000 0.07880393    Lu_100   4  Lumiracoxib_100 #> 280      Lehmann 2005  2.000 3.750000 0.08124250    Lu_100   4  Lumiracoxib_100 #> 281      Lehmann 2005 13.000 3.250000 0.08923133    Lu_100   4  Lumiracoxib_100 #> 282        Leung 2002  0.000 6.870000 0.20939918      Pl_0   1        Placebo_0 #> 283        Leung 2002  2.000 5.530000 0.23627637      Pl_0   1        Placebo_0 #> 284        Leung 2002  4.000 5.400000 0.24560040      Pl_0   1        Placebo_0 #> 285        Leung 2002  8.000 5.160000 0.25982124      Pl_0   1        Placebo_0 #> 286        Leung 2002 12.000 5.340000 0.27087539      Pl_0   1        Placebo_0 #> 287        Leung 2002  0.000 6.564000 0.11522885   Na_1000   2    Naproxen_1000 #> 288        Leung 2002  2.000 3.974000 0.11677361   Na_1000   2    Naproxen_1000 #> 289        Leung 2002  4.000 4.034000 0.11914814   Na_1000   2    Naproxen_1000 #> 290        Leung 2002  8.000 4.034000 0.12366869   Na_1000   2    Naproxen_1000 #> 291        Leung 2002 12.000 4.084000 0.12715119   Na_1000   2    Naproxen_1000 #> 292        Leung 2002  0.000 6.491000 0.11198246     Et_60   3    Etoricoxib_60 #> 293        Leung 2002  2.000 4.041000 0.11590711     Et_60   3    Etoricoxib_60 #> 294        Leung 2002  4.000 4.021000 0.11857705     Et_60   3    Etoricoxib_60 #> 295        Leung 2002  8.000 3.901000 0.12290712     Et_60   3    Etoricoxib_60 #> 296        Leung 2002 12.000 3.801000 0.12652421     Et_60   3    Etoricoxib_60 #> 297    Markenson 2005  0.000 6.130000 0.31002201      Pl_0   1        Placebo_0 #> 298    Markenson 2005  2.142 5.830000 0.31002201      Pl_0   1        Placebo_0 #> 299    Markenson 2005  4.286 5.720000 0.31002201      Pl_0   1        Placebo_0 #> 300    Markenson 2005  6.429 5.940000 0.31002201      Pl_0   1        Placebo_0 #> 301    Markenson 2005  8.571 5.980000 0.31002201      Pl_0   1        Placebo_0 #> 302    Markenson 2005 12.857 5.980000 0.31002201      Pl_0   1        Placebo_0 #> 303    Markenson 2005  0.000 6.310000 0.27995615     Ox_44   2     Oxycodone_44 #> 304    Markenson 2005  2.142 4.830000 0.27995615     Ox_44   2     Oxycodone_44 #> 305    Markenson 2005  4.286 5.020000 0.27995615     Ox_44   2     Oxycodone_44 #> 306    Markenson 2005  6.429 4.760000 0.27995615     Ox_44   2     Oxycodone_44 #> 307    Markenson 2005  8.571 4.720000 0.27995615     Ox_44   2     Oxycodone_44 #> 308    Markenson 2005 12.857 4.940000 0.27995615     Ox_44   2     Oxycodone_44 #> 309      McKenna 2001  0.000 5.350000 0.11667262      Pl_0   1        Placebo_0 #> 310      McKenna 2001  6.000 5.350000 0.12868684      Pl_0   1        Placebo_0 #> 311      McKenna 2001  0.000 5.300000 0.10987659    Ce_200   2     Celebrex_200 #> 312      McKenna 2001  6.000 5.300000 0.12302332    Ce_200   2     Celebrex_200 #> 313      Puopolo 2007  0.000 6.466000 0.16356491      Pl_0   1        Placebo_0 #> 314      Puopolo 2007  2.000 5.236000 0.17148452      Pl_0   1        Placebo_0 #> 315      Puopolo 2007  4.000 5.186000 0.17771766      Pl_0   1        Placebo_0 #> 316      Puopolo 2007  8.000 4.686000 0.18879059      Pl_0   1        Placebo_0 #> 317      Puopolo 2007 12.000 4.716000 0.19583685      Pl_0   1        Placebo_0 #> 318      Puopolo 2007  0.000 6.646000 0.11544539     Et_30   2    Etoricoxib_30 #> 319      Puopolo 2007  2.000 4.416000 0.11860337     Et_30   2    Etoricoxib_30 #> 320      Puopolo 2007  4.000 4.146000 0.12123458     Et_30   2    Etoricoxib_30 #> 321      Puopolo 2007  8.000 3.646000 0.12544008     Et_30   2    Etoricoxib_30 #> 322      Puopolo 2007 12.000 3.656000 0.12905699     Et_30   2    Etoricoxib_30 #> 323     Sawitzke 2010  0.000 4.790000 0.14954087      Pl_0   1        Placebo_0 #> 324     Sawitzke 2010  4.000 3.420000 0.16328616      Pl_0   1        Placebo_0 #> 325     Sawitzke 2010  8.000 3.080000 0.17919315      Pl_0   1        Placebo_0 #> 326     Sawitzke 2010 16.000 2.790000 0.19864814      Pl_0   1        Placebo_0 #> 327     Sawitzke 2010 24.000 2.700000 0.20921215      Pl_0   1        Placebo_0 #> 328     Sawitzke 2010  0.000 4.660000 0.14429790    Ce_200   2     Celebrex_200 #> 329     Sawitzke 2010  4.000 3.080000 0.15170564    Ce_200   2     Celebrex_200 #> 330     Sawitzke 2010  8.000 2.630000 0.15982418    Ce_200   2     Celebrex_200 #> 331     Sawitzke 2010 16.000 2.600000 0.17277095    Ce_200   2     Celebrex_200 #> 332     Sawitzke 2010 24.000 2.140000 0.18297588    Ce_200   2     Celebrex_200 #> 333  Schnitzer 2005_2  0.000 6.600000 0.16571813      Pl_0   1        Placebo_0 #> 334  Schnitzer 2005_2  1.000 4.390000 0.17390525      Pl_0   1        Placebo_0 #> 335  Schnitzer 2005_2  2.000 4.410000 0.17768641      Pl_0   1        Placebo_0 #> 336  Schnitzer 2005_2  4.000 4.050000 0.18398436      Pl_0   1        Placebo_0 #> 337  Schnitzer 2005_2  6.000 3.970000 0.18952849      Pl_0   1        Placebo_0 #> 338  Schnitzer 2005_2  0.000 6.500000 0.15993856   Na_1000   2    Naproxen_1000 #> 339  Schnitzer 2005_2  1.000 3.450000 0.16243804   Na_1000   2    Naproxen_1000 #> 340  Schnitzer 2005_2  2.000 3.000000 0.16392544   Na_1000   2    Naproxen_1000 #> 341  Schnitzer 2005_2  4.000 2.760000 0.16789523   Na_1000   2    Naproxen_1000 #> 342  Schnitzer 2005_2  6.000 2.690000 0.17061128   Na_1000   2    Naproxen_1000 #> 343  Schnitzer 2005_2  0.000 6.700000 0.15640983   Na_1500   3 Naproxcinod_1500 #> 344  Schnitzer 2005_2  1.000 3.430000 0.16417310   Na_1500   3 Naproxcinod_1500 #> 345  Schnitzer 2005_2  2.000 3.180000 0.16645459   Na_1500   3 Naproxcinod_1500 #> 346  Schnitzer 2005_2  4.000 2.880000 0.16974660   Na_1500   3 Naproxcinod_1500 #> 347  Schnitzer 2005_2  6.000 2.730000 0.17321634   Na_1500   3 Naproxcinod_1500 #> 348  Schnitzer 2005_2  0.000 6.500000 0.16970563     Ro_25   4     Rofecoxib_25 #> 349  Schnitzer 2005_2  1.000 3.320000 0.17658562     Ro_25   4     Rofecoxib_25 #> 350  Schnitzer 2005_2  2.000 3.160000 0.17939738     Ro_25   4     Rofecoxib_25 #> 351  Schnitzer 2005_2  4.000 2.970000 0.18349812     Ro_25   4     Rofecoxib_25 #> 352  Schnitzer 2005_2  6.000 2.900000 0.18625935     Ro_25   4     Rofecoxib_25 #> 353  Schnitzer 2005_2  0.000 6.600000 0.17111236    Na_750   5  Naproxcinod_750 #> 354  Schnitzer 2005_2  1.000 3.330000 0.16997392    Na_750   5  Naproxcinod_750 #> 355  Schnitzer 2005_2  2.000 2.950000 0.17160362    Na_750   5  Naproxcinod_750 #> 356  Schnitzer 2005_2  4.000 2.840000 0.17541465    Na_750   5  Naproxcinod_750 #> 357  Schnitzer 2005_2  6.000 2.790000 0.17898501    Na_750   5  Naproxcinod_750 #> 358  Schnitzer 2005_2  0.000 6.700000 0.18336859    Na_250   6  Naproxcinod_250 #> 359  Schnitzer 2005_2  1.000 4.550000 0.17227298    Na_250   6  Naproxcinod_250 #> 360  Schnitzer 2005_2  2.000 4.170000 0.17410810    Na_250   6  Naproxcinod_250 #> 361  Schnitzer 2005_2  4.000 4.140000 0.17815403    Na_250   6  Naproxcinod_250 #> 362  Schnitzer 2005_2  6.000 3.990000 0.18131412    Na_250   6  Naproxcinod_250 #> 363    Schnitzer 2010  0.000 7.215000 0.10649083      Pl_0   1        Placebo_0 #> 364    Schnitzer 2010  2.000 5.265000 0.11319620      Pl_0   1        Placebo_0 #> 365    Schnitzer 2010  6.000 4.945000 0.12136624      Pl_0   1        Placebo_0 #> 366    Schnitzer 2010 13.000 4.655000 0.13216957      Pl_0   1        Placebo_0 #> 367    Schnitzer 2010  0.000 7.101000 0.11400775   Na_1000   2    Naproxen_1000 #> 368    Schnitzer 2010  2.000 3.871000 0.10996805   Na_1000   2    Naproxen_1000 #> 369    Schnitzer 2010  6.000 3.551000 0.11460991   Na_1000   2    Naproxen_1000 #> 370    Schnitzer 2010 13.000 3.331000 0.12044908   Na_1000   2    Naproxen_1000 #> 371    Schnitzer 2010  0.000 7.316000 0.09844550   Na_1500   3 Naproxcinod_1500 #> 372    Schnitzer 2010  2.000 4.016000 0.10918995   Na_1500   3 Naproxcinod_1500 #> 373    Schnitzer 2010  6.000 3.546000 0.11374548   Na_1500   3 Naproxcinod_1500 #> 374    Schnitzer 2010 13.000 3.596000 0.11998801   Na_1500   3 Naproxcinod_1500 #> 375    Schnitzer 2010  0.000 7.358000 0.09927747    Na_750   4  Naproxcinod_750 #> 376    Schnitzer 2010  2.000 4.628000 0.10666145    Na_750   4  Naproxcinod_750 #> 377    Schnitzer 2010  6.000 4.118000 0.11133092    Na_750   4  Naproxcinod_750 #> 378    Schnitzer 2010 13.000 3.918000 0.11741286    Na_750   4  Naproxcinod_750 #> 379 Schnitzer 2011LUM  0.000 5.300000 0.07329841      Pl_0   1        Placebo_0 #> 380 Schnitzer 2011LUM  4.000 4.420000 0.08359282      Pl_0   1        Placebo_0 #> 381 Schnitzer 2011LUM  8.000 4.255000 0.08894068      Pl_0   1        Placebo_0 #> 382 Schnitzer 2011LUM 13.000 4.140000 0.09407760      Pl_0   1        Placebo_0 #> 383 Schnitzer 2011LUM  0.000 5.400000 0.07279126    Ce_200   2     Celebrex_200 #> 384 Schnitzer 2011LUM  4.000 3.860000 0.08060813    Ce_200   2     Celebrex_200 #> 385 Schnitzer 2011LUM  8.000 3.580000 0.08354665    Ce_200   2     Celebrex_200 #> 386 Schnitzer 2011LUM 13.000 3.545000 0.08671550    Ce_200   2     Celebrex_200 #> 387 Schnitzer 2011LUM  0.000 5.400000 0.07863926    Lu_100   3  Lumiracoxib_100 #> 388 Schnitzer 2011LUM  4.000 3.880000 0.07981473    Lu_100   3  Lumiracoxib_100 #> 389 Schnitzer 2011LUM  8.000 3.585000 0.08284601    Lu_100   3  Lumiracoxib_100 #> 390 Schnitzer 2011LUM 13.000 3.585000 0.08591064    Lu_100   3  Lumiracoxib_100 #> 391      Sheldon 2005  0.000 5.500000 0.07393263      Pl_0   1        Placebo_0 #> 392      Sheldon 2005 13.000 4.350000 0.09856959      Pl_0   1        Placebo_0 #> 393      Sheldon 2005  0.000 5.400000 0.08171819    Ce_200   2     Celebrex_200 #> 394      Sheldon 2005 13.000 3.700000 0.08986899    Ce_200   2     Celebrex_200 #> 395      Sheldon 2005  0.000 5.400000 0.07813401    Lu_100   3  Lumiracoxib_100 #> 396      Sheldon 2005 13.000 3.600000 0.09022642    Lu_100   3  Lumiracoxib_100 #> 397      Sheldon 2005  0.000 5.400000 0.08077908     Lu_NA   4   Lumiracoxib_NA #> 398      Sheldon 2005 13.000 3.550000 0.09065824     Lu_NA   4   Lumiracoxib_NA #> 399       Sowers 2005  0.000 4.800000 0.19003495   Na_1000   1    Naproxen_1000 #> 400       Sowers 2005  6.000 3.480000 0.21001071   Na_1000   1    Naproxen_1000 #> 401       Sowers 2005 12.000 3.340000 0.23997436   Na_1000   1    Naproxen_1000 #> 402       Sowers 2005  0.000 4.280000 0.19002043    Ce_200   2     Celebrex_200 #> 403       Sowers 2005  6.000 2.970000 0.19002043    Ce_200   2     Celebrex_200 #> 404       Sowers 2005 12.000 2.780000 0.19996735    Ce_200   2     Celebrex_200 #> 405       Sowers 2005  0.000 4.850000 0.19000576     Ro_25   3     Rofecoxib_25 #> 406       Sowers 2005  6.000 3.360000 0.20001523     Ro_25   3     Rofecoxib_25 #> 407       Sowers 2005 12.000 3.180000 0.22003416     Ro_25   3     Rofecoxib_25 #> 408   Tannenbaum 2004  0.000 5.150000 0.09622504      Pl_0   1        Placebo_0 #> 409   Tannenbaum 2004  2.000 4.450000 0.11095877      Pl_0   1        Placebo_0 #> 410   Tannenbaum 2004 13.000 3.950000 0.12879815      Pl_0   1        Placebo_0 #> 411   Tannenbaum 2004  0.000 5.050000 0.07523352    Ce_200   2     Celebrex_200 #> 412   Tannenbaum 2004  2.000 3.850000 0.07727746    Ce_200   2     Celebrex_200 #> 413   Tannenbaum 2004 13.000 3.500000 0.08489279    Ce_200   2     Celebrex_200 #> 414   Tannenbaum 2004  0.000 5.000000 0.07446346    Lu_400   3  Lumiracoxib_400 #> 415   Tannenbaum 2004  2.000 3.700000 0.07649130    Lu_400   3  Lumiracoxib_400 #> 416   Tannenbaum 2004 13.000 3.400000 0.08413371    Lu_400   3  Lumiracoxib_400 #> 417   Tannenbaum 2004  0.000 5.050000 0.07703435    Lu_200   4  Lumiracoxib_200 #> 418   Tannenbaum 2004  2.000 3.750000 0.07698671    Lu_200   4  Lumiracoxib_200 #> 419   Tannenbaum 2004 13.000 3.450000 0.08442820    Lu_200   4  Lumiracoxib_200 #> 420     Williams 2001  0.000 5.300000 0.10007405      Pl_0   1        Placebo_0 #> 421     Williams 2001  6.000 4.400000 0.10007405      Pl_0   1        Placebo_0 #> 422     Williams 2001  0.000 5.050000 0.15008849    Ce_200   2     Celebrex_200 #> 423     Williams 2001  6.000 3.750000 0.10016636    Ce_200   2     Celebrex_200  # Define network network <- mb.network(osteopain, description=\"Osteoarthritis Dataset\") #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Define network with different network reference treatment network <- mb.network(osteopain, reference=\"Ce_200\") #> Studies reporting change from baseline automatically identified from the data   # Using the alogliptin dataset network <- mb.network(alog_pcfb, description=\"Alogliptin Dataset\") #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data  # Examine networks print(network) #> description : #> [1] \"Alogliptin Dataset\" #>  #> data.ab : #>   studyID time treatment narm arm     y    se  n clinicaltrialGov_ID      agent #> 1      11    6         1    6   1  0.02 0.097 41         NCT00755846 alogliptin #> 2      11    6         2    6   2 -0.12 0.095 42         NCT00755846 alogliptin #> 3      11    6         3    6   3 -0.35 0.096 42         NCT00755846 alogliptin #> 4      11    6         4    6   4 -0.36 0.093 45         NCT00755846 alogliptin #> 5      11    6         5    6   5 -0.32 0.097 43         NCT00755846 alogliptin #> 6      11    6         6    6   6 -0.31 0.094 44         NCT00755846 alogliptin #>     dose fupcount fups #> 1   0.00        1    2 #> 2   6.25        1    2 #> 3  12.50        1    2 #> 4  25.00        1    2 #> 5  50.00        1    2 #> 6 100.00        1    2 #>  [ reached 'max' / getOption(\"max.print\") -- omitted 227 rows ] #>  #> studyID : #>  [1] \"11\" \"1\"  \"3\"  \"2\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"14\" \"12\" \"13\" #>  #> cfb : #>  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE #>  #> treatments : #> [1] \"placebo\"   \"alog_6.25\" \"alog_12.5\" \"alog_25\"   \"alog_50\"   \"alog_100\"  #>  plot(network)"},{"path":"/reference/mb.nodesplit.comparisons.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify comparisons in time-course MBNMA datasets that fulfil criteria for node-splitting — mb.nodesplit.comparisons","title":"Identify comparisons in time-course MBNMA datasets that fulfil criteria for node-splitting — mb.nodesplit.comparisons","text":"Identify comparisons informed direct indirect evidence independent sources MBNMA datasets repeated measurements study. comparisons therefore fulfil criteria testing inconsistency via node-splitting, following method van Valkenhoef van Valkenhoef et al. (2016) .","code":""},{"path":"/reference/mb.nodesplit.comparisons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify comparisons in time-course MBNMA datasets that fulfil criteria for node-splitting — mb.nodesplit.comparisons","text":"","code":"mb.nodesplit.comparisons(network)"},{"path":"/reference/mb.nodesplit.comparisons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify comparisons in time-course MBNMA datasets that fulfil criteria for node-splitting — mb.nodesplit.comparisons","text":"network object class \"mb.network\".","code":""},{"path":"/reference/mb.nodesplit.comparisons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify comparisons in time-course MBNMA datasets that fulfil criteria for node-splitting — mb.nodesplit.comparisons","text":"data frame comparisons informed direct indirect evidence independent sources. row data frame different treatment comparison. Numerical codes t1 t2 correspond treatment codes.","code":""},{"path":"/reference/mb.nodesplit.comparisons.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Identify comparisons in time-course MBNMA datasets that fulfil criteria for node-splitting — mb.nodesplit.comparisons","text":"Similar gemtc::mtc.nodesplit() uses fixed reference treatment therefore suggests fewer loops test inconsistency. Heterogeneity can also parameterised inconsistency testing inconsistency additional loops whilst changing reference treatment also identifying heterogeneity. Depends igraph.","code":""},{"path":"/reference/mb.nodesplit.comparisons.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Identify comparisons in time-course MBNMA datasets that fulfil criteria for node-splitting — mb.nodesplit.comparisons","text":"van Valkenhoef G, Dias S, Ades AE, Welton NJ (2016). “Automated generation node-splitting models assessment inconsistency network meta-analysis.” Res Synth Methods, 7(1), 80-93. ISSN 1759-2887 (Electronic) 1759-2879 (Linking), doi:10.1002/jrsm.1167 , https://pubmed.ncbi.nlm.nih.gov/26461181/.","code":""},{"path":"/reference/mb.nodesplit.comparisons.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify comparisons in time-course MBNMA datasets that fulfil criteria for node-splitting — mb.nodesplit.comparisons","text":"","code":"# Create mb.network object network <- mb.network(osteopain) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Identify comparisons informed by direct and indirect evidence mb.nodesplit.comparisons(network) #>   t1 t2     path #> 5  3 22 3->1->22 #> 4  3 15 3->1->15"},{"path":"/reference/mb.nodesplit.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform node-splitting on a MBNMA time-course network — plot.nodesplit","title":"Perform node-splitting on a MBNMA time-course network — plot.nodesplit","text":"Within MBNMA time-course network, split contributions direct indirect evidence test consistency . Closed loops treatments possible test consistency direct indirect evidence available independent sources van Valkenhoef van Valkenhoef et al. (2016) .","code":""},{"path":"/reference/mb.nodesplit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform node-splitting on a MBNMA time-course network — plot.nodesplit","text":"","code":"# S3 method for nodesplit plot(x, plot.type = NULL, params = NULL, ...)  mb.nodesplit(   network,   comparisons = mb.nodesplit.comparisons(network),   nodesplit.parameters = \"all\",   fun = tpoly(degree = 1),   times = NULL,   lim = \"cred\",   ... )"},{"path":"/reference/mb.nodesplit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform node-splitting on a MBNMA time-course network — plot.nodesplit","text":"x object class(\"nodesplit\") plot.type character string can take value \"forest\" plot forest plots, \"density\" plot density plots, left NULL (default) plot types plot. params character vector corresponding time-course parameter(s) plot results. left NULL (default), nodes-split results time-course parameters plotted. ... Arguments sent mb.run() network object class \"mb.network\". comparisons data frame specifying comparisons split (one row per comparison). frame two columns indicating treatment comparison: t1 t2. nodesplit.parameters character vector named time-course parameters node-split (e.g. c(\"beta.1\", \"beta.2\")). Can use \"\" split time-course parameters. fun object class \"timefun\" generated (see Details) using tloglin(), tpoly(), titp(), temax(), tfpoly(), tspline() tuser() times sequence positive numbers indicating time points predict mean responses (conduct node-split used mb.nodesplit()) lim Specifies calculation either 95% credible intervals (lim=\"cred\") 95% prediction intervals (lim=\"pred\").","code":""},{"path":"/reference/mb.nodesplit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform node-splitting on a MBNMA time-course network — plot.nodesplit","text":"Plots desired graph(s) returns object (list objects plot.type=NULL) class(c(\"gg\", \"ggplot\")), can edited using ggplot commands. object class(\"mb.nodesplit\") list containing elements d.X.Y (treatment 1 = X, treatment 2 = Y). element (corresponding comparison) contains additional numbered elements corresponding parameter time-course function node splitting performed. elements contain: overlap matrix MCMC results difference direct indirect evidence p.values Bayesian p-value test consistency direct indirect evidence quantiles forest.plot density.plot direct MCMC results direct evidence indirect MCMC results indirect evidence","code":""},{"path":"/reference/mb.nodesplit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform node-splitting on a MBNMA time-course network — plot.nodesplit","text":"S3 method plot() mb.nodesplit object generates either forest plots posterior medians 95\\% credible intervals, density plots posterior densities direct indirect evidence. Note specifying times argument user can perform node-split treatment effects specific time-point. give treatment effect direct, indirect, MBNMA estimates time point.","code":""},{"path":"/reference/mb.nodesplit.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Perform node-splitting on a MBNMA time-course network — plot.nodesplit","text":"plot(nodesplit): Plot outputs nodesplit models","code":""},{"path":"/reference/mb.nodesplit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Perform node-splitting on a MBNMA time-course network — plot.nodesplit","text":"van Valkenhoef G, Dias S, Ades AE, Welton NJ (2016). “Automated generation node-splitting models assessment inconsistency network meta-analysis.” Res Synth Methods, 7(1), 80-93. ISSN 1759-2887 (Electronic) 1759-2879 (Linking), doi:10.1002/jrsm.1167 , https://pubmed.ncbi.nlm.nih.gov/26461181/.","code":""},{"path":"/reference/mb.nodesplit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform node-splitting on a MBNMA time-course network — plot.nodesplit","text":"","code":"# \\donttest{ # Create mb.network object painnet <- mb.network(osteopain) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Identify comparisons informed by direct and indirect evidence splits <- mb.nodesplit.comparisons(painnet)  # Fit a log-linear time-course MBNMA (takes a while to run) result <- mb.nodesplit(painnet, comparisons=splits, nodesplit.parameters=\"all\",   fun=tloglin(pool.rate=\"rel\", method.rate=\"common\"),   rho=\"dunif(0,1)\", covar=\"varadj\"   ) #> [1] \"running checks\" #> [1] \"Running NMA model\" #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 89 #>    Total graph size: 7303 #>  #> Initializing model #>  #> [1] \"Comparison 1/2\" #> [1] \"Calculating nodesplit for: Ce_200 vs Ro_25\" #> [1] \"Treatment code: 3 vs 22\" #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 467 #>    Total graph size: 7651 #>  #> Initializing model #>  #> [1] \"Direct complete\" #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 414 #>    Unobserved stochastic nodes: 89 #>    Total graph size: 7251 #>  #> Initializing model #>  #> [1] \"Indirect complete\" #> [1] \"Comparison 2/2\" #> [1] \"Calculating nodesplit for: Ce_200 vs Na_1000\" #> [1] \"Treatment code: 3 vs 15\" #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 467 #>    Total graph size: 7651 #>  #> Initializing model #>  #> [1] \"Direct complete\" #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 408 #>    Unobserved stochastic nodes: 89 #>    Total graph size: 7152 #>  #> Initializing model #>  #> [1] \"Indirect complete\"  # Fit an emax time-course MBNMA with a node-split on emax parameters only result <- mb.nodesplit(painnet, comparisons=splits, nodesplit.parameters=\"emax\",   fun=temax(pool.emax=\"rel\", method.emax=\"common\",     pool.et50=\"rel\", method.et50=\"common\")) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> [1] \"running checks\" #> [1] \"Running NMA model\" #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 146 #>    Total graph size: 8294 #>  #> Initializing model #>  #> [1] \"Comparison 1/2\" #> [1] \"Calculating nodesplit for: Ce_200 vs Ro_25\" #> [1] \"Treatment code: 3 vs 22\" #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 524 #>    Total graph size: 8646 #>  #> Initializing model #>  #> [1] \"Direct complete\" #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 414 #>    Unobserved stochastic nodes: 146 #>    Total graph size: 8237 #>  #> Initializing model #>  #> [1] \"Indirect complete\" #> [1] \"Comparison 2/2\" #> [1] \"Calculating nodesplit for: Ce_200 vs Na_1000\" #> [1] \"Treatment code: 3 vs 15\" #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 524 #>    Total graph size: 8646 #>  #> Initializing model #>  #> [1] \"Direct complete\" #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 408 #>    Unobserved stochastic nodes: 146 #>    Total graph size: 8118 #>  #> Initializing model #>  #> [1] \"Indirect complete\"  # Inspect results print(result) #> ======================================== #> Node-splitting analysis of inconsistency #> ======================================== #>  #> emax #>  #> |Comparison        | p-value| Median|   2.5%|  97.5%| #> |:-----------------|-------:|------:|------:|------:| #> |Ro_25 vs Ce_200   |   0.086|       |       |       | #> |-> direct         |        |  0.456| -1.887|  8.003| #> |-> indirect       |        | -0.426| -0.734| -0.175| #> |                  |        |       |       |       | #> |Na_1000 vs Ce_200 |   0.014|       |       |       | #> |-> direct         |        | -0.096| -0.265|  0.070| #> |-> indirect       |        | -0.339| -0.462| -0.213| #> |                  |        |       |       |       | summary(result) #>          Comparison Time.Param Evidence Median   2.5%  97.5% p.value #> 1   Ro_25 vs Ce_200       emax   Direct  0.456 -1.887  8.003   0.086 #> 2   Ro_25 vs Ce_200       emax Indirect -0.426 -0.734 -0.175   0.086 #> 3 Na_1000 vs Ce_200       emax   Direct -0.096 -0.265  0.070   0.014 #> 4 Na_1000 vs Ce_200       emax Indirect -0.339 -0.462 -0.213   0.014  # Plot results plot(result)   # }"},{"path":"/reference/mb.run.html","id":null,"dir":"Reference","previous_headings":"","what":"Run MBNMA time-course models — mb.run","title":"Run MBNMA time-course models — mb.run","text":"Fits Bayesian time-course model model-based network meta-analysis (MBNMA) can account repeated measures time within studies applying desired time-course function. Follows methods Pedder et al. (2019) .","code":""},{"path":"/reference/mb.run.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run MBNMA time-course models — mb.run","text":"","code":"mb.run(   network,   fun = tpoly(degree = 1),   positive.scale = FALSE,   intercept = NULL,   link = \"identity\",   parameters.to.save = NULL,   rho = 0,   covar = \"varadj\",   omega = NULL,   corparam = FALSE,   class.effect = list(),   UME = FALSE,   pd = \"pv\",   parallel = FALSE,   priors = NULL,   n.iter = 20000,   n.chains = 3,   n.burnin = floor(n.iter/2),   n.thin = max(1, floor((n.iter - n.burnin)/1000)),   model.file = NULL,   jagsdata = NULL,   ... )"},{"path":"/reference/mb.run.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run MBNMA time-course models — mb.run","text":"network object class \"mb.network\". fun object class \"timefun\" generated (see Details) using tloglin(), tpoly(), titp(), temax(), tfpoly(), tspline() tuser() positive.scale boolean object indicates whether continuous mean responses (y) positive therefore whether baseline response given prior constrains positive (e.g. scales <0). intercept boolean object indicates whether intercept (written alpha model) included. left NULL (default), intercept included studies reporting absolute means, excluded studies reporting change baseline (indicated network$cfb). link Can take either \"identity\" (default), \"log\" (modelling Ratios Means (Friedrich et al. 2011) ) \"smd\" (modelling Standardised Mean Differences - although also corresponds identity link function). parameters..save character vector containing names parameters monitor JAGS rho correlation coefficient modelling within-study correlation time points. default string representing prior distribution JAGS, indicating estimated data (e.g. rho=\"dunif(0,1)\"). rho also assigned numeric value (e.g. rho=0.7), fixes rho model value (e.g. use deterministic sensitivity analysis). set rho=0 (default) implies modelling correlation time points. covar character specifying covariance structure use modelling within-study correlation time-points. can done specifying one following: \"varadj\" - univariate likelihood variance adjustment assume constant correlation subsequent time points (Jansen et al. 2015) . default. \"CS\" - multivariate normal likelihood compound symmetry structure \"AR1\" - multivariate normal likelihood autoregressive AR1 structure omega DEPRACATED VERSION 0.2.3 ONWARDS (~uniform(-1,1) now used correlation parameters rather Wishart prior). scale matrix inverse-Wishart prior covariance matrix used model correlation time-course parameters (see Details time-course functions). omega must symmetric positive definite matrix dimensions equal number time-course parameters modelled using relative effects (pool=\"rel\"). left NULL (default) diagonal matrix elements equal 1 used. corparam boolean object indicates whether correlation modeled relative effect time-course parameters. Default FALSE automatically set FALSE class effects modeled. Setting TRUE models correlation time-course parameters. can help identify parameters estimated poorly treatments allowing sharing information parameters different treatments network, may also cause shrinkage. class.effect list named strings determines time-course parameters model class effect effect (\"common\" \"random\"). example: list(emax=\"common\", et50=\"random\"). UME Can take either TRUE FALSE (unrelated mean effects model time-course parameters respectively) can vector parameter name strings model UME. example: c(\"beta.1\", \"beta.2\"). pd Can take either: pv pV reported (automatically outputted R2jags). plugin calculates pD plug-method (Spiegelhalter et al. 2002) . faster, may output negative non-sensical values, due skewed deviances can arise non-linear models. pd.kl (default) calculates pD Kullback–Leibler divergence (Plummer 2008) . require running model additional iterations always produce sensical result. popt calculates pD using optimism adjustment allows calculation penalized expected deviance (Plummer 2008) parallel boolean value indicates whether JAGS run parallel (TRUE) (FALSE). TRUE number cores use automatically calculated. Functions involve updating model (e.g. devplot(), fitplot()) used models implemented parallel. priors named list parameter values (without indices) replacement prior distribution values given strings using distributions specified JAGS syntax (see Plummer (2017) ). n.iter number total iterations per chain (including burn ; default: 20000) n.chains number Markov chains (default: 3) n.burnin length burn , .e. number iterations discard beginning. Default n.iter/2``, , discarding first half simulations. n.burnin` 0, jags() run 100 iterations adaption. n.thin thinning rate. Must positive integer. Set n.thin > 1`` save memory computation time n.iteris large. Default ismax(1, floor(n.chains * (n.iter-n.burnin) / 1000))`` thin least 2000 simulations. model.file file path JAGS model (.jags file) can used overwrite JAGS model automatically written based specified options MBNMAtime. Useful adding model flexibility. jagsdata named list data objects used JAGS model. required users defining JAGS model using model.file. Format match standard models fitted MBNMAtime (see mbnma$model.arg$jagsdata) ... Arguments sent R2jags.","code":""},{"path":"/reference/mb.run.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run MBNMA time-course models — mb.run","text":"object S3 class c(\"mbnma\", \"rjags\")`` containing parameter results model. Can summarized print()can check traceplots usingR2jags::traceplot()various functions packagemcmcplots`.#' errors JAGS model code object list consisting two elements - error message JAGS can help debugging model.arg, list arguments provided mb.run() includes jagscode, JAGS code model can help users identify source error.","code":""},{"path":"/reference/mb.run.html","id":"time-course-parameters","dir":"Reference","previous_headings":"","what":"Time-course parameters","title":"Run MBNMA time-course models — mb.run","text":"Nodes automatically monitored (present model) name time-course function named time-course parameters (e.g. emax). However, named beta.1, beta.2, beta.3 beta.4 parameters may alternative interpretation. Details interpretation model specification different parameters can shown using summary() method \"mbnma\" object generated mb.run(). Parameters modelled using relative effects pooling relative (e.g. pool.1=\"rel\") given parameter named parameter (e.g. emax) numbered d parameter (e.g. d.1) corresponds pooled relative effect given treatment compared network reference treatment time-course parameter. sd. followed named (e.g. emax, beta.1) -study SD (heterogeneity) relative effects, reported pooling time-course parameter relative (e.g. pool.1=\"rel\") method synthesis random (e.g. method.1=\"random). class effects modelled, parameters classes represented upper case name time-course parameter correspond . example class.effect=list(emax=\"random\"), relative class effects represented EMAX. SD class effect (e.g. sd.EMAX, sd.BETA.1) SD treatments within class time-course parameter correspond . Parameters modelled using absolute effects pooling absolute (e.g. pool.1=\"abs\") given parameter named parameter (e.g. emax) numbered beta parameter (e.g. beta.1) corresponds estimated absolute effect time-course parameter. absolute time-course parameter corresponding method common (e.g. method.1=\"common\") parameter corresponds single common parameter estimated across studies treatments. corresponding method random (e.g. method.1=\"random\") parameter mean effect around study-level absolute effects vary SD corresponding sd. followed named parameter (e.g. sd.emax, sd.beta.1) . model parameters rho correlation coefficient correlation time-points. interpretation differ depending covariance structure specified covar totresdev residual deviance model deviance deviance model","code":""},{"path":"/reference/mb.run.html","id":"time-course-function","dir":"Reference","previous_headings":"","what":"Time-course function","title":"Run MBNMA time-course models — mb.run","text":"Several general time-course functions 4 time-course parameters provided, user-defined time-course relationship can instead used. Details can found respective help files function. Available time-course functions : Log-linear: tloglin() Polynomial: tpoly() Integrated Two-Component Prediction (ITP): titp() Emax: temax() Fractional polynomial: tfpoly() Splines (various spline types can used): tspline() User-defined: tuser()","code":""},{"path":"/reference/mb.run.html","id":"correlation-between-observations","dir":"Reference","previous_headings":"","what":"Correlation between observations","title":"Run MBNMA time-course models — mb.run","text":"modelling correlation observations using rho, values rho must imply positive semidefinite covariance matrix.","code":""},{"path":"/reference/mb.run.html","id":"advanced-options","dir":"Reference","previous_headings":"","what":"Advanced options","title":"Run MBNMA time-course models — mb.run","text":"model.file jagsdata can used run edited JAGS model dataset. allows users considerably modelling flexibility possible using basic MBNMAtime syntax, though requires strong understanding JAGS MBNMA modelling framework. Treatment-specific priors, meta-regression bias-adjustment possible way, allows users make use subsequent functions MBNMAtime (plotting, prediction, ranking) whilst fitting complex models.","code":""},{"path":"/reference/mb.run.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Run MBNMA time-course models — mb.run","text":"Friedrich JO, Adhikari NKJ, Beyene J (2011). “Ratio means analyzing continuous outcomes meta-analysis performed well mean difference methods.” Journal Clinical Epidemiology, 64(5), 556-564. doi:10.1016/j.jclinepi.2010.09.016 . Jansen JP, Vieira MC, Cope S (2015). “Network meta-analysis longitudinal data using fractional polynomials.” Stat Med, 34(15), 2294-311. ISSN 1097-0258 (Electronic) 0277-6715 (Linking), doi:10.1002/sim.6492 , https://pubmed.ncbi.nlm.nih.gov/25877808/. Pedder H, Dias S, Bennetts M, Boucher M, Welton NJ (2019). “Modelling time-course relationships multiple treatments: Model-Based Network Meta-Analysis continuous summary outcomes.” Res Synth Methods, 10(2), 267-286. Plummer M (2008). “Penalized loss functions Bayesian model comparison.” Biostatistics, 9(3), 523-39. ISSN 1468-4357 (Electronic) 1465-4644 (Linking), https://pubmed.ncbi.nlm.nih.gov/18209015/. Plummer M (2017). JAGS user manual. https://people.stat.sc.edu/hansont/stat740/jags_user_manual.pdf. Spiegelhalter DJ, Best NG, Carlin BP, van der Linde (2002). “Bayesian measures model complexity fit.” J R Statistic Soc B, 64(4), 583-639.","code":""},{"path":"/reference/mb.run.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run MBNMA time-course models — mb.run","text":"","code":"# \\donttest{ # Create mb.network object network <- mb.network(osteopain) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Fit a linear time-course MBNMA with: # random relative treatment effects on the slope mb.run(network, fun=tpoly(degree=1, pool.1=\"rel\", method.1=\"random\")) #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 163 #>    Total graph size: 7701 #>  #> Initializing model #>  #> Inference for Bugs model at \"/tmp/RtmprYte33/file20665e3bae48\", fit using jags, #>  3 chains, each with 20000 iterations (first 10000 discarded), n.thin = 10 #>  n.sims = 3000 iterations saved #>            mu.vect sd.vect     2.5%      25%      50%      75%    97.5%  Rhat #> d.1[1]       0.000   0.000    0.000    0.000    0.000    0.000    0.000 1.000 #> d.1[2]      -0.064   0.045   -0.153   -0.095   -0.064   -0.035    0.024 1.002 #> d.1[3]      -0.094   0.018   -0.129   -0.106   -0.094   -0.082   -0.059 1.002 #> d.1[4]      -0.095   0.044   -0.182   -0.125   -0.094   -0.064   -0.008 1.001 #> d.1[5]      -0.044   0.052   -0.145   -0.079   -0.046   -0.010    0.063 1.002 #> d.1[6]       0.002   0.070   -0.135   -0.043    0.002    0.049    0.139 1.001 #> d.1[7]      -0.148   0.035   -0.217   -0.172   -0.147   -0.124   -0.079 1.001 #> d.1[8]      -0.028   0.068   -0.164   -0.072   -0.029    0.016    0.107 1.001 #> d.1[9]      -0.290   0.050   -0.389   -0.324   -0.289   -0.256   -0.196 1.002 #> d.1[10]     -0.305   0.068   -0.442   -0.350   -0.303   -0.260   -0.175 1.001 #> d.1[11]     -0.076   0.037   -0.151   -0.100   -0.076   -0.052   -0.002 1.001 #> d.1[12]     -0.069   0.037   -0.143   -0.093   -0.068   -0.045    0.004 1.001 #> d.1[13]     -0.082   0.044   -0.168   -0.112   -0.082   -0.053    0.006 1.001 #> d.1[14]     -0.082   0.061   -0.202   -0.124   -0.081   -0.041    0.038 1.001 #> d.1[15]     -0.128   0.025   -0.178   -0.145   -0.128   -0.112   -0.078 1.001 #> d.1[16]     -0.134   0.040   -0.215   -0.161   -0.134   -0.108   -0.055 1.002 #> d.1[17]      0.114   0.065   -0.011    0.070    0.114    0.157    0.242 1.002 #> d.1[18]     -0.128   0.046   -0.220   -0.159   -0.127   -0.097   -0.039 1.001 #> d.1[19]     -0.124   0.077   -0.282   -0.175   -0.124   -0.074    0.027 1.001 #> d.1[20]     -0.115   0.049   -0.211   -0.148   -0.114   -0.084   -0.019 1.001 #> d.1[21]     -0.428   0.075   -0.577   -0.479   -0.428   -0.377   -0.285 1.001 #> d.1[22]     -0.172   0.042   -0.255   -0.200   -0.171   -0.143   -0.092 1.001 #> d.1[23]     -0.031   0.041   -0.110   -0.059   -0.031   -0.003    0.048 1.003 #> d.1[24]     -0.040   0.041   -0.121   -0.068   -0.040   -0.014    0.041 1.003 #> d.1[25]     -0.067   0.040   -0.146   -0.094   -0.066   -0.040    0.013 1.001 #> d.1[26]     -0.084   0.062   -0.206   -0.125   -0.084   -0.044    0.041 1.001 #> d.1[27]     -0.067   0.064   -0.194   -0.107   -0.066   -0.024    0.057 1.001 #> d.1[28]     -0.094   0.066   -0.218   -0.138   -0.095   -0.051    0.039 1.002 #> d.1[29]     -0.078   0.066   -0.207   -0.121   -0.078   -0.035    0.053 1.002 #> rho          0.000   0.000    0.000    0.000    0.000    0.000    0.000 1.000 #> sd.beta.1    0.072   0.009    0.056    0.066    0.072    0.078    0.093 1.001 #> totresdev 9299.256  16.784 9268.779 9287.704 9298.758 9309.882 9335.378 1.004 #> deviance  8419.217  16.784 8388.740 8407.664 8418.718 8429.842 8455.339 1.004 #>           n.eff #> d.1[1]        1 #> d.1[2]     1900 #> d.1[3]     1500 #> d.1[4]     3000 #> d.1[5]     1800 #> d.1[6]     3000 #> d.1[7]     3000 #> d.1[8]     3000 #> d.1[9]     1700 #> d.1[10]    2600 #> d.1[11]    2100 #> d.1[12]    3000 #> d.1[13]    3000 #> d.1[14]    3000 #> d.1[15]    3000 #> d.1[16]    1200 #> d.1[17]    1000 #> d.1[18]    3000 #> d.1[19]    2300 #> d.1[20]    3000 #> d.1[21]    3000 #> d.1[22]    3000 #> d.1[23]     770 #> d.1[24]    1700 #> d.1[25]    3000 #> d.1[26]    3000 #> d.1[27]    3000 #> d.1[28]    1100 #> d.1[29]    1500 #> rho           1 #> sd.beta.1  2800 #> totresdev   690 #> deviance    690 #>  #> For each parameter, n.eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor (at convergence, Rhat=1). #>  #> DIC info (using the rule, pD = var(deviance)/2) #> pD = 140.5 and DIC = 8559.3 #> DIC is an estimate of expected predictive error (lower deviance is better).  # Fit an emax time-course MBNMA with: # fixed relative treatment effects on emax # a common parameter estimated independently of treatment # a common Hill parameter estimated independently of treatment # a prior for the Hill parameter (normal with mean 0 and precision 0.1) # data reported as change from baseline result <- mb.run(network, fun=temax(pool.emax=\"rel\", method.emax=\"common\",                                     pool.et50=\"abs\", method.et50=\"common\",                                     pool.hill=\"abs\", method.hill=\"common\"),                  priors=list(hill=\"dunif(0.5, 2)\"),                  intercept=TRUE) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> 'hill' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 90 #>    Total graph size: 7722 #>  #> Initializing model #>    #### commented out to prevent errors from JAGS version in github actions build #### # Fit a log-linear MBNMA with: # random relative treatment effects on the rate # an autoregressive AR1 covariance structure # modelled as standardised mean differences # copdnet <- mb.network(copd) # result <- mb.run(copdnet, fun=tloglin(pool.rate=\"rel\", method.rate=\"random\"), #                covar=\"AR1\", rho=\"dunif(0,1)\", link=\"smd\")    ####### Examine MCMC diagnostics (using mcmcplots package) #######  # Traceplots # mcmcplots::traplot(result)  # Plots for assessing convergence # mcmcplots::mcmcplot(result, c(\"rate\", \"sd.rate\", \"rho\"))  ########## Output ###########  # Print R2jags output and summary print(result) #> Inference for Bugs model at \"/tmp/RtmprYte33/file2066e94e1d8\", fit using jags, #>  3 chains, each with 20000 iterations (first 10000 discarded), n.thin = 10 #>  n.sims = 3000 iterations saved #>           mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff #> emax[1]     0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000     1 #> emax[2]    -0.637   0.105  -0.843  -0.706  -0.635  -0.567  -0.436 1.001  3000 #> emax[3]    -0.929   0.047  -1.017  -0.961  -0.928  -0.898  -0.839 1.023    91 #> emax[4]    -1.035   0.105  -1.239  -1.106  -1.034  -0.962  -0.828 1.003   780 #> emax[5]    -0.632   0.196  -1.005  -0.766  -0.637  -0.499  -0.252 1.004   550 #> emax[6]    -0.117   0.143  -0.387  -0.214  -0.119  -0.019   0.168 1.001  3000 #> emax[7]    -1.223   0.076  -1.373  -1.275  -1.222  -1.172  -1.076 1.015   140 #> emax[8]    -0.117   0.142  -0.404  -0.210  -0.114  -0.020   0.159 1.001  3000 #> emax[9]    -1.887   0.113  -2.098  -1.967  -1.886  -1.808  -1.675 1.012   180 #> emax[10]   -1.884   0.160  -2.207  -1.992  -1.876  -1.774  -1.589 1.007   320 #> emax[11]   -0.872   0.064  -1.000  -0.916  -0.871  -0.828  -0.746 1.010   220 #> emax[12]   -0.856   0.066  -0.983  -0.901  -0.856  -0.811  -0.727 1.008   260 #> emax[13]   -1.059   0.081  -1.217  -1.115  -1.061  -1.002  -0.901 1.006   360 #> emax[14]   -0.985   0.125  -1.227  -1.070  -0.983  -0.903  -0.739 1.002  1400 #> emax[15]   -1.314   0.070  -1.446  -1.362  -1.314  -1.265  -1.180 1.016   130 #> emax[16]   -1.218   0.078  -1.373  -1.269  -1.218  -1.163  -1.071 1.010   210 #> emax[17]    0.352   0.138   0.087   0.256   0.354   0.443   0.627 1.001  3000 #> emax[18]   -0.922   0.090  -1.100  -0.983  -0.923  -0.860  -0.752 1.005   420 #> emax[19]   -1.282   0.234  -1.756  -1.439  -1.279  -1.127  -0.821 1.003   790 #> emax[20]   -0.878   0.103  -1.086  -0.945  -0.875  -0.806  -0.684 1.006   370 #> emax[21]   -2.639   0.211  -3.055  -2.776  -2.638  -2.494  -2.232 1.005   500 #> emax[22]   -1.308   0.115  -1.542  -1.387  -1.304  -1.230  -1.090 1.005   500 #> emax[23]   -0.210   0.069  -0.349  -0.255  -0.210  -0.161  -0.079 1.001  3000 #> emax[24]   -0.328   0.070  -0.466  -0.375  -0.328  -0.281  -0.192 1.002  1300 #> emax[25]   -0.763   0.073  -0.908  -0.813  -0.763  -0.713  -0.623 1.005   460 #> emax[26]   -0.824   0.097  -1.022  -0.888  -0.824  -0.759  -0.640 1.005   420 #> emax[27]   -0.784   0.123  -1.029  -0.869  -0.782  -0.699  -0.549 1.003   790 #> emax[28]   -1.020   0.127  -1.272  -1.107  -1.016  -0.933  -0.779 1.004   560 #> emax[29]   -0.833   0.126  -1.074  -0.921  -0.833  -0.748  -0.589 1.010   250 #> et50        0.467   0.046   0.387   0.435   0.463   0.493   0.569 1.003   970 #> hill        0.594   0.086   0.502   0.524   0.568   0.646   0.802 1.030    78 #> rho         0.000   0.000   0.000   0.000   0.000   0.000   0.000 1.000     1 #> totresdev 836.971  13.887 812.425 827.096 836.126 846.002 866.623 1.002  1100 #> deviance  -43.069  13.887 -67.615 -52.943 -43.913 -34.037 -13.416 1.002  1100 #>  #> For each parameter, n.eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor (at convergence, Rhat=1). #>  #> DIC info (using the rule, pD = var(deviance)/2) #> pD = 96.3 and DIC = 52.4 #> DIC is an estimate of expected predictive error (lower deviance is better). summary(result) #> ======================================== #> Time-course MBNMA #> ======================================== #>  #> Time-course function: emax #> Data modelled with intercept #>  #> emax parameter #> Pooling: relative effects #> Method: common treatment effects #>  #> |Treatment |Parameter |  Median|    2.5%|   97.5%| #> |:---------|:---------|-------:|-------:|-------:| #> |Pl_0      |emax[1]   |  0.0000|  0.0000|  0.0000| #> |Ce_100    |emax[2]   | -0.6349| -0.8427| -0.4357| #> |Ce_200    |emax[3]   | -0.9277| -1.0173| -0.8386| #> |Ce_400    |emax[4]   | -1.0335| -1.2393| -0.8282| #> |Du_90     |emax[5]   | -0.6368| -1.0052| -0.2524| #> |Et_10     |emax[6]   | -0.1185| -0.3865|  0.1683| #> |Et_30     |emax[7]   | -1.2221| -1.3727| -1.0760| #> |Et_5      |emax[8]   | -0.1144| -0.4042|  0.1590| #> |Et_60     |emax[9]   | -1.8856| -2.0978| -1.6753| #> |Et_90     |emax[10]  | -1.8764| -2.2072| -1.5886| #> |Lu_100    |emax[11]  | -0.8709| -0.9995| -0.7463| #> |Lu_200    |emax[12]  | -0.8558| -0.9834| -0.7274| #> |Lu_400    |emax[13]  | -1.0607| -1.2170| -0.9010| #> |Lu_NA     |emax[14]  | -0.9834| -1.2270| -0.7387| #> |Na_1000   |emax[15]  | -1.3141| -1.4461| -1.1801| #> |Na_1500   |emax[16]  | -1.2176| -1.3733| -1.0711| #> |Na_250    |emax[17]  |  0.3541|  0.0875|  0.6274| #> |Na_750    |emax[18]  | -0.9226| -1.1004| -0.7520| #> |Ox_44     |emax[19]  | -1.2790| -1.7562| -0.8207| #> |Ro_12     |emax[20]  | -0.8753| -1.0859| -0.6839| #> |Ro_125    |emax[21]  | -2.6380| -3.0553| -2.2322| #> |Ro_25     |emax[22]  | -1.3037| -1.5418| -1.0901| #> |Tr_100    |emax[23]  | -0.2101| -0.3489| -0.0788| #> |Tr_200    |emax[24]  | -0.3279| -0.4662| -0.1925| #> |Tr_300    |emax[25]  | -0.7630| -0.9081| -0.6232| #> |Tr_400    |emax[26]  | -0.8236| -1.0219| -0.6398| #> |Va_10     |emax[27]  | -0.7819| -1.0292| -0.5487| #> |Va_20     |emax[28]  | -1.0160| -1.2721| -0.7793| #> |Va_5      |emax[29]  | -0.8326| -1.0741| -0.5894| #>  #>  #> et50 parameter #> Pooling: absolute effects #> Method: common treatment effects #>  #> |Treatment |Parameter | Median|   2.5%|  97.5%| #> |:---------|:---------|------:|------:|------:| #> |Pl_0      |et50      | 0.4632| 0.3867| 0.5691| #> |Ce_100    |et50      | 0.4632| 0.3867| 0.5691| #> |Ce_200    |et50      | 0.4632| 0.3867| 0.5691| #> |Ce_400    |et50      | 0.4632| 0.3867| 0.5691| #> |Du_90     |et50      | 0.4632| 0.3867| 0.5691| #> |Et_10     |et50      | 0.4632| 0.3867| 0.5691| #> |Et_30     |et50      | 0.4632| 0.3867| 0.5691| #> |Et_5      |et50      | 0.4632| 0.3867| 0.5691| #> |Et_60     |et50      | 0.4632| 0.3867| 0.5691| #> |Et_90     |et50      | 0.4632| 0.3867| 0.5691| #> |Lu_100    |et50      | 0.4632| 0.3867| 0.5691| #> |Lu_200    |et50      | 0.4632| 0.3867| 0.5691| #> |Lu_400    |et50      | 0.4632| 0.3867| 0.5691| #> |Lu_NA     |et50      | 0.4632| 0.3867| 0.5691| #> |Na_1000   |et50      | 0.4632| 0.3867| 0.5691| #> |Na_1500   |et50      | 0.4632| 0.3867| 0.5691| #> |Na_250    |et50      | 0.4632| 0.3867| 0.5691| #> |Na_750    |et50      | 0.4632| 0.3867| 0.5691| #> |Ox_44     |et50      | 0.4632| 0.3867| 0.5691| #> |Ro_12     |et50      | 0.4632| 0.3867| 0.5691| #> |Ro_125    |et50      | 0.4632| 0.3867| 0.5691| #> |Ro_25     |et50      | 0.4632| 0.3867| 0.5691| #> |Tr_100    |et50      | 0.4632| 0.3867| 0.5691| #> |Tr_200    |et50      | 0.4632| 0.3867| 0.5691| #> |Tr_300    |et50      | 0.4632| 0.3867| 0.5691| #> |Tr_400    |et50      | 0.4632| 0.3867| 0.5691| #> |Va_10     |et50      | 0.4632| 0.3867| 0.5691| #> |Va_20     |et50      | 0.4632| 0.3867| 0.5691| #> |Va_5      |et50      | 0.4632| 0.3867| 0.5691| #>  #>  #> hill parameter #> Pooling: absolute effects #> Method: common treatment effects #>  #> |Treatment |Parameter | Median|   2.5%|  97.5%| #> |:---------|:---------|------:|------:|------:| #> |Pl_0      |hill      | 0.5677| 0.5018| 0.8017| #> |Ce_100    |hill      | 0.5677| 0.5018| 0.8017| #> |Ce_200    |hill      | 0.5677| 0.5018| 0.8017| #> |Ce_400    |hill      | 0.5677| 0.5018| 0.8017| #> |Du_90     |hill      | 0.5677| 0.5018| 0.8017| #> |Et_10     |hill      | 0.5677| 0.5018| 0.8017| #> |Et_30     |hill      | 0.5677| 0.5018| 0.8017| #> |Et_5      |hill      | 0.5677| 0.5018| 0.8017| #> |Et_60     |hill      | 0.5677| 0.5018| 0.8017| #> |Et_90     |hill      | 0.5677| 0.5018| 0.8017| #> |Lu_100    |hill      | 0.5677| 0.5018| 0.8017| #> |Lu_200    |hill      | 0.5677| 0.5018| 0.8017| #> |Lu_400    |hill      | 0.5677| 0.5018| 0.8017| #> |Lu_NA     |hill      | 0.5677| 0.5018| 0.8017| #> |Na_1000   |hill      | 0.5677| 0.5018| 0.8017| #> |Na_1500   |hill      | 0.5677| 0.5018| 0.8017| #> |Na_250    |hill      | 0.5677| 0.5018| 0.8017| #> |Na_750    |hill      | 0.5677| 0.5018| 0.8017| #> |Ox_44     |hill      | 0.5677| 0.5018| 0.8017| #> |Ro_12     |hill      | 0.5677| 0.5018| 0.8017| #> |Ro_125    |hill      | 0.5677| 0.5018| 0.8017| #> |Ro_25     |hill      | 0.5677| 0.5018| 0.8017| #> |Tr_100    |hill      | 0.5677| 0.5018| 0.8017| #> |Tr_200    |hill      | 0.5677| 0.5018| 0.8017| #> |Tr_300    |hill      | 0.5677| 0.5018| 0.8017| #> |Tr_400    |hill      | 0.5677| 0.5018| 0.8017| #> |Va_10     |hill      | 0.5677| 0.5018| 0.8017| #> |Va_20     |hill      | 0.5677| 0.5018| 0.8017| #> |Va_5      |hill      | 0.5677| 0.5018| 0.8017| #>  #>  #>  #> Correlation between time points #> Covariance structure: varadj  #> Rho assigned a numeric value: 0 #>  #> #### Model Fit Statistics #### #>  #> Effective number of parameters: #> pD (pV) calculated using the rule, pD = var(deviance)/2 = 96 #> Deviance = -44 #> Residual deviance = 836 #> Deviance Information Criterion (DIC) = 52  #>  #> The following parameters have Rhat values > 1.02 which could be due to convergence issues: #> emax[3] #> hill  # Plot forest plot of results plot(result)    ###### Additional model arguments ######  # Use gout dataset goutnet <- mb.network(goutSUA_CFBcomb) #> Reference treatment is `Plac` #> Studies reporting change from baseline automatically identified from the data  # Define a user-defined time-course relationship for use in mb.run timecourse <- ~ exp(beta.1 * time) + (time^beta.2)  # Run model with: # user-defined time-course function # random relative effects on beta.1 # default common effects on beta.2 # default relative pooling on beta.1 and beta.2 # common class effect on beta.2 mb.run(goutnet, fun=tuser(fun=timecourse, method.1=\"random\"),        class.effect=list(beta.1=\"common\")) #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 224 #>    Unobserved stochastic nodes: 121 #>    Total graph size: 4851 #>  #> Initializing model #>  #> Inference for Bugs model at \"/tmp/RtmprYte33/file20665490e649\", fit using jags, #>  3 chains, each with 20000 iterations (first 10000 discarded), n.thin = 10 #>  n.sims = 3000 iterations saved #>               mu.vect sd.vect        2.5%         25%         50%         75% #> D.1[1]          0.000   0.000       0.000       0.000       0.000       0.000 #> D.1[2]          7.700  23.977     -41.825      -7.560       8.150      22.465 #> D.1[3]        -15.195  21.058     -57.815     -28.462     -14.418      -4.968 #> D.1[4]        -15.768  26.214     -71.410     -32.032     -18.820       1.730 #> D.1[5]        -10.228  25.804     -66.842     -27.058      -9.371       8.946 #> D.1[6]        -34.926  29.042     -98.230     -48.105     -26.613     -12.214 #> D.1[7]        -21.561  20.299     -70.063     -31.868     -19.396      -7.488 #> d.1[1]          0.000   0.000       0.000       0.000       0.000       0.000 #> d.1[2]          7.700  23.977     -41.825      -7.560       8.150      22.465 #> d.1[3]          7.700  23.977     -41.825      -7.560       8.150      22.465 #> d.1[4]          7.700  23.977     -41.825      -7.560       8.150      22.465 #> d.1[5]          7.700  23.977     -41.825      -7.560       8.150      22.465 #> d.1[6]        -15.195  21.058     -57.815     -28.462     -14.418      -4.968 #> d.1[7]        -15.768  26.214     -71.410     -32.032     -18.820       1.730 #> d.1[8]        -15.768  26.214     -71.410     -32.032     -18.820       1.730 #> d.1[9]        -15.768  26.214     -71.410     -32.032     -18.820       1.730 #> d.1[10]       -15.768  26.214     -71.410     -32.032     -18.820       1.730 #> d.1[11]       -10.228  25.804     -66.842     -27.058      -9.371       8.946 #> d.1[12]       -34.926  29.042     -98.230     -48.105     -26.613     -12.214 #> d.1[13]       -34.926  29.042     -98.230     -48.105     -26.613     -12.214 #> d.1[14]       -34.926  29.042     -98.230     -48.105     -26.613     -12.214 #> d.1[15]       -34.926  29.042     -98.230     -48.105     -26.613     -12.214 #> d.1[16]       -21.561  20.299     -70.063     -31.868     -19.396      -7.488 #> d.1[17]       -21.561  20.299     -70.063     -31.868     -19.396      -7.488 #> d.1[18]       -21.561  20.299     -70.063     -31.868     -19.396      -7.488 #> d.1[19]       -21.561  20.299     -70.063     -31.868     -19.396      -7.488 #> d.2[1]          0.000   0.000       0.000       0.000       0.000       0.000 #> d.2[2]         -5.357  29.701     -63.042     -25.630      -4.519      14.397 #> d.2[3]          3.580  29.771     -54.484     -16.551       3.414      24.208 #> d.2[4]        -16.378  10.327     -42.777     -21.634     -13.711      -8.527 #> d.2[5]          2.740  29.890     -57.383     -17.348       2.744      22.524 #> d.2[6]        -14.923  28.265     -70.755     -32.225     -15.956       1.024 #> d.2[7]         -3.111  30.452     -64.624     -23.489      -2.490      17.922 #> d.2[8]         -7.718  27.396     -64.247     -25.017      -6.632      10.284 #> d.2[9]         -2.393  30.193     -62.072     -22.087      -2.739      18.173 #> d.2[10]        -5.888  29.016     -64.118     -25.513      -4.631      13.920 #> d.2[11]       -17.711  25.567     -70.304     -33.864     -17.243      -0.970 #> d.2[12]       -10.551  26.877     -63.893     -28.055     -10.272       7.461 #> d.2[13]        -9.772  27.959     -67.431     -28.080      -9.700       8.251 #> d.2[14]       -15.171  21.842     -62.164     -28.827     -13.519      -0.481 #> d.2[15]       -16.041  25.069     -69.652     -31.591     -15.061       0.475 #> d.2[16]         4.250  29.932     -55.832     -15.301       4.366      23.962 #> d.2[17]       -18.063  25.242     -67.707     -34.304     -17.865      -3.924 #> d.2[18]       -16.919  23.410     -64.900     -32.001     -16.084      -3.362 #> d.2[19]       -18.059  26.253     -70.305     -35.237     -17.738      -2.791 #> rho             0.000   0.000       0.000       0.000       0.000       0.000 #> sd.beta.1       3.253   2.453       0.117       1.318       2.685       4.709 #> totresdev 2013066.684   7.418 2013056.569 2013062.327 2013064.722 2013068.425 #> deviance  2012372.495   7.418 2012362.380 2012368.138 2012370.533 2012374.236 #>                 97.5%  Rhat n.eff #> D.1[1]          0.000 1.000     1 #> D.1[2]         59.162 1.243    12 #> D.1[3]         30.563 1.080    35 #> D.1[4]         38.392 1.085    54 #> D.1[5]         38.858 1.083    31 #> D.1[6]          0.276 1.911     5 #> D.1[7]         12.513 1.349    10 #> d.1[1]          0.000 1.000     1 #> d.1[2]         59.162 1.243    12 #> d.1[3]         59.162 1.243    12 #> d.1[4]         59.162 1.243    12 #> d.1[5]         59.162 1.243    12 #> d.1[6]         30.563 1.080    35 #> d.1[7]         38.392 1.085    54 #> d.1[8]         38.392 1.085    54 #> d.1[9]         38.392 1.085    54 #> d.1[10]        38.392 1.085    54 #> d.1[11]        38.858 1.083    31 #> d.1[12]         0.276 1.911     5 #> d.1[13]         0.276 1.911     5 #> d.1[14]         0.276 1.911     5 #> d.1[15]         0.276 1.911     5 #> d.1[16]        12.513 1.349    10 #> d.1[17]        12.513 1.349    10 #> d.1[18]        12.513 1.349    10 #> d.1[19]        12.513 1.349    10 #> d.2[1]          0.000 1.000     1 #> d.2[2]         52.523 1.001  3000 #> d.2[3]         60.448 1.007   320 #> d.2[4]         -4.238 1.001  3000 #> d.2[5]         61.959 1.001  3000 #> d.2[6]         45.481 1.087    30 #> d.2[7]         54.215 1.002  1200 #> d.2[8]         45.194 1.001  3000 #> d.2[9]         56.501 1.001  3000 #> d.2[10]        48.140 1.001  3000 #> d.2[11]        30.991 1.002  1900 #> d.2[12]        41.813 1.003   670 #> d.2[13]        44.766 1.006   410 #> d.2[14]        25.234 1.001  2600 #> d.2[15]        29.768 1.001  3000 #> d.2[16]        63.974 1.001  3000 #> d.2[17]        33.935 1.025    99 #> d.2[18]        30.441 1.023   110 #> d.2[19]        34.395 1.034    71 #> rho             0.000 1.000     1 #> sd.beta.1       8.987 1.082   100 #> totresdev 2013085.444 1.000     1 #> deviance  2012391.256 1.000     1 #>  #> For each parameter, n.eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor (at convergence, Rhat=1). #>  #> DIC info (using the rule, pD = var(deviance)/2) #> pD = 27.2 and DIC = 2012397.8 #> DIC is an estimate of expected predictive error (lower deviance is better).  # Fit a log-linear MBNMA # with variance adjustment for correlation between time-points result <- mb.run(network, fun=tloglin(),                  rho=\"dunif(0,1)\", covar=\"varadj\") #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 89 #>    Total graph size: 7303 #>  #> Initializing model #>  # }"},{"path":"/reference/mb.update.html","id":null,"dir":"Reference","previous_headings":"","what":"Update MBNMA to obtain deviance contributions or fitted values — mb.update","title":"Update MBNMA to obtain deviance contributions or fitted values — mb.update","text":"Update MBNMA obtain deviance contributions fitted values","code":""},{"path":"/reference/mb.update.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update MBNMA to obtain deviance contributions or fitted values — mb.update","text":"","code":"mb.update(   mbnma,   param = \"theta\",   n.iter = mbnma$BUGSoutput$n.iter,   n.thin = mbnma$BUGSoutput$n.thin )"},{"path":"/reference/mb.update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update MBNMA to obtain deviance contributions or fitted values — mb.update","text":"mbnma S3 object class \"mbnma\" generated running time-course MBNMA model param character object represents parameter within model monitor updating. Can currently used monitoring fitted values deviance contributions can take either \"dev\" (deviance contributions), \"resdev\" (residual deviance contributions) \"theta\" (fitted values). n.iter number iterations update model whilst monitoring additional parameters (necessary). Must positive integer. Default value used mbnma. n.thin thinning rate. Must positive integer. Default value used mbnma.","code":""},{"path":"/reference/mb.update.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update MBNMA to obtain deviance contributions or fitted values — mb.update","text":"data frame containing posterior means specified param observation, arm study.","code":""},{"path":"/reference/mb.update.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update MBNMA to obtain deviance contributions or fitted values — mb.update","text":"","code":"# \\donttest{ # Using the alogliptin dataset network <- mb.network(alog_pcfb) #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data  # Run Emax model emax <- mb.run(network, fun=temax()) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 233 #>    Unobserved stochastic nodes: 38 #>    Total graph size: 4166 #>  #> Initializing model #>   # Update model for 500 iterations to monitor fitted values mb.update(emax, param=\"theta\", n.iter=500) #>     study arm fup         mean #> 1       1   1   1 -0.045838806 #> 2       2   1   1 -0.036108654 #> 3       3   1   1 -0.473315122 #> 4       4   1   1 -0.004863005 #> 5       5   1   1 -0.084983592 #> 6       6   1   1 -0.031897313 #> 7       7   1   1 -0.102558680 #> 8       8   1   1 -0.009663954 #> 9       9   1   1 -0.097999511 #> 10     10   1   1  0.055049937 #> 11     11   1   1 -0.046138331 #> 12     12   1   1  0.038081050 #> 13     13   1   1 -0.764234830 #> 14     14   1   1 -0.721613891 #> 15      1   2   1 -0.222901501 #> 16      2   2   1 -0.155417583 #> 17      3   2   1 -0.675217660 #> 18      4   2   1 -0.362795617 #> 19      5   2   1 -0.417415685 #> 20      6   2   1 -0.352134618 #> 21      7   2   1 -0.505519919 #> 22      8   2   1 -0.384711270 #> 23      9   2   1 -0.258762260 #> 24     10   2   1 -0.188094463 #> 25     11   2   1 -0.250130536 #> 26     12   2   1 -0.167678098 #> 27     13   2   1 -0.825288270 #> 28     14   2   1 -0.787264923 #> 29      1   3   1 -0.263340370 #> 30      2   3   1 -0.212098185 #> 31      3   3   1 -0.761623079 #> 32      4   3   1 -0.392946915 #> 33      5   3   1 -0.446093502 #> 34      6   3   1 -0.379093270 #> 35      7   3   1 -0.541149116 #> 36      8   3   1 -0.416544737 #> 37      9   3   1 -0.273143703 #> 38     10   3   1 -0.208255962 #> 39     11   3   1 -0.268061437 #> 40     12   3   1 -0.184653729 #> 43      1   4   1 -0.280914140 #> 44      2   4   1 -0.227238140 #> 45      3   4   1 -0.853937953 #> 57      1   5   1 -0.309667228 #> 58      2   5   1 -0.223422937 #> 71      1   6   1 -0.293739263 #> 85      1   1   2 -0.080018459 #> 86      2   1   2 -0.059132567 #> 87      3   1   2 -0.476837838 #> 88      4   1   2 -0.007134970 #> 89      5   1   2 -0.119498369 #> 90      6   1   2 -0.045645940 #> 91      7   1   2 -0.134853970 #> 92      8   1   2 -0.013408396 #> 93      9   1   2 -0.162197089 #> 94     10   1   2  0.083797494 #> 95     11   1   2 -0.073144756 #> 96     12   1   2  0.060297921 #> 97     13   1   2 -0.800171389 #> 98     14   1   2 -0.738516031 #> 99      1   2   2 -0.363212634 #> 100     2   2   2 -0.267077528 #> 101     3   2   2 -0.632795050 #> 102     4   2   2 -0.507727626 #> 103     5   2   2 -0.595121591 #> 104     6   2   2 -0.508414911 #> 105     7   2   2 -0.678543308 #> 106     8   2   2 -0.530842882 #> 107     9   2   2 -0.431950671 #> 108    10   2   2 -0.292503214 #> 109    11   2   2 -0.401056128 #> 110    12   2   2 -0.269705637 #> 111    13   2   2 -0.862356872 #> 112    14   2   2 -0.803737497 #> 113     1   3   2 -0.417170662 #> 114     2   3   2 -0.349767437 #> 115     3   3   2 -0.712341489 #> 116     4   3   2 -0.548779224 #> 117     5   3   2 -0.634822909 #> 118     6   3   2 -0.546426608 #> 119     7   3   2 -0.724450545 #> 120     8   3   2 -0.573422152 #> 121     9   3   2 -0.455501135 #> 122    10   3   2 -0.323218742 #> 123    11   3   2 -0.429139580 #> 124    12   3   2 -0.296592307 #> 127     1   4   2 -0.444015802 #> 128     2   4   2 -0.374292190 #> 129     3   4   2 -0.847194681 #> 141     1   5   2 -0.499420743 #> 142     2   5   2 -0.380906557 #> 155     1   6   2 -0.525337757 #> 170     2   1   3 -0.086872516 #> 171     3   1   3 -0.478997753 #> 172     4   1   3 -0.008431620 #> 173     5   1   3 -0.138264636 #> 174     6   1   3 -0.053328877 #> 175     7   1   3 -0.150788699 #> 176     8   1   3 -0.015398657 #> 177     9   1   3 -0.241299216 #> 178    10   1   3  0.113545942 #> 179    11   1   3 -0.103497638 #> 180    12   1   3  0.085191782 #> 181    13   1   3 -0.819664405 #> 182    14   1   3 -0.747363422 #> 184     2   2   3 -0.416993386 #> 185     3   2   3 -0.610119762 #> 186     4   2   3 -0.586083327 #> 187     5   2   3 -0.693739421 #> 188     6   2   3 -0.596916512 #> 189     7   2   3 -0.766258313 #> 190     8   2   3 -0.608054976 #> 191     9   2   3 -0.649358243 #> 192    10   2   3 -0.405145592 #> 193    11   2   3 -0.574573704 #> 194    12   2   3 -0.387832242 #> 195    13   2   3 -0.882408166 #> 196    14   2   3 -0.812365684 #> 198     2   3   3 -0.518076384 #> 199     3   3   3 -0.686060949 #> 200     4   3   3 -0.632763596 #> 201     5   3   3 -0.739263780 #> 202     6   3   3 -0.640940601 #> 203     7   3   3 -0.817031330 #> 204     8   3   3 -0.656037398 #> 205     9   3   3 -0.683898574 #> 206    10   3   3 -0.446741178 #> 207    11   3   3 -0.613718631 #> 208    12   3   3 -0.425786351 #> 212     2   4   3 -0.553607140 #> 213     3   4   3 -0.843628510 #> 226     2   5   3 -0.588513633 #> 254     2   1   4 -0.103011519 #> 255     3   1   4 -0.480457708 #> 256     4   1   4 -0.009268076 #> 257     5   1   4 -0.150067601 #> 258     6   1   4 -0.058239261 #> 259     7   1   4 -0.160295311 #> 260     8   1   4 -0.016633946 #> 261     9   1   4 -0.288201488 #> 262    10   1   4  0.128844894 #> 263    11   1   4 -0.120156423 #> 264    12   1   4  0.098817259 #> 265    13   1   4 -0.831904764 #> 266    14   1   4 -0.752807217 #> 268     2   2   4 -0.513113130 #> 269     3   2   4 -0.595993172 #> 270     4   2   4 -0.635227623 #> 271     5   2   4 -0.756491219 #> 272     6   2   4 -0.653920112 #> 273     7   2   4 -0.819322597 #> 274     8   2   4 -0.655838947 #> 275     9   2   4 -0.780363075 #> 276    10   2   4 -0.464942658 #> 277    11   2   4 -0.671535567 #> 278    12   2   4 -0.454238833 #> 279    13   2   4 -0.894978376 #> 280    14   2   4 -0.817676328 #> 282     2   3   4 -0.617206669 #> 283     3   3   4 -0.669710440 #> 284     4   3   4 -0.685344419 #> 285     5   3   4 -0.805613400 #> 286     6   3   4 -0.701722096 #> 287     7   3   4 -0.872930011 #> 288     8   3   4 -0.707073410 #> 289     9   3   4 -0.821244747 #> 290    10   3   4 -0.512100898 #> 291    11   3   4 -0.716579741 #> 292    12   3   4 -0.498217920 #> 296     2   4   4 -0.658980845 #> 297     3   4   4 -0.841440795 #> 310     2   5   4 -0.719385084 #> 339     3   1   5 -0.481510573 #> 340     4   1   5 -0.009852008 #> 341     5   1   5 -0.158178681 #> 342     6   1   5 -0.061649734 #> 343     7   1   5 -0.166613471 #> 344     8   1   5 -0.018331982 #> 349    13   1   5 -0.840306884 #> 350    14   1   5 -0.756494959 #> 353     3   2   5 -0.586344206 #> 354     4   2   5 -0.668944923 #> 355     5   2   5 -0.799942037 #> 356     6   2   5 -0.693713747 #> 357     7   2   5 -0.854892439 #> 358     8   2   5 -0.721365339 #> 363    13   2   5 -0.903597483 #> 364    14   2   5 -0.821274569 #> 367     3   3   5 -0.658552388 #> 368     4   3   5 -0.721377904 #> 369     5   3   5 -0.851507000 #> 370     6   3   5 -0.744108978 #> 371     7   3   5 -0.910354467 #> 372     8   3   5 -0.776948019 #> 381     3   4   5 -0.839968388 #> 423     3   1   6 -0.482305808 #> 424     4   1   6 -0.010458178 #> 425     5   1   6 -0.166493572 #> 426     6   1   6 -0.065177026 #> 427     7   1   6 -0.172917596 #> 433    13   1   6 -0.846431982 #> 434    14   1   6 -0.759158446 #> 437     3   2   6 -0.579334061 #> 438     4   2   6 -0.703466952 #> 439     5   2   6 -0.844762931 #> 440     6   2   6 -0.735045213 #> 441     7   2   6 -0.890624343 #> 447    13   2   6 -0.909875860 #> 448    14   2   6 -0.823873747 #> 451     3   3   6 -0.650450974 #> 452     4   3   6 -0.758236475 #> 453     5   3   6 -0.898806508 #> 454     6   3   6 -0.788095462 #> 455     7   3   6 -0.947913228 #> 465     3   4   6 -0.838912529 #> 507     3   1   7 -0.482927678 #> 517    13   1   7 -0.851095457 #> 518    14   1   7 -0.761172411 #> 521     3   2   7 -0.574009982 #> 531    13   2   7 -0.914653236 #> 532    14   2   7 -0.825839266 #> 535     3   3   7 -0.644300989 #> 549     3   4   7 -0.838119649 #> 591     3   1   8 -0.483427307 #> 601    13   1   8 -0.854764821 #> 602    14   1   8 -0.762748643 #> 605     3   2   8 -0.569828763 #> 615    13   2   8 -0.918410507 #> 616    14   2   8 -0.827377688 #> 619     3   3   8 -0.639472914 #> 633     3   4   8 -0.837503037 #> 685    13   1   9 -0.857727382 #> 699    13   2   9 -0.921442934  # Update model for 500 iterations to monitor residual deviance contributions mb.update(emax, param=\"resdev\", n.iter=500) #>     study arm fup        mean #> 1       1   1   1  0.95971588 #> 2       2   1   1  2.87664922 #> 3       3   1   1  1.30403626 #> 4       4   1   1  4.27536962 #> 5       5   1   1  1.71304014 #> 6       6   1   1  2.36392839 #> 7       7   1   1 12.32515250 #> 8       8   1   1 16.67078082 #> 9       9   1   1 11.73860200 #> 10     10   1   1  0.91685151 #> 11     11   1   1  3.04780254 #> 12     12   1   1  1.54163144 #> 13     13   1   1  3.01058144 #> 14     14   1   1  2.48064998 #> 15      1   2   1  1.27625530 #> 16      2   2   1  0.28353752 #> 17      3   2   1  0.48326988 #> 18      4   2   1  0.30718169 #> 19      5   2   1  0.57331036 #> 20      6   2   1  0.33914451 #> 21      7   2   1  0.96217963 #> 22      8   2   1  0.63622996 #> 23      9   2   1  7.42053106 #> 24     10   2   1  8.25588604 #> 25     11   2   1 13.09813188 #> 26     12   2   1  3.54333834 #> 27     13   2   1  1.21290871 #> 28     14   2   1  3.46378269 #> 29      1   3   1  0.94503821 #> 30      2   3   1  4.20077971 #> 31      3   3   1  0.51648476 #> 32      4   3   1  2.72708834 #> 33      5   3   1  0.37034829 #> 34      6   3   1  0.84595297 #> 35      7   3   1  1.12705130 #> 36      8   3   1  2.70054713 #> 37      9   3   1 13.05656983 #> 38     10   3   1 15.17120967 #> 39     11   3   1  9.19479581 #> 40     12   3   1 12.95089597 #> 43      1   4   1  0.91622247 #> 44      2   4   1 10.50449027 #> 45      3   4   1  0.48190075 #> 57      1   5   1  0.29697083 #> 58      2   5   1 13.45866017 #> 71      1   6   1  0.35847603 #> 85      1   1   2  1.06765514 #> 86      2   1   2  1.68844539 #> 87      3   1   2  1.46632442 #> 88      4   1   2  3.08700381 #> 89      5   1   2  0.99242878 #> 90      6   1   2  7.90727253 #> 91      7   1   2  5.00021520 #> 92      8   1   2  8.74221602 #> 93      9   1   2  5.43415482 #> 94     10   1   2  0.32646976 #> 95     11   1   2  2.37111959 #> 96     12   1   2  1.26103834 #> 97     13   1   2  2.50591638 #> 98     14   1   2  3.95232832 #> 99      1   2   2  2.20615611 #> 100     2   2   2  7.46568741 #> 101     3   2   2  3.66028783 #> 102     4   2   2  0.29938512 #> 103     5   2   2  0.13184543 #> 104     6   2   2  4.17920401 #> 105     7   2   2  1.93709187 #> 106     8   2   2  1.09400005 #> 107     9   2   2  3.07909193 #> 108    10   2   2  0.73832367 #> 109    11   2   2  2.14613872 #> 110    12   2   2  0.60799939 #> 111    13   2   2  3.99224957 #> 112    14   2   2  3.57396375 #> 113     1   3   2  1.13061103 #> 114     2   3   2  0.88762858 #> 115     3   3   2  0.87733053 #> 116     4   3   2  3.37154476 #> 117     5   3   2  5.46291212 #> 118     6   3   2  1.27930564 #> 119     7   3   2  3.59282328 #> 120     8   3   2  3.84976959 #> 121     9   3   2  0.21583824 #> 122    10   3   2  1.38663968 #> 123    11   3   2  0.15039980 #> 124    12   3   2  0.39715651 #> 127     1   4   2  1.13192107 #> 128     2   4   2  0.73899424 #> 129     3   4   2  0.99586430 #> 141     1   5   2  0.45485042 #> 142     2   5   2  0.53441757 #> 155     1   6   2  0.65782429 #> 170     2   1   3  2.61202826 #> 171     3   1   3  1.30751636 #> 172     4   1   3  2.52472948 #> 173     5   1   3  1.76445421 #> 174     6   1   3  2.50345913 #> 175     7   1   3  2.75191758 #> 176     8   1   3  5.33623259 #> 177     9   1   3  3.71756685 #> 178    10   1   3  1.85496229 #> 179    11   1   3  4.12660321 #> 180    12   1   3  1.15753629 #> 181    13   1   3  1.78214013 #> 182    14   1   3  6.65992685 #> 184     2   2   3  3.13378671 #> 185     3   2   3  1.47533040 #> 186     4   2   3  0.17627021 #> 187     5   2   3  0.09660341 #> 188     6   2   3  1.90479567 #> 189     7   2   3  1.10322630 #> 190     8   2   3  0.43357936 #> 191     9   2   3 10.81816964 #> 192    10   2   3  5.86433809 #> 193    11   2   3 11.41200394 #> 194    12   2   3  4.07568282 #> 195    13   2   3  1.52797004 #> 196    14   2   3  5.70197250 #> 198     2   3   3  3.13924275 #> 199     3   3   3  0.10152799 #> 200     4   3   3  0.31334674 #> 201     5   3   3  2.96381856 #> 202     6   3   3  0.25276448 #> 203     7   3   3  0.08081891 #> 204     8   3   3  0.62427701 #> 205     9   3   3 11.33150118 #> 206    10   3   3  8.49668563 #> 207    11   3   3  9.57013060 #> 208    12   3   3 10.64618505 #> 212     2   4   3  4.87543457 #> 213     3   4   3  0.46866346 #> 226     2   5   3  5.72231882 #> 254     2   1   4  9.45334028 #> 255     3   1   4  0.11907872 #> 256     4   1   4  1.86751731 #> 257     5   1   4  2.06424314 #> 258     6   1   4  1.01003360 #> 259     7   1   4  0.71832821 #> 260     8   1   4  4.13482708 #> 261     9   1   4  4.31389970 #> 262    10   1   4 12.50669852 #> 263    11   1   4  8.92872667 #> 264    12   1   4  3.19538401 #> 265    13   1   4  0.82408250 #> 266    14   1   4  3.15195837 #> 268     2   2   4  0.06641390 #> 269     3   2   4  0.11043168 #> 270     4   2   4  0.70112087 #> 271     5   2   4  1.22323165 #> 272     6   2   4  0.09250646 #> 273     7   2   4  0.13710259 #> 274     8   2   4  6.39321090 #> 275     9   2   4  9.44939364 #> 276    10   2   4  6.15937381 #> 277    11   2   4 20.99508658 #> 278    12   2   4  2.21046795 #> 279    13   2   4  0.07203373 #> 280    14   2   4  3.24208970 #> 282     2   3   4  1.86946230 #> 283     3   3   4  0.09033226 #> 284     4   3   4  0.45602195 #> 285     5   3   4  0.48879713 #> 286     6   3   4  1.55657751 #> 287     7   3   4  2.29411553 #> 288     8   3   4  0.93756334 #> 289     9   3   4  9.10559322 #> 290    10   3   4  7.34043705 #> 291    11   3   4 12.91438947 #> 292    12   3   4  8.06409335 #> 296     2   4   4  2.75658986 #> 297     3   4   4  0.16583203 #> 310     2   5   4  3.76307062 #> 339     3   1   5  1.18282112 #> 340     4   1   5  1.66258198 #> 341     5   1   5  2.02911729 #> 342     6   1   5  0.67784536 #> 343     7   1   5  0.11189906 #> 344     8   1   5  0.21388553 #> 349    13   1   5  0.07389116 #> 350    14   1   5  0.30217471 #> 353     3   2   5  0.20449766 #> 354     4   2   5  2.14565155 #> 355     5   2   5  4.91554437 #> 356     6   2   5  1.69408221 #> 357     7   2   5  1.64564811 #> 358     8   2   5 34.66143698 #> 363    13   2   5  0.18155972 #> 364    14   2   5  0.09150837 #> 367     3   3   5  0.08647337 #> 368     4   3   5  3.33792148 #> 369     5   3   5  0.43056466 #> 370     6   3   5  4.98027989 #> 371     7   3   5  4.87602269 #> 372     8   3   5 19.73503096 #> 381     3   4   5  0.76972838 #> 423     3   1   6  2.46483431 #> 424     4   1   6  0.11838757 #> 425     5   1   6  0.16069566 #> 426     6   1   6  0.28124467 #> 427     7   1   6  0.43854174 #> 433    13   1   6  0.29351479 #> 434    14   1   6  0.11790947 #> 437     3   2   6  0.12759922 #> 438     4   2   6  4.94737404 #> 439     5   2   6 11.18860933 #> 440     6   2   6  5.80448494 #> 441     7   2   6 11.88979253 #> 447    13   2   6  0.16263969 #> 448    14   2   6  1.92513203 #> 451     3   3   6  0.33390841 #> 452     4   3   6  6.60436394 #> 453     5   3   6  3.33354943 #> 454     6   3   6 13.78509921 #> 455     7   3   6  9.44978512 #> 465     3   4   6  1.08040985 #> 507     3   1   7  3.77276022 #> 517    13   1   7  0.51119465 #> 518    14   1   7  0.79649483 #> 521     3   2   7  0.41229121 #> 531    13   2   7  0.79627067 #> 532    14   2   7  4.42055829 #> 535     3   3   7  0.12053856 #> 549     3   4   7  0.85086689 #> 591     3   1   8  4.18625238 #> 601    13   1   8  0.26522066 #> 602    14   1   8  3.95013051 #> 605     3   2   8  0.91967280 #> 615    13   2   8  0.14929420 #> 616    14   2   8  8.15036663 #> 619     3   3   8  0.15821374 #> 633     3   4   8  0.84504632 #> 685    13   1   9  0.93702690 #> 699    13   2   9  0.09789011  # Update model for 500 iterations to monitor deviance contributions mb.update(emax, param=\"dev\", n.iter=500) #>     study arm fup        mean #> 1       1   1   1 -1.57479285 #> 2       2   1   1 -2.92769951 #> 3       3   1   1 -2.13626112 #> 4       4   1   1  0.04542028 #> 5       5   1   1 -2.91395703 #> 6       6   1   1 -2.02208367 #> 7       7   1   1  7.65236919 #> 8       8   1   1 12.09275395 #> 9       9   1   1  5.24119765 #> 10     10   1   1 -4.26543983 #> 11     11   1   1 -2.97147900 #> 12     12   1   1 -4.53467328 #> 13     13   1   1 -1.34326731 #> 14     14   1   1 -2.64369658 #> 15      1   2   1 -1.65913096 #> 16      2   2   1 -6.03764952 #> 17      3   2   1 -3.46862764 #> 18      4   2   1 -4.49627863 #> 19      5   2   1 -4.67135332 #> 20      6   2   1 -4.77580707 #> 21      7   2   1 -3.22324822 #> 22      8   2   1 -4.71153168 #> 23      9   2   1  1.35129930 #> 24     10   2   1  2.67110957 #> 25     11   2   1  7.19487858 #> 26     12   2   1 -2.25991975 #> 27     13   2   1 -3.44253040 #> 28     14   2   1 -1.55979163 #> 29      1   3   1 -1.75537381 #> 30      2   3   1 -1.49265395 #> 31      3   3   1 -3.48057492 #> 32      4   3   1 -1.84977438 #> 33      5   3   1 -4.73599693 #> 34      6   3   1 -4.29646824 #> 35      7   3   1 -3.24136717 #> 36      8   3   1 -2.57718374 #> 37      9   3   1  6.92587008 #> 38     10   3   1  9.00299815 #> 39     11   3   1  3.26448452 #> 40     12   3   1  6.65987905 #> 43      1   4   1 -1.80849296 #> 44      2   4   1  4.76643446 #> 45      3   4   1 -3.59761333 #> 57      1   5   1 -2.45254008 #> 58      2   5   1  7.36329077 #> 71      1   6   1 -2.48919747 #> 85      1   1   2 -0.66703888 #> 86      2   1   2 -2.96111542 #> 87      3   1   2 -1.73241186 #> 88      4   1   2 -0.46713368 #> 89      5   1   2 -2.84000343 #> 90      6   1   2  4.11039214 #> 91      7   1   2  1.13680023 #> 92      8   1   2  4.80467013 #> 93      9   1   2 -0.20159885 #> 94     10   1   2 -4.55172665 #> 95     11   1   2 -2.63042283 #> 96     12   1   2 -3.93373492 #> 97     13   1   2 -1.37673344 #> 98     14   1   2 -0.85459925 #> 99      1   2   2 -0.15741214 #> 100     2   2   2  1.86292937 #> 101     3   2   2  0.02637524 #> 102     4   2   2 -3.86535251 #> 103     5   2   2 -4.36525883 #> 104     6   2   2 -0.44193439 #> 105     7   2   2 -1.91959528 #> 106     8   2   2 -3.51931084 #> 107     9   2   2 -2.81633070 #> 108    10   2   2 -4.11658794 #> 109    11   2   2 -3.25541439 #> 110    12   2   2 -4.64852495 #> 111    13   2   2 -0.11616116 #> 112    14   2   2 -0.95872107 #> 113     1   3   2 -1.18851752 #> 114     2   3   2 -4.08712442 #> 115     3   3   2 -2.72803968 #> 116     4   3   2 -0.65670210 #> 117     5   3   2  1.09609792 #> 118     6   3   2 -3.25360980 #> 119     7   3   2 -0.16884047 #> 120     8   3   2 -0.74987179 #> 121     9   3   2 -5.42417686 #> 122    10   3   2 -3.53452056 #> 123    11   3   2 -5.03870790 #> 124    12   3   2 -4.96811900 #> 127     1   4   2 -1.23772187 #> 128     2   4   2 -4.30930347 #> 129     3   4   2 -2.80703994 #> 141     1   5   2 -1.93950418 #> 142     2   5   2 -4.45313453 #> 155     1   6   2 -1.72611947 #> 170     2   1   3 -1.37143145 #> 171     3   1   3 -2.02559024 #> 172     4   1   3 -0.82496653 #> 173     5   1   3 -1.85457017 #> 174     6   1   3 -1.01646467 #> 175     7   1   3 -0.69022681 #> 176     8   1   3  1.76632957 #> 177     9   1   3 -1.30469055 #> 178    10   1   3 -2.14487372 #> 179    11   1   3 -0.43262657 #> 180    12   1   3 -3.16076613 #> 181    13   1   3 -1.75208356 #> 182    14   1   3  2.30212663 #> 184     2   2   3 -1.13478135 #> 185     3   2   3 -2.01278340 #> 186     4   2   3 -3.79559323 #> 187     5   2   3 -4.14283266 #> 188     6   2   3 -2.36182904 #> 189     7   2   3 -2.33852998 #> 190     8   2   3 -3.84439835 #> 191     9   2   3  6.20639565 #> 192    10   2   3  1.63030118 #> 193    11   2   3  7.47328378 #> 194    12   2   3 -0.02508922 #> 195    13   2   3 -2.14764296 #> 196    14   2   3  1.36627304 #> 198     2   3   3 -0.90860173 #> 199     3   3   3 -3.32945652 #> 200     4   3   3 -3.60956534 #> 201     5   3   3 -1.21844724 #> 202     6   3   3 -3.99414589 #> 203     7   3   3 -3.31416064 #> 204     8   3   3 -3.64593970 #> 205     9   3   3  6.97165497 #> 206    10   3   3  4.33062210 #> 207    11   3   3  5.46715356 #> 208    12   3   3  6.10418352 #> 212     2   4   3  0.69067849 #> 213     3   4   3 -3.21908827 #> 226     2   5   3  1.37029498 #> 254     2   1   4  5.36085217 #> 255     3   1   4 -3.11296361 #> 256     4   1   4 -1.32689832 #> 257     5   1   4 -1.35670582 #> 258     6   1   4 -2.37476416 #> 259     7   1   4 -2.60802470 #> 260     8   1   4  0.68222235 #> 261     9   1   4 -0.32779572 #> 262    10   1   4  8.97529295 #> 263    11   1   4  4.47666551 #> 264    12   1   4 -0.51171074 #> 265    13   1   4 -2.44848073 #> 266    14   1   4 -0.95722252 #> 268     2   2   4 -3.23700747 #> 269     3   2   4 -3.18703082 #> 270     4   2   4 -3.18059488 #> 271     5   2   4 -2.83605737 #> 272     6   2   4 -4.05123326 #> 273     7   2   4 -3.23524012 #> 274     8   2   4  2.13558647 #> 275     9   2   4  5.57686303 #> 276    10   2   4  2.20256252 #> 277    11   2   4 17.81310039 #> 278    12   2   4 -1.58822812 #> 279    13   2   4 -3.55265735 #> 280    14   2   4 -1.06886290 #> 282     2   3   4 -1.80466200 #> 283     3   3   4 -3.23211418 #> 284     4   3   4 -3.38119840 #> 285     5   3   4 -3.53908990 #> 286     6   3   4 -2.57062434 #> 287     7   3   4 -1.02766040 #> 288     8   3   4 -3.19644631 #> 289     9   3   4  5.44600506 #> 290    10   3   4  3.34350501 #> 291    11   3   4  9.36443757 #> 292    12   3   4  3.94401716 #> 296     2   4   4 -0.92606419 #> 297     3   4   4 -3.33700914 #> 310     2   5   4 -0.22165912 #> 339     3   1   5 -1.88470750 #> 340     4   1   5 -1.41016865 #> 341     5   1   5 -1.33706692 #> 342     6   1   5 -2.68033707 #> 343     7   1   5 -3.14167710 #> 344     8   1   5 -2.91683168 #> 349    13   1   5 -3.15680043 #> 350    14   1   5 -3.86292309 #> 353     3   2   5 -3.02787666 #> 354     4   2   5 -1.61232628 #> 355     5   2   5  0.91002620 #> 356     6   2   5 -2.48979453 #> 357     7   2   5 -1.69938115 #> 358     8   2   5 30.40936077 #> 363    13   2   5 -3.30858751 #> 364    14   2   5 -4.20417744 #> 367     3   3   5 -3.11171549 #> 368     4   3   5 -0.39312036 #> 369     5   3   5 -3.53369974 #> 370     6   3   5  0.85034691 #> 371     7   3   5  1.59080084 #> 372     8   3   5 15.75450153 #> 381     3   4   5 -2.48518753 #> 423     3   1   6 -0.65540882 #> 424     4   1   6 -2.77372165 #> 425     5   1   6 -3.02942296 #> 426     6   1   6 -3.00426482 #> 427     7   1   6 -2.82878541 #> 433    13   1   6 -3.02506320 #> 434    14   1   6 -4.02807288 #> 437     3   2   6 -2.84949935 #> 438     4   2   6  1.28122057 #> 439     5   2   6  7.19994488 #> 440     6   2   6  1.57479099 #> 441     7   2   6  8.43782279 #> 447    13   2   6 -3.34205547 #> 448    14   2   6 -2.32040038 #> 451     3   3   6 -2.79562357 #> 452     4   3   6  3.03662609 #> 453     5   3   6 -0.57327476 #> 454     6   3   6  9.64006613 #> 455     7   3   6  6.13766900 #> 465     3   4   6 -2.00379019 #> 507     3   1   7  0.48427789 #> 517    13   1   7 -2.78214154 #> 518    14   1   7 -3.43340214 #> 521     3   2   7 -2.47192834 #> 531    13   2   7 -2.47889773 #> 532    14   2   7  0.31569055 #> 535     3   3   7 -3.08662066 #> 549     3   4   7 -2.21865929 #> 591     3   1   8  0.78576221 #> 601    13   1   8 -2.96893871 #> 602    14   1   8 -0.44522988 #> 605     3   2   8 -1.89829548 #> 615    13   2   8 -3.21015948 #> 616    14   2   8  3.94664694 #> 619     3   3   8 -3.08774902 #> 633     3   4   8 -2.20401789 #> 685    13   1   9 -2.18073299 #> 699    13   2   9 -3.21157908 # }"},{"path":"/reference/mb.validate.data.html","id":null,"dir":"Reference","previous_headings":"","what":"Validates that a dataset fulfils requirements for MBNMA — mb.validate.data","title":"Validates that a dataset fulfils requirements for MBNMA — mb.validate.data","text":"Validates dataset fulfils requirements MBNMA","code":""},{"path":"/reference/mb.validate.data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validates that a dataset fulfils requirements for MBNMA — mb.validate.data","text":"","code":"mb.validate.data(data.ab, single.arm = FALSE, CFB = TRUE)"},{"path":"/reference/mb.validate.data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validates that a dataset fulfils requirements for MBNMA — mb.validate.data","text":"data.ab data frame arm-level data \"long\" format containing columns: studyID Study identifiers time Numeric data indicating follow-times y Numeric data indicating aggregate response given observation (e.g. mean) se Numeric data indicating standard error given observation treatment Treatment identifiers (can numeric, factor character) class optional column indicating particular class identifier. Observations treatment identifier must also class identifier. n optional column indicating number participants used calculate response given observation (required modelling using Standardised Mean Differences) single.arm boolean object indicate whether function allow singe arm studies allowed network without returning error. Default allow inclusion (single.arm=FALSE) CFB boolean object indicate dataset composed studies measuring change baseline (TRUE) (FALSE). essential specify correctly failing may lead warnings.","code":""},{"path":"/reference/mb.validate.data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validates that a dataset fulfils requirements for MBNMA — mb.validate.data","text":"error warnings checks passed. Runs silently checks passed","code":""},{"path":"/reference/mb.validate.data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validates that a dataset fulfils requirements for MBNMA — mb.validate.data","text":"Checks done within validation: Checks data.ab required column names Checks NAs Checks SEs positive Checks studies baseline measurement (unless change baseline data used) Checks arms balanced time point Checks class codes consistent within treatment Checks treatment codes consistent across different time points within study Checks studies least two arms (single.arm = FALSE)","code":""},{"path":"/reference/mb.write.html","id":null,"dir":"Reference","previous_headings":"","what":"Write MBNMA time-course models JAGS code — mb.write","title":"Write MBNMA time-course models JAGS code — mb.write","text":"Writes JAGS code Bayesian time-course model model-based network meta-analysis (MBNMA).","code":""},{"path":"/reference/mb.write.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write MBNMA time-course models JAGS code — mb.write","text":"","code":"mb.write(   fun = tpoly(degree = 1),   link = \"identity\",   positive.scale = TRUE,   intercept = NULL,   rho = 0,   covar = \"varadj\",   omega = NULL,   corparam = TRUE,   class.effect = list(),   UME = FALSE )"},{"path":"/reference/mb.write.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write MBNMA time-course models JAGS code — mb.write","text":"fun object class \"timefun\" generated (see Details) using tloglin(), tpoly(), titp(), temax(), tfpoly(), tspline() tuser() link Can take either \"identity\" (default), \"log\" (modelling Ratios Means (Friedrich et al. 2011) ) \"smd\" (modelling Standardised Mean Differences - although also corresponds identity link function). positive.scale boolean object indicates whether continuous mean responses (y) positive therefore whether baseline response given prior constrains positive (e.g. scales <0). intercept boolean object indicates whether intercept (written alpha model) included. left NULL (default), intercept included studies reporting absolute means, excluded studies reporting change baseline (indicated network$cfb). rho correlation coefficient modelling within-study correlation time points. default string representing prior distribution JAGS, indicating estimated data (e.g. rho=\"dunif(0,1)\"). rho also assigned numeric value (e.g. rho=0.7), fixes rho model value (e.g. use deterministic sensitivity analysis). set rho=0 (default) implies modelling correlation time points. covar character specifying covariance structure use modelling within-study correlation time-points. can done specifying one following: \"varadj\" - univariate likelihood variance adjustment assume constant correlation subsequent time points (Jansen et al. 2015) . default. \"CS\" - multivariate normal likelihood compound symmetry structure \"AR1\" - multivariate normal likelihood autoregressive AR1 structure omega DEPRACATED VERSION 0.2.3 ONWARDS (~uniform(-1,1) now used correlation parameters rather Wishart prior). scale matrix inverse-Wishart prior covariance matrix used model correlation time-course parameters (see Details time-course functions). omega must symmetric positive definite matrix dimensions equal number time-course parameters modelled using relative effects (pool=\"rel\"). left NULL (default) diagonal matrix elements equal 1 used. corparam boolean object indicates whether correlation modeled relative effect time-course parameters. Default FALSE automatically set FALSE class effects modeled. Setting TRUE models correlation time-course parameters. can help identify parameters estimated poorly treatments allowing sharing information parameters different treatments network, may also cause shrinkage. class.effect list named strings determines time-course parameters model class effect effect (\"common\" \"random\"). example: list(emax=\"common\", et50=\"random\"). UME Can take either TRUE FALSE (unrelated mean effects model time-course parameters respectively) can vector parameter name strings model UME. example: c(\"beta.1\", \"beta.2\").","code":""},{"path":"/reference/mb.write.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write MBNMA time-course models JAGS code — mb.write","text":"single long character string containing JAGS model generated based arguments passed function.","code":""},{"path":"/reference/mb.write.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write MBNMA time-course models JAGS code — mb.write","text":"","code":"# Write a linear time-course MBNMA: # random treatment effects on beta.1 # equal baselines in study arms model <- mb.write(fun=tpoly(degree=1, pool.1=\"rel\", method.1=\"random\"))  # Write an emax time-course MBNMA with: # a Hill parameter # no intercept model <- mb.write(fun=temax(pool.emax=\"rel\", method.emax=\"common\",     pool.et50=\"abs\", method.et50=\"common\", pool.hill=\"abs\", method.hill=\"common\"),   intercept=TRUE) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> 'hill' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values.  # Write a log-linear time-course MBNMA with: # AR1 correlation between time points model <- mb.write(fun=tloglin(),   rho=\"dunif(0,1)\", covar=\"AR1\")  # Define a user-defined time-course relationship for the MBNMA JAGS model userfun <- ~ (exp(beta.1 * time) / (beta.2 * time)) model <- mb.write(fun=tuser(fun=userfun,     pool.1=\"rel\", method.1=\"random\",     pool.2=\"rel\", method.2=\"common\"))"},{"path":"/reference/nma.run.html","id":null,"dir":"Reference","previous_headings":"","what":"Run an NMA model — nma.run","title":"Run an NMA model — nma.run","text":"Run NMA model","code":""},{"path":"/reference/nma.run.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run an NMA model — nma.run","text":"","code":"nma.run(data.ab, method = \"common\", link = \"identity\", ...)"},{"path":"/reference/nma.run.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run an NMA model — nma.run","text":"data.ab data frame arm-level data \"long\" format containing columns: studyID Study identifiers time Numeric data indicating follow-times y Numeric data indicating aggregate response given observation (e.g. mean) se Numeric data indicating standard error given observation treatment Treatment identifiers (can numeric, factor character) class optional column indicating particular class identifier. Observations treatment identifier must also class identifier. n optional column indicating number participants used calculate response given observation (required modelling using Standardised Mean Differences) method Can take \"common\" \"random\" indicate type NMA model used synthesise data points given overlay.nma. default \"random\" since assumes different time-points overlay.nma lumped together estimate NMA. link Can take either \"identity\" (default), \"log\" (modelling Ratios Means (Friedrich et al. 2011) ) \"smd\" (modelling Standardised Mean Differences - although also corresponds identity link function). ... Options plotting igraph.","code":""},{"path":"/reference/nma.run.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run an NMA model — nma.run","text":"Returns object class(\"nma\", \"rjags\")","code":""},{"path":"/reference/nma.run.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run an NMA model — nma.run","text":"","code":"network <- mb.network(osteopain) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Get the latest time point df <- get.latest.time(network)  # Get the closest time point to a given value (t) df <- get.closest.time(network, t=7)  # Run NMA on the data nma.run(df, method=\"random\") #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 104 #>    Unobserved stochastic nodes: 133 #>    Total graph size: 1451 #>  #> Initializing model #>  #> Inference for Bugs model at \"/tmp/RtmprYte33/file206610024113\", fit using jags, #>  3 chains, each with 2000 iterations (first 1000 discarded) #>  n.sims = 3000 iterations saved #>            mu.vect sd.vect     2.5%      25%      50%      75%    97.5%  Rhat #> d[1]         0.000   0.000    0.000    0.000    0.000    0.000    0.000 1.000 #> d[2]        -0.045   0.107   -0.238   -0.122   -0.048    0.028    0.150 1.078 #> d[3]        -0.022   0.047   -0.090   -0.059   -0.032    0.011    0.079 1.332 #> d[4]         0.051   0.101   -0.133   -0.023    0.044    0.132    0.237 1.152 #> d[5]        -0.044   0.137   -0.299   -0.144   -0.043    0.061    0.200 1.019 #> d[6]         0.198   0.172   -0.167    0.094    0.198    0.293    0.562 1.079 #> d[7]         0.072   0.073   -0.082    0.031    0.071    0.116    0.219 1.075 #> d[8]         0.043   0.193   -0.295   -0.092    0.028    0.159    0.468 1.270 #> d[9]        -0.135   0.105   -0.332   -0.204   -0.142   -0.068    0.092 1.070 #> d[10]        0.013   0.209   -0.353   -0.154    0.020    0.181    0.381 1.723 #> d[11]       -0.026   0.063   -0.143   -0.071   -0.028    0.017    0.098 1.127 #> d[12]       -0.018   0.061   -0.123   -0.061   -0.025    0.025    0.110 1.153 #> d[13]       -0.137   0.093   -0.335   -0.195   -0.136   -0.070    0.035 1.433 #> d[14]       -0.046   0.094   -0.224   -0.111   -0.046    0.014    0.141 1.036 #> d[15]        0.000   0.060   -0.120   -0.040   -0.001    0.049    0.103 1.059 #> d[16]        0.177   0.070    0.039    0.132    0.180    0.221    0.314 1.074 #> d[17]        0.203   0.229   -0.275    0.063    0.238    0.378    0.556 1.231 #> d[18]        0.208   0.106    0.035    0.134    0.193    0.272    0.459 1.297 #> d[19]        0.060   0.369   -0.576   -0.233    0.060    0.331    0.778 1.137 #> d[20]        0.065   0.119   -0.162   -0.017    0.061    0.139    0.316 1.186 #> d[21]       -0.192   0.219   -0.644   -0.328   -0.196   -0.060    0.295 1.067 #> d[22]        0.161   0.118   -0.091    0.095    0.158    0.229    0.383 1.104 #> d[23]       -0.034   0.108   -0.232   -0.114   -0.030    0.031    0.186 1.097 #> d[24]        0.031   0.090   -0.144   -0.031    0.025    0.091    0.218 1.070 #> d[25]        0.051   0.103   -0.153   -0.020    0.047    0.121    0.252 1.094 #> d[26]       -0.138   0.174   -0.475   -0.257   -0.146    0.015    0.159 1.326 #> d[27]        0.157   0.146   -0.147    0.057    0.153    0.262    0.421 1.042 #> d[28]       -0.028   0.153   -0.325   -0.119   -0.022    0.063    0.292 1.119 #> d[29]        0.068   0.178   -0.278   -0.055    0.069    0.198    0.411 1.609 #> sd           0.033   0.024    0.006    0.014    0.028    0.046    0.092 1.723 #> totresdev  100.892  10.921   80.010   93.409  100.771  107.702  124.250 1.027 #> deviance  -140.155  10.921 -161.037 -147.639 -140.276 -133.346 -116.797 1.030 #>           n.eff #> d[1]          1 #> d[2]         36 #> d[3]         10 #> d[4]         19 #> d[5]        140 #> d[6]         33 #> d[7]         89 #> d[8]         12 #> d[9]        450 #> d[10]         6 #> d[11]        23 #> d[12]        19 #> d[13]         8 #> d[14]        99 #> d[15]        41 #> d[16]        56 #> d[17]        14 #> d[18]        11 #> d[19]        22 #> d[20]        21 #> d[21]        79 #> d[22]        91 #> d[23]        43 #> d[24]        93 #> d[25]        42 #> d[26]        10 #> d[27]       200 #> d[28]        28 #> d[29]         7 #> sd            6 #> totresdev    80 #> deviance     76 #>  #> For each parameter, n.eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor (at convergence, Rhat=1). #>  #> DIC info (using the rule, pD = var(deviance)/2) #> pD = 58.1 and DIC = -82.1 #> DIC is an estimate of expected predictive error (lower deviance is better)."},{"path":"/reference/obesityBW_CFB.html","id":null,"dir":"Reference","previous_headings":"","what":"Studies of treatments for reducing body weight in patients with obesity — obesityBW_CFB","title":"Studies of treatments for reducing body weight in patients with obesity — obesityBW_CFB","text":"dataset systematic review pharmacological treatments reducing body weight patients obesity. outcome continuous, aggregate data responses given mean change baseline body weight (KG). Overall 35 RCTs investigating 26 treatments 16 agents (/combinations agents) network. Standard deviations imputed 421 observations.","code":""},{"path":"/reference/obesityBW_CFB.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Studies of treatments for reducing body weight in patients with obesity — obesityBW_CFB","text":"","code":"obesityBW_CFB"},{"path":"/reference/obesityBW_CFB.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Studies of treatments for reducing body weight in patients with obesity — obesityBW_CFB","text":"data frame 710 rows 7 variables: studyID Study identifiers time Numeric data indicating follow-times y Numeric data indicating mean response given observation se Numeric data indicating standard error given observation n Numeric data indicating number participants used calculate means observation treatment Treatment identifiers factors. Labels shortened treatment names. treatname Character data giving full names treatment format agent_dose agent Agent (drug) names stored characters class drug class agent (broader category agent) stored characters","code":""},{"path":"/reference/obesityBW_CFB.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Studies of treatments for reducing body weight in patients with obesity — obesityBW_CFB","text":"Pfizer Ltd.","code":""},{"path":"/reference/obesityBW_CFB.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Studies of treatments for reducing body weight in patients with obesity — obesityBW_CFB","text":"obesityBW_CFB data frame long format (one row per observation, arm study), variables studyID, time, y, se, n, treatment, treatname, agent class.","code":""},{"path":"/reference/osteopain.html","id":null,"dir":"Reference","previous_headings":"","what":"Studies of pain relief medications for osteoarthritis — osteopain","title":"Studies of pain relief medications for osteoarthritis — osteopain","text":"dataset containing results WOMAC pain scale (0-10) time studies investigating 29 treatments pain relief patients osteoarthritis. Standard deviations imputed 269 observations.","code":""},{"path":"/reference/osteopain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Studies of pain relief medications for osteoarthritis — osteopain","text":"","code":"osteopain"},{"path":"/reference/osteopain.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Studies of pain relief medications for osteoarthritis — osteopain","text":"data frame 417 rows 7 variables: studyID Study identifiers time Numeric data indicating follow-times y Numeric data indicating mean response given observation se Numeric data indicating standard error given observation treatment Treatment identifiers factors. Labels shortened treatment names. arm Arm identifiers coded study treatname Character data giving full names treatment","code":""},{"path":"/reference/osteopain.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Studies of pain relief medications for osteoarthritis — osteopain","text":"Pfizer Ltd.","code":""},{"path":"/reference/osteopain.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Studies of pain relief medications for osteoarthritis — osteopain","text":"osteopain data frame long format (one row per observation, arm study), variables studyID, time, y, se, treatment, arm treatname.","code":""},{"path":"/reference/pDcalc.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate plugin pD from a JAGS model with univariate likelihood for studies\nwith repeated measurements — pDcalc","title":"Calculate plugin pD from a JAGS model with univariate likelihood for studies\nwith repeated measurements — pDcalc","text":"Uses results MBNMA JAGS models calculate pD via plugin method (Spiegelhalter et al. 2002) . Can used models known standard errors covariance matrices (typically univariate).","code":""},{"path":"/reference/pDcalc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate plugin pD from a JAGS model with univariate likelihood for studies\nwith repeated measurements — pDcalc","text":"","code":"pDcalc(   obs1,   obs2,   fups = NULL,   narm,   NS,   theta.result,   resdev.result,   likelihood = \"normal\",   type = \"time\" )"},{"path":"/reference/pDcalc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate plugin pD from a JAGS model with univariate likelihood for studies\nwith repeated measurements — pDcalc","text":"obs1 matrix (study x arm) array (study x arm x time point) containing observed data y (normal likelihood) r (binomial Poisson likelihood) arm study. array used data JAGS model. obs2 matrix (study x arm) array (study x arm x time point) containing observed data se (normal likelihood), N (binomial likelihood) E (Poisson likelihood) arm study. array used data JAGS model. fups numeric vector length equal number studies, containing number follow-mean responses reported study. Required time-course MBNMA models (type=\"time\") narm numeric vector length equal number studies, containing number arms study. NS single number equal number studies dataset. theta.result matrix (study x arm) array (study x arm x time point) containing posterior mean predicted means/probabilities/rate arm study. estimated JAGS model. resdev.result matrix (study x arm) array (study x arm x time point) containing posterior mean residual deviance contributions arm study. estimated JAGS model. likelihood character object following likelihoods: univariate binomial (work time-course MBNMA models) multivar.normal (work time-course MBNMA models) type type MBNMA model fitted. Can either \"time\" \"dose\"","code":""},{"path":"/reference/pDcalc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate plugin pD from a JAGS model with univariate likelihood for studies\nwith repeated measurements — pDcalc","text":"Method calculating pD via plugin method proposed (Spiegelhalter et al. 2002) . Standard errors / covariance matrices must assumed known. obtain values theta.result resdev.result parameters must monitored running JAGS model. non-linear time-course MBNMA models residual deviance contributions may skewed, can lead non-sensical results calculating pD via plugin method. Alternative approaches use pV (pv) approximation (Plummer 2008)  pD calculated Kullback–Leibler divergence (pd.kl) using optimism adjustment (popt) (Plummer 2008) .","code":""},{"path":"/reference/pDcalc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate plugin pD from a JAGS model with univariate likelihood for studies\nwith repeated measurements — pDcalc","text":"ADD pV REF","code":""},{"path":"/reference/pDcalc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate plugin pD from a JAGS model with univariate likelihood for studies\nwith repeated measurements — pDcalc","text":"","code":"# \\donttest{ # Using the alogliptin dataset network <- mb.network(alog_pcfb) #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data  # Run Emax model saving predicted means and residual deviance contributions emax <- mb.run(network, fun=temax(),   parameters.to.save=c(\"theta\", \"resdev\"), intercept=FALSE) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 233 #>    Unobserved stochastic nodes: 38 #>    Total graph size: 4166 #>  #> Initializing model #>   # Get matrices of observed data jagsdat <- getjagsdata(network$data.ab)  # Plugin estimation of pD is problematic with non-linear models as it often leads to #negative values, hence use of pV, pd.kl and popt as other measures for the effective #number of parameters pDcalc(obs1=jagsdat$y, obs2=jagsdat$se,   fups=jagsdat$fups, narm=jagsdat$narm, NS=jagsdat$NS,   theta.result = emax$BUGSoutput$mean$theta,   resdev.result = emax$BUGSoutput$mean$resdev   ) #> [1] -9718.865 # }"},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"/reference/plot.mb.predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots predicted responses from a time-course MBNMA model — plot.mb.predict","title":"Plots predicted responses from a time-course MBNMA model — plot.mb.predict","text":"Plots predicted responses time-course MBNMA model","code":""},{"path":"/reference/plot.mb.predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots predicted responses from a time-course MBNMA model — plot.mb.predict","text":"","code":"# S3 method for mb.predict plot(   x,   disp.obs = FALSE,   overlay.ref = TRUE,   overlay.nma = NULL,   method = \"random\",   col = \"blue\",   max.col.scale = NULL,   treat.labs = NULL,   plot.bins = TRUE,   ... )"},{"path":"/reference/plot.mb.predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots predicted responses from a time-course MBNMA model — plot.mb.predict","text":"x object class \"mb.predict\" generated predict(\"mbnma\") disp.obs boolean object indicate whether show shaded sections plot observed data (TRUE) (FALSE) overlay.ref boolean object indicating whether overlay line showing median network reference treatment response time plot (TRUE) (FALSE). network reference treatment (treatment must included predict display network reference treatment properly. overlay.nma Numeric vector used overlay results standard NMA model \"lumps\" time-points together within time bin ranges specified overlay.nma. numbers overlay.nma define boundaries time bins within perform standard NMA. Length must >=2, can left NULL (default) indicate NMA perfomed. overlay.nma can specified overlay.ref==TRUE. See Details information. method Can take \"common\" \"random\" indicate type NMA model used synthesise data points given overlay.nma. default \"random\" since assumes different time-points overlay.nma lumped together estimate NMA. col character indicating colour use shading disp.obs set TRUE. Can either \"blue\", \"green\", \"red\" max.col.scale Rarely requires adjustment. maximum count observations (therefore darkest shaded color) used disp.obs used. allows consistency shading multiple plotted graphs. always least high maximum count observations plotted treat.labs vector treatment labels order treatment codes. Easiest use treatment labels stored mb.network() plot.bins Plot time bin boundaries vertical dashed lines. Setting plot.bins=TRUE overlay.nma specified also sets x-axis ticks time bin boundaries automatically. ... Arguments ggplot() R2jags()","code":""},{"path":"/reference/plot.mb.predict.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots predicted responses from a time-course MBNMA model — plot.mb.predict","text":"S3 method plot(), disp.obs set TRUE advisable ensure predictions predict estimated using even sequence time points avoid misrepresentation shaded densities. Shaded counts observations relative treatment plotted panel rather network reference treatment disp.obs set TRUE.","code":""},{"path":"/reference/plot.mb.predict.html","id":"overlaying-nma-results","dir":"Reference","previous_headings":"","what":"Overlaying NMA results","title":"Plots predicted responses from a time-course MBNMA model — plot.mb.predict","text":"overlay.nma indicates regions data (defined \"time bins\") may reasonable \"lump\" different follow-times different studies together assume standard NMA model. example: overlay.nma=c(5,10) indicates single NMA studies follow-times >5 <=10 overlay.nma=c(5,10,15) indicates two NMAs performed studies follow-times >5 <=10 studies follow-times >10 <=15 used MBNMA (via predict.mbnma()) allows comparison MBNMA results specific range time within time bin. can useful assess time-course function might suitable using binplot(), assess MBNMA predictions agreement predictions NMA model using plot.mb.predict() specific range time-points. can general indicator fit time-course model. However, important note wider range specified overlay.nma, likely different time-points included, therefore greater heterogeneity/inconsistency NMA model. overlay.nma includes several follow-times study single time-point taken (one closest mean(overlay.nma)). NMA predictions plotted range specified overlay.nma horizontal line, 95%CrI shown grey rectangle. NMA predictions represent time-points within range since lump together data time-points. Predictions treatments disconnected network reference treatment data points specified within overlay.nma estimated included. important note NMA model necessarily \"correct\" model, since \"lumps\" different time-points together ignores potential differences treatment effects may arise . wider range specified overlay.nma, greater effect \"lumping\" stronger assumption similarity studies. NMA model estimated corresponding prediction made , time bin must include network reference treatment (treatment=1) evaluated least 1 connected study time bin. given time bin meet criteria NMA calculated .","code":""},{"path":"/reference/plot.mb.predict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots predicted responses from a time-course MBNMA model — plot.mb.predict","text":"","code":"# \\donttest{ # Create an mb.network object from a dataset copdnet <- mb.network(copd) #> Reference treatment is `Placebo` #> Studies reporting change from baseline automatically identified from the data  # Run an MBNMA model with a log-linear time-course loglin <- mb.run(copdnet,   fun=tloglin(pool.rate=\"rel\", method.rate=\"common\"),   rho=\"dunif(0,1)\", covar=\"varadj\") #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 80 #>    Unobserved stochastic nodes: 16 #>    Total graph size: 1310 #>  #> Initializing model #>   # Predict responses using the original dataset to estimate the network reference #treatment response df.ref <- copd[copd$treatment==\"Placebo\",] predict <- predict(loglin, times=c(0:20), E0=0, ref.resp=df.ref) #> Data frame must contain only data from reference treatment #> Studies reporting change from baseline automatically identified from ref.resp #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 39 #>    Unobserved stochastic nodes: 2 #>    Total graph size: 649 #>  #> Initializing model #>   # Plot the predicted responses with observations displayed on plot as green shading plot(predict, disp.obs=TRUE, overlay.ref=FALSE, col=\"green\")   # Plot the predicted responses with the median network reference treatment response overlayed #on the plot plot(predict, disp.obs=FALSE, overlay.ref=TRUE) #> Reference treatment in plots is Placebo   # Plot predictions from NMAs calculated between different time-points plot(predict, overlay.nma=c(5,10), n.iter=20000) #> Reference treatment in plots is Placebo #> Running overlay.nma for time=5 and time=10 #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 17 #>    Unobserved stochastic nodes: 20 #>    Total graph size: 221 #>  #> Initializing model #>   plot(predict, overlay.nma=c(5,10,15,20), n.iter=20000) #> Reference treatment in plots is Placebo #> Running overlay.nma for time=5 and time=10 #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 17 #>    Unobserved stochastic nodes: 20 #>    Total graph size: 221 #>  #> Initializing model #>  #> Running overlay.nma for time=10 and time=15 #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 18 #>    Unobserved stochastic nodes: 21 #>    Total graph size: 223 #>  #> Initializing model #>  #> Running overlay.nma for time=15 and time=20 #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 2 #>    Unobserved stochastic nodes: 4 #>    Total graph size: 41 #>  #> Initializing model #>   # Time-course fit may be less well at 15-20 weeks follow-up # }"},{"path":"/reference/plot.mb.rank.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot histograms of rankings from MBNMA models — plot.mb.rank","title":"Plot histograms of rankings from MBNMA models — plot.mb.rank","text":"Plot histograms rankings MBNMA models","code":""},{"path":"/reference/plot.mb.rank.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot histograms of rankings from MBNMA models — plot.mb.rank","text":"","code":"# S3 method for mb.rank plot(x, params = NULL, treat.labs = NULL, ...)"},{"path":"/reference/plot.mb.rank.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot histograms of rankings from MBNMA models — plot.mb.rank","text":"x object class \"mb.rank\" generated rank.mbnma() params character vector containing model parameters monitored mbnma ranking desired (e.g. \"beta.1\", \"emax\"). Parameters must vary treatment ranking possible. Can include \"auc\" (see details). treat.labs vector treatment labels order treatment codes. Easiest use treatment labels stored mb.network() ... Arguments sent ggplot2::ggplot()","code":""},{"path":"/reference/plot.mb.rank.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot histograms of rankings from MBNMA models — plot.mb.rank","text":"series histograms show rankings treatment/agent/prediction, separate panel parameter object returned list containing separate element parameter params object class c(\"gg\", \"ggplot\").","code":""},{"path":"/reference/plot.mb.rank.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot histograms of rankings from MBNMA models — plot.mb.rank","text":"","code":"# \\donttest{ # Create an mb.network object from a dataset painnet <- mb.network(osteopain) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Run an MBNMA model with an Emax time-course emax <- mb.run(painnet,   fun=temax(pool.emax=\"rel\", method.emax=\"common\",     pool.et50=\"abs\", method.et50=\"random\"),   positive.scale=TRUE) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 194 #>    Total graph size: 8240 #>  #> Initializing model #>   # Calculate treatment rankings for AUC and emax ranks <- rank(emax,   param=c(\"auc\", \"emax\"),   int.range=c(0,15), n.iter=500) #>    |                                                                               |                                                                      |   0%   |                                                                               |                                                                      |   1%   |                                                                               |=                                                                     |   1%   |                                                                               |=                                                                     |   2%   |                                                                               |==                                                                    |   2%   |                                                                               |==                                                                    |   3%   |                                                                               |===                                                                   |   4%   |                                                                               |===                                                                   |   5%   |                                                                               |====                                                                  |   5%   |                                                                               |====                                                                  |   6%   |                                                                               |=====                                                                 |   7%   |                                                                               |=====                                                                 |   8%   |                                                                               |======                                                                |   8%   |                                                                               |======                                                                |   9%   |                                                                               |=======                                                               |   9%   |                                                                               |=======                                                               |  10%   |                                                                               |=======                                                               |  11%   |                                                                               |========                                                              |  11%   |                                                                               |========                                                              |  12%   |                                                                               |=========                                                             |  12%   |                                                                               |=========                                                             |  13%   |                                                                               |==========                                                            |  14%   |                                                                               |==========                                                            |  15%   |                                                                               |===========                                                           |  15%   |                                                                               |===========                                                           |  16%   |                                                                               |============                                                          |  17%   |                                                                               |============                                                          |  18%   |                                                                               |=============                                                         |  18%   |                                                                               |=============                                                         |  19%   |                                                                               |==============                                                        |  19%   |                                                                               |==============                                                        |  20%   |                                                                               |==============                                                        |  21%   |                                                                               |===============                                                       |  21%   |                                                                               |===============                                                       |  22%   |                                                                               |================                                                      |  22%   |                                                                               |================                                                      |  23%   |                                                                               |=================                                                     |  24%   |                                                                               |=================                                                     |  25%   |                                                                               |==================                                                    |  25%   |                                                                               |==================                                                    |  26%   |                                                                               |===================                                                   |  27%   |                                                                               |===================                                                   |  28%   |                                                                               |====================                                                  |  28%   |                                                                               |====================                                                  |  29%   |                                                                               |=====================                                                 |  29%   |                                                                               |=====================                                                 |  30%   |                                                                               |=====================                                                 |  31%   |                                                                               |======================                                                |  31%   |                                                                               |======================                                                |  32%   |                                                                               |=======================                                               |  32%   |                                                                               |=======================                                               |  33%   |                                                                               |========================                                              |  34%   |                                                                               |========================                                              |  35%   |                                                                               |=========================                                             |  35%   |                                                                               |=========================                                             |  36%   |                                                                               |==========================                                            |  37%   |                                                                               |==========================                                            |  38%   |                                                                               |===========================                                           |  38%   |                                                                               |===========================                                           |  39%   |                                                                               |============================                                          |  39%   |                                                                               |============================                                          |  40%   |                                                                               |============================                                          |  41%   |                                                                               |=============================                                         |  41%   |                                                                               |=============================                                         |  42%   |                                                                               |==============================                                        |  42%   |                                                                               |==============================                                        |  43%   |                                                                               |===============================                                       |  44%   |                                                                               |===============================                                       |  45%   |                                                                               |================================                                      |  45%   |                                                                               |================================                                      |  46%   |                                                                               |=================================                                     |  47%   |                                                                               |=================================                                     |  48%   |                                                                               |==================================                                    |  48%   |                                                                               |==================================                                    |  49%   |                                                                               |===================================                                   |  49%   |                                                                               |===================================                                   |  50%   |                                                                               |===================================                                   |  51%   |                                                                               |====================================                                  |  51%   |                                                                               |====================================                                  |  52%   |                                                                               |=====================================                                 |  52%   |                                                                               |=====================================                                 |  53%   |                                                                               |======================================                                |  54%   |                                                                               |======================================                                |  55%   |                                                                               |=======================================                               |  55%   |                                                                               |=======================================                               |  56%   |                                                                               |========================================                              |  57%   |                                                                               |========================================                              |  58%   |                                                                               |=========================================                             |  58%   |                                                                               |=========================================                             |  59%   |                                                                               |==========================================                            |  59%   |                                                                               |==========================================                            |  60%   |                                                                               |==========================================                            |  61%   |                                                                               |===========================================                           |  61%   |                                                                               |===========================================                           |  62%   |                                                                               |============================================                          |  62%   |                                                                               |============================================                          |  63%   |                                                                               |=============================================                         |  64%   |                                                                               |=============================================                         |  65%   |                                                                               |==============================================                        |  65%   |                                                                               |==============================================                        |  66%   |                                                                               |===============================================                       |  67%   |                                                                               |===============================================                       |  68%   |                                                                               |================================================                      |  68%   |                                                                               |================================================                      |  69%   |                                                                               |=================================================                     |  69%   |                                                                               |=================================================                     |  70%   |                                                                               |=================================================                     |  71%   |                                                                               |==================================================                    |  71%   |                                                                               |==================================================                    |  72%   |                                                                               |===================================================                   |  72%   |                                                                               |===================================================                   |  73%   |                                                                               |====================================================                  |  74%   |                                                                               |====================================================                  |  75%   |                                                                               |=====================================================                 |  75%   |                                                                               |=====================================================                 |  76%   |                                                                               |======================================================                |  77%   |                                                                               |======================================================                |  78%   |                                                                               |=======================================================               |  78%   |                                                                               |=======================================================               |  79%   |                                                                               |========================================================              |  79%   |                                                                               |========================================================              |  80%   |                                                                               |========================================================              |  81%   |                                                                               |=========================================================             |  81%   |                                                                               |=========================================================             |  82%   |                                                                               |==========================================================            |  82%   |                                                                               |==========================================================            |  83%   |                                                                               |===========================================================           |  84%   |                                                                               |===========================================================           |  85%   |                                                                               |============================================================          |  85%   |                                                                               |============================================================          |  86%   |                                                                               |=============================================================         |  87%   |                                                                               |=============================================================         |  88%   |                                                                               |==============================================================        |  88%   |                                                                               |==============================================================        |  89%   |                                                                               |===============================================================       |  89%   |                                                                               |===============================================================       |  90%   |                                                                               |===============================================================       |  91%   |                                                                               |================================================================      |  91%   |                                                                               |================================================================      |  92%   |                                                                               |=================================================================     |  92%   |                                                                               |=================================================================     |  93%   |                                                                               |==================================================================    |  94%   |                                                                               |==================================================================    |  95%   |                                                                               |===================================================================   |  95%   |                                                                               |===================================================================   |  96%   |                                                                               |====================================================================  |  97%   |                                                                               |====================================================================  |  98%   |                                                                               |===================================================================== |  98%   |                                                                               |===================================================================== |  99%   |                                                                               |======================================================================|  99%   |                                                                               |======================================================================| 100%  # Plot histograms for ranking by AUC plot(ranks, param=\"auc\")   # Plot histograms for ranking by emax plot(ranks, param=\"emax\")  # }"},{"path":"/reference/plot.mbnma.html","id":null,"dir":"Reference","previous_headings":"","what":"Forest plot for results from time-course MBNMA models — plot.mbnma","title":"Forest plot for results from time-course MBNMA models — plot.mbnma","text":"Generates forest plot time-course parameters interest results time-course MBNMA models. Posterior densities plotted result using ggdist:stat_:halfeye()","code":""},{"path":"/reference/plot.mbnma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Forest plot for results from time-course MBNMA models — plot.mbnma","text":"","code":"# S3 method for mbnma plot(x, params = NULL, treat.labs = NULL, class.labs = NULL, ...)"},{"path":"/reference/plot.mbnma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Forest plot for results from time-course MBNMA models — plot.mbnma","text":"x S3 object class \"mbnma\" generated running time-course MBNMA model params character vector time-course parameters plot. Parameters must given name monitored nodes mbnma must vary treatment class. Can set NULL include available time-course parameters estimated mbnma. treat.labs character vector treatment labels. left NULL (default) labels used defined data. class.labs character vector class labels mbnma modelled using class effects left NULL (default) labels used defined data. ... Arguments sent ggdist::stat_halfeye()","code":""},{"path":"/reference/plot.mbnma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Forest plot for results from time-course MBNMA models — plot.mbnma","text":"forest plot class c(\"gg\", \"ggplot\") separate panels different time-course parameters","code":""},{"path":"/reference/plot.mbnma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Forest plot for results from time-course MBNMA models — plot.mbnma","text":"","code":"# \\donttest{ # Create an mb.network object from a dataset alognet <- mb.network(alog_pcfb) #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data  # Run an MBNMA model with an Emax time-course emax <- mb.run(alognet,   fun=temax(pool.emax=\"rel\", method.emax=\"common\",     pool.et50=\"rel\", method.et50=\"common\"),   intercept=FALSE) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 233 #>    Unobserved stochastic nodes: 38 #>    Total graph size: 4166 #>  #> Initializing model #>   # Generate forest plot plot(emax)   # Plot results for only one time-course parameter plot(emax, params=\"emax\")  # }"},{"path":"/reference/predict.mbnma.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict effects over time in a given population based on MBNMA time-course\nmodels — predict.mbnma","title":"Predict effects over time in a given population based on MBNMA time-course\nmodels — predict.mbnma","text":"Used predict effects time different treatments predict results new study. MBNMA models include consistency relative effects time-course parameters, calculated combining relative treatment effects given reference treatment response (specific population interest).","code":""},{"path":"/reference/predict.mbnma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict effects over time in a given population based on MBNMA time-course\nmodels — predict.mbnma","text":"","code":"# S3 method for mbnma predict(   object,   times = seq(0, max(object$model.arg$jagsdata$time, na.rm = TRUE), length.out = 30),   E0 = 0,   treats = NULL,   level = \"treatment\",   ref.resp = NULL,   synth = \"common\",   lim = \"cred\",   ... )"},{"path":"/reference/predict.mbnma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict effects over time in a given population based on MBNMA time-course\nmodels — predict.mbnma","text":"object S3 object class(\"mbnma\") generated running time-course MBNMA model times sequence positive numbers indicating time points predict mean responses (conduct node-split used mb.nodesplit()) E0 object indicate value(s) use response time = 0 prediction. can take number different formats depending used/calculated. default 0 may lead non-sensical predictions Ratio Means modeled. numeric() single numeric value representing deterministic response time = 0 formula() formula representing stochastic distribution response time = 0. specified random number generator (RNG) given string, can take RNG distribution function exists R. example: ~rnorm(n, 7, 0.5). treats character vector treatment/class names numeric vector treatment/class codes (coded mbnma) indicates treatments/classes calculate predictions . left NULL predictions calculated treatments/classes. Whether vector correspond treatments classes depends value level. level Can take either \"treatment\" make predictions treatments, \"class\" make predictions classes (case object must class effect model). ref.resp object indicate value(s) use reference treatment response MBNMA models reference treatment response estimated within model (.e. model time- course parameters using pool=\"rel\"). can take number different formats depending used/calculated. two approaches : reference response can estimated dataset studies investigating reference treatment using meta-analysis. dataset set observational studies specific population make predictions, subset study arms within MBNMA dataset investigate reference treatment. data provided ref.resp data.frame() containing data long format (one row per observation). See ref.synth() Values reference treatment response can assigned different time-course parameters within model modelled using consistency relative effects (pool=\"rel\"). given list, named element corresponds time-course parameter modelled mbnma. values can either following: numeric() numeric value representing deterministic value time-course parameter question individuals given reference treatment. 0 used default, assumes effect time reference treatment (.e. mean differences / relative effects versus reference treatment modeled). formula() formula representing stochastic distribution value time-course parameter question. specified random number generator (RNG) given formula, can take RNG distribution function exists R. example: ~rnorm(n, -3, 0.2). synth character object can take value \"common\" \"random\" specifies type pooling use synthesis ref.resp. Using \"random\" rather \"common\" synth result wider 95\\% CrI predictions. lim Specifies calculation either 95% credible intervals (lim=\"cred\") 95% prediction intervals (lim=\"pred\"). ... Arguments sent R2jags synthesis network reference treatment effect (using ref.synth())","code":""},{"path":"/reference/predict.mbnma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict effects over time in a given population based on MBNMA time-course\nmodels — predict.mbnma","text":"S3 object class mb.predict contains following elements: summary named list data frames. data frame contains summary predicted responses follow-times specified times treatment specified treats pred.mat named list matrices. matrix contains MCMC results predicted responses follow-times specified times treatment specified treats","code":""},{"path":"/reference/predict.mbnma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Predict effects over time in a given population based on MBNMA time-course\nmodels — predict.mbnma","text":"default network reference treatment baseline (E0) time-course parameter values set zero predict() estimates mean differences (/relative treatment effects) time versus network reference treatment. ref.resp needs specified mbnma estimated using consistency relative effects (pool=\"rel\") time-course parameters, inform absolute values network reference treatment parameters can added relative effects calculate specific predictions.","code":""},{"path":"/reference/predict.mbnma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict effects over time in a given population based on MBNMA time-course\nmodels — predict.mbnma","text":"","code":"# \\donttest{ # Create an mb.network object from a dataset network <- mb.network(osteopain) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Run an MBNMA model with an Emax time-course emax <- mb.run(network,   fun=temax(pool.emax=\"rel\", method.emax=\"common\",     pool.et50=\"abs\", method.et50=\"common\")) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 89 #>    Total graph size: 7703 #>  #> Initializing model #>   # Predict responses using a stochastic baseline (E0) and a distribution for the #network reference treatment preds <- predict(emax, times=c(0:10),   E0=~rnorm(n, 7, 0.5),   ref.resp=list(emax=~rnorm(n, -0.5, 0.05))) #> Priors required for: mu.1 #> Success: Elements in prior match consistency time-course treatment effect parameters summary(preds) #>       time     Pl_0   Ce_100   Ce_200   Ce_400    Du_90    Et_10    Et_30 #>  [1,]    0 7.005450 7.005450 7.005450 7.005450 7.005450 7.005450 7.005450 #>  [2,]    1 6.675765 6.297475 6.125762 6.063860 6.300273 6.603914 5.953470 #>  [3,]    2 6.607934 6.151800 5.944768 5.870133 6.155181 6.521333 5.737028 #>  [4,]    3 6.578652 6.088913 5.866635 5.786504 6.092546 6.485687 5.643593 #>  [5,]    4 6.562329 6.053855 5.823078 5.739884 6.057630 6.465817 5.591506 #>  [6,]    5 6.551920 6.031500 5.795304 5.710156 6.035365 6.453147 5.558293 #>  [7,]    6 6.544704 6.016003 5.776050 5.689548 6.019930 6.444363 5.535268 #>  [8,]    7 6.539407 6.004627 5.761917 5.674421 6.008600 6.437916 5.518367 #>  [9,]    8 6.535354 5.995922 5.751101 5.662845 5.999930 6.432983 5.505433 #> [10,]    9 6.532152 5.989046 5.742558 5.653701 5.993081 6.429086 5.495217 #> [11,]   10 6.529559 5.983477 5.735639 5.646295 5.987534 6.425929 5.486943 #>           Et_5    Et_60    Et_90   Lu_100   Lu_200   Lu_400    Lu_NA  Na_1000 #>  [1,] 7.005450 7.005450 7.005450 7.005450 7.005450 7.005450 7.005450 7.005450 #>  [2,] 6.602191 5.564168 5.565775 6.160144 6.168307 6.047835 6.090014 5.900434 #>  [3,] 6.519224 5.267629 5.269554 5.986221 5.996065 5.850810 5.901651 5.673079 #>  [4,] 6.483409 5.139617 5.141679 5.911140 5.921711 5.765757 5.820335 5.574934 #>  [5,] 6.463443 5.068255 5.070392 5.869285 5.880261 5.718343 5.775004 5.520220 #>  [6,] 6.450712 5.022750 5.024935 5.842596 5.853830 5.688109 5.746098 5.485332 #>  [7,] 6.441886 4.991204 4.993423 5.824094 5.835507 5.667150 5.726060 5.461147 #>  [8,] 6.435408 4.968049 4.970292 5.810513 5.822057 5.651765 5.711351 5.443393 #>  [9,] 6.430450 4.950329 4.952591 5.800120 5.811765 5.639992 5.700094 5.429808 #> [10,] 6.426534 4.936332 4.938609 5.791911 5.803635 5.630692 5.691203 5.419076 #> [11,] 6.423363 4.924996 4.927285 5.785262 5.797051 5.623160 5.684002 5.410385 #>        Na_1500   Na_250   Na_750    Ox_44    Ro_12   Ro_125    Ro_25   Tr_100 #>  [1,] 7.005450 7.005450 7.005450 7.005450 7.005450 7.005450 7.005450 7.005450 #>  [2,] 5.957163 6.883203 6.133066 5.922490 6.157136 5.136819 5.907323 6.549768 #>  [3,] 5.741486 6.858098 5.953579 5.699690 5.982603 4.752321 5.681380 6.456010 #>  [4,] 5.648381 6.847265 5.876098 5.603511 5.907261 4.586336 5.583843 6.415536 #>  [5,] 5.596479 6.841228 5.832905 5.549895 5.865260 4.493804 5.529469 6.392973 #>  [6,] 5.563383 6.837378 5.805363 5.515707 5.838478 4.434800 5.494797 6.378585 #>  [7,] 5.540440 6.834710 5.786269 5.492007 5.819911 4.393896 5.470761 6.368611 #>  [8,] 5.523599 6.832751 5.772254 5.474610 5.806283 4.363871 5.453118 6.361290 #>  [9,] 5.510711 6.831253 5.761529 5.461297 5.795854 4.340895 5.439617 6.355687 #> [10,] 5.500531 6.830069 5.753057 5.450780 5.787616 4.322745 5.428952 6.351262 #> [11,] 5.492286 6.829110 5.746196 5.442264 5.780944 4.308046 5.420314 6.347678 #>         Tr_200   Tr_300   Tr_400    Va_10    Va_20     Va_5 #>  [1,] 7.005450 7.005450 7.005450 7.005450 7.005450 7.005450 #>  [2,] 6.480205 6.223788 6.187582 6.210777 6.072871 6.184990 #>  [3,] 6.372129 6.062953 6.019295 6.047292 5.880990 6.016190 #>  [4,] 6.325473 5.993523 5.946647 5.976720 5.798158 5.943322 #>  [5,] 6.299463 5.954817 5.906148 5.937379 5.751981 5.902701 #>  [6,] 6.282878 5.930136 5.880323 5.912293 5.722536 5.876799 #>  [7,] 6.271381 5.913026 5.862420 5.894903 5.702124 5.858843 #>  [8,] 6.262941 5.900466 5.849279 5.882138 5.687141 5.845662 #>  [9,] 6.256483 5.890855 5.839223 5.872369 5.675675 5.835576 #> [10,] 6.251381 5.883264 5.831279 5.864653 5.666618 5.827608 #> [11,] 6.247250 5.877115 5.824846 5.858404 5.659283 5.821156  # Predict responses using the original dataset to estimate the network reference #treatment response paindata.ref <- osteopain[osteopain$treatname==\"Placebo_0\",] preds <- predict(emax, times=c(5:15),   E0=10,   ref.resp=paindata.ref) #> Data frame must contain only data from reference treatment #> Studies reporting change from baseline automatically identified from ref.resp #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 113 #>    Unobserved stochastic nodes: 31 #>    Total graph size: 2037 #>  #> Initializing model #>  summary(preds) #>       time     Pl_0   Ce_100   Ce_200   Ce_400    Du_90    Et_10    Et_30 #>  [1,]    5 8.535336 8.014916 7.778720 7.693572 8.018780 8.436562 7.541709 #>  [2,]    6 8.512037 7.983335 7.743382 7.656880 7.987262 8.411696 7.502600 #>  [3,]    7 8.494934 7.960154 7.717444 7.629948 7.964127 8.393443 7.473894 #>  [4,]    8 8.481847 7.942415 7.697594 7.609337 7.946422 8.379475 7.451926 #>  [5,]    9 8.471509 7.928402 7.681914 7.593057 7.932437 8.368442 7.434573 #>  [6,]   10 8.463136 7.917054 7.669216 7.579872 7.921111 8.359506 7.420520 #>  [7,]   11 8.456217 7.907675 7.658722 7.568976 7.911752 8.352122 7.408906 #>  [8,]   12 8.450404 7.899795 7.649905 7.559821 7.903887 8.345917 7.399148 #>  [9,]   13 8.445450 7.893081 7.642391 7.552019 7.897186 8.340631 7.390833 #> [10,]   14 8.441179 7.887291 7.635913 7.545293 7.891408 8.336072 7.383664 #> [11,]   15 8.437458 7.882248 7.630270 7.539433 7.886374 8.332101 7.377418 #>           Et_5    Et_60    Et_90   Lu_100   Lu_200   Lu_400    Lu_NA  Na_1000 #>  [1,] 8.434128 7.006166 7.008351 7.826012 7.837246 7.671525 7.729514 7.468748 #>  [2,] 8.409219 6.958537 6.960756 7.791427 7.802840 7.634482 7.693392 7.428479 #>  [3,] 8.390935 6.923576 6.925819 7.766040 7.777584 7.607292 7.666877 7.398920 #>  [4,] 8.376943 6.896822 6.899084 7.746613 7.758258 7.586484 7.646587 7.376300 #>  [5,] 8.365891 6.875689 6.877965 7.731267 7.742991 7.570048 7.630559 7.358433 #>  [6,] 8.356940 6.858573 6.860862 7.718839 7.730627 7.556737 7.617579 7.343962 #>  [7,] 8.349543 6.844429 6.846727 7.708568 7.720410 7.545737 7.606852 7.332004 #>  [8,] 8.343327 6.832545 6.834851 7.699938 7.711825 7.536494 7.597839 7.321955 #>  [9,] 8.338031 6.822418 6.824732 7.692585 7.704510 7.528618 7.590159 7.313394 #> [10,] 8.333465 6.813687 6.816006 7.686245 7.698202 7.521827 7.583537 7.306011 #> [11,] 8.329487 6.806080 6.808405 7.680722 7.692708 7.515912 7.577768 7.299580 #>        Na_1500   Na_250   Na_750    Ox_44    Ro_12   Ro_125    Ro_25   Tr_100 #>  [1,] 7.546799 8.820794 7.788778 7.499123 7.821893 6.418216 7.478213 8.362001 #>  [2,] 7.507772 8.802042 7.753602 7.459339 7.787244 6.361229 7.438094 8.335944 #>  [3,] 7.479125 8.788278 7.727781 7.430136 7.761810 6.319398 7.408645 8.316817 #>  [4,] 7.457204 8.777745 7.708022 7.407789 7.742346 6.287387 7.386109 8.302180 #>  [5,] 7.439887 8.769425 7.692413 7.390137 7.726972 6.262101 7.368308 8.290618 #>  [6,] 7.425863 8.762687 7.679773 7.375840 7.714521 6.241623 7.353891 8.281254 #>  [7,] 7.414274 8.757119 7.669327 7.364026 7.704231 6.224700 7.341977 8.273516 #>  [8,] 7.404536 8.752440 7.660549 7.354099 7.695585 6.210480 7.331967 8.267014 #>  [9,] 7.396238 8.748453 7.653070 7.345641 7.688219 6.198364 7.323437 8.261474 #> [10,] 7.389083 8.745016 7.646622 7.338347 7.681866 6.187916 7.316082 8.256697 #> [11,] 7.382851 8.742021 7.641004 7.331994 7.676333 6.178815 7.309675 8.252536 #>         Tr_200   Tr_300   Tr_400    Va_10    Va_20     Va_5 #>  [1,] 8.266294 7.913551 7.863739 7.895709 7.705952 7.860215 #>  [2,] 8.238713 7.880358 7.829753 7.862235 7.669457 7.826175 #>  [3,] 8.218468 7.855993 7.804806 7.837664 7.642668 7.801189 #>  [4,] 8.202975 7.837348 7.785715 7.818862 7.622167 7.782068 #>  [5,] 8.190738 7.822620 7.770635 7.804009 7.605974 7.766965 #>  [6,] 8.180826 7.810692 7.758423 7.791980 7.592859 7.754733 #>  [7,] 8.172636 7.800835 7.748330 7.782040 7.582022 7.744624 #>  [8,] 8.165754 7.792552 7.739850 7.773688 7.572915 7.736131 #>  [9,] 8.159890 7.785495 7.732624 7.766571 7.565156 7.728893 #> [10,] 8.154834 7.779410 7.726393 7.760434 7.558465 7.722653 #> [11,] 8.150429 7.774109 7.720966 7.755089 7.552637 7.717217  # Repeat the above prediction but using a random effects meta-analysis of the #network reference treatment response preds <- predict(emax, times=c(5:15),   E0=10,   ref.resp=paindata.ref,   synth=\"random\") #> Data frame must contain only data from reference treatment #> Studies reporting change from baseline automatically identified from ref.resp #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 113 #>    Unobserved stochastic nodes: 61 #>    Total graph size: 2261 #>  #> Initializing model #>  summary(preds) #>       time     Pl_0   Ce_100   Ce_200   Ce_400    Du_90    Et_10    Et_30 #>  [1,]    5 8.521118 8.000698 7.764502 7.679355 8.004563 8.422345 7.527491 #>  [2,]    6 8.497595 7.968893 7.728940 7.642438 7.972820 8.397254 7.488158 #>  [3,]    7 8.480327 7.945547 7.702837 7.615341 7.949520 8.378836 7.459287 #>  [4,]    8 8.467114 7.927682 7.682861 7.594604 7.931689 8.364742 7.437193 #>  [5,]    9 8.456676 7.913569 7.667082 7.578224 7.917605 8.353609 7.419741 #>  [6,]   10 8.448223 7.902140 7.654303 7.564959 7.906198 8.344593 7.405607 #>  [7,]   11 8.441238 7.892695 7.643742 7.553996 7.896772 8.337142 7.393926 #>  [8,]   12 8.435368 7.884759 7.634869 7.544785 7.888851 8.330881 7.384112 #>  [9,]   13 8.430367 7.877997 7.627308 7.536936 7.882102 8.325547 7.375749 #> [10,]   14 8.426054 7.872166 7.620788 7.530168 7.876283 8.320947 7.368539 #> [11,]   15 8.422297 7.867087 7.615109 7.524273 7.871214 8.316940 7.362257 #>           Et_5    Et_60    Et_90   Lu_100   Lu_200   Lu_400    Lu_NA  Na_1000 #>  [1,] 8.419911 6.991948 6.994134 7.811795 7.823028 7.657307 7.715297 7.454531 #>  [2,] 8.394777 6.944095 6.946314 7.776985 7.788398 7.620040 7.678950 7.414037 #>  [3,] 8.376328 6.908969 6.911212 7.751433 7.762977 7.592685 7.652271 7.384313 #>  [4,] 8.362210 6.882089 6.884351 7.731880 7.743525 7.571751 7.631854 7.361567 #>  [5,] 8.351058 6.860856 6.863133 7.716434 7.728159 7.555216 7.615727 7.343600 #>  [6,] 8.342026 6.843660 6.845948 7.703926 7.715714 7.541824 7.602666 7.329049 #>  [7,] 8.334563 6.829449 6.831748 7.693588 7.705430 7.530757 7.591872 7.317024 #>  [8,] 8.328291 6.817509 6.819815 7.684903 7.696789 7.521458 7.582803 7.306920 #>  [9,] 8.322948 6.807335 6.809648 7.677502 7.689426 7.513535 7.575075 7.298310 #> [10,] 8.318340 6.798562 6.800882 7.671120 7.683078 7.506703 7.568412 7.290887 #> [11,] 8.314326 6.790920 6.793245 7.665561 7.677547 7.500751 7.562607 7.284420 #>        Na_1500   Na_250   Na_750    Ox_44    Ro_12   Ro_125    Ro_25   Tr_100 #>  [1,] 7.532581 8.806577 7.774561 7.484906 7.807676 6.403998 7.463995 8.347784 #>  [2,] 7.493330 8.787600 7.739160 7.444897 7.772802 6.346787 7.423652 8.321502 #>  [3,] 7.464519 8.773671 7.713174 7.415530 7.747203 6.304791 7.394038 8.302210 #>  [4,] 7.442471 8.763012 7.693289 7.393056 7.727614 6.272654 7.371376 8.287447 #>  [5,] 7.425055 8.754593 7.677581 7.375304 7.712140 6.247269 7.353475 8.275785 #>  [6,] 7.410950 8.747774 7.664860 7.360927 7.699608 6.226710 7.338978 8.266341 #>  [7,] 7.399294 8.742139 7.654347 7.349046 7.689251 6.209720 7.326997 8.258536 #>  [8,] 7.389500 8.737404 7.645513 7.339063 7.680549 6.195444 7.316931 8.251979 #>  [9,] 7.381154 8.733370 7.637987 7.330557 7.673135 6.183280 7.308353 8.246391 #> [10,] 7.373959 8.729891 7.631497 7.323223 7.666742 6.172792 7.300957 8.241573 #> [11,] 7.367690 8.726861 7.625843 7.316833 7.661172 6.163655 7.294514 8.237375 #>         Tr_200   Tr_300   Tr_400    Va_10    Va_20     Va_5 #>  [1,] 8.252077 7.899334 7.849522 7.881491 7.691735 7.845997 #>  [2,] 8.224271 7.865916 7.815311 7.847793 7.655015 7.811733 #>  [3,] 8.203861 7.841386 7.790199 7.823058 7.628061 7.786582 #>  [4,] 8.188242 7.822615 7.770982 7.804129 7.607435 7.767335 #>  [5,] 8.175905 7.807787 7.755803 7.789177 7.591142 7.752132 #>  [6,] 8.165913 7.795779 7.743509 7.777067 7.577946 7.739819 #>  [7,] 8.157656 7.785855 7.733350 7.767060 7.567042 7.729644 #>  [8,] 8.150718 7.777516 7.724814 7.758652 7.557879 7.721095 #>  [9,] 8.144806 7.770411 7.717540 7.751487 7.550072 7.713810 #> [10,] 8.139709 7.764285 7.711268 7.745309 7.543340 7.707528 #> [11,] 8.135268 7.758948 7.705805 7.739928 7.537476 7.702056 # }"},{"path":"/reference/print.mb.network.html","id":null,"dir":"Reference","previous_headings":"","what":"Print mb.network information to the console — print.mb.network","title":"Print mb.network information to the console — print.mb.network","text":"Print mb.network information console","code":""},{"path":"/reference/print.mb.network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print mb.network information to the console — print.mb.network","text":"","code":"# S3 method for mb.network print(x, ...)"},{"path":"/reference/print.mb.network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print mb.network information to the console — print.mb.network","text":"x object class mb.network. ... arguments passed methods","code":""},{"path":"/reference/print.mb.predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Print summary information from an mb.predict object — print.mb.predict","title":"Print summary information from an mb.predict object — print.mb.predict","text":"Print summary information mb.predict object","code":""},{"path":"/reference/print.mb.predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print summary information from an mb.predict object — print.mb.predict","text":"","code":"# S3 method for mb.predict print(x, ...)"},{"path":"/reference/print.mb.predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print summary information from an mb.predict object — print.mb.predict","text":"x object class(\"mb.predict\") generated predict.mbnma() ... arguments passed methods","code":""},{"path":"/reference/print.mb.rank.html","id":null,"dir":"Reference","previous_headings":"","what":"Prints a summary of rankings for each parameter — print.mb.rank","title":"Prints a summary of rankings for each parameter — print.mb.rank","text":"Prints summary rankings parameter","code":""},{"path":"/reference/print.mb.rank.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prints a summary of rankings for each parameter — print.mb.rank","text":"","code":"# S3 method for mb.rank print(x, ...)"},{"path":"/reference/print.mb.rank.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prints a summary of rankings for each parameter — print.mb.rank","text":"x object class \"mb.rank\" generated rank.mbnma() ... arguments passed methods","code":""},{"path":"/reference/print.nodesplit.html","id":null,"dir":"Reference","previous_headings":"","what":"Prints basic results from a node-split to the console — print.nodesplit","title":"Prints basic results from a node-split to the console — print.nodesplit","text":"Prints basic results node-split console","code":""},{"path":"/reference/print.nodesplit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prints basic results from a node-split to the console — print.nodesplit","text":"","code":"# S3 method for nodesplit print(x, groupby = \"time.param\", ...)"},{"path":"/reference/print.nodesplit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prints basic results from a node-split to the console — print.nodesplit","text":"x object class \"nodesplit\" generated mb.nodeplit() groupby character object can take value \"time.param\" present results grouped time-course parameter (default) \"comparison\" present results grouped treatment comparison. ... arguments sent knitr::kable()","code":""},{"path":"/reference/print.relative.array.html","id":null,"dir":"Reference","previous_headings":"","what":"Print posterior medians (95% credible intervals) for table of relative effects/mean\ndifferences between treatments/classes — print.relative.array","title":"Print posterior medians (95% credible intervals) for table of relative effects/mean\ndifferences between treatments/classes — print.relative.array","text":"Print posterior medians (95% credible intervals) table relative effects/mean differences treatments/classes","code":""},{"path":"/reference/print.relative.array.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print posterior medians (95% credible intervals) for table of relative effects/mean\ndifferences between treatments/classes — print.relative.array","text":"","code":"# S3 method for relative.array print(x, digits = 2, ...)"},{"path":"/reference/print.relative.array.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print posterior medians (95% credible intervals) for table of relative effects/mean\ndifferences between treatments/classes — print.relative.array","text":"x object class \"relative.array\" generated get.relative() digits integer indicating number significant digits used. ... arguments passed knitr::kable","code":""},{"path":"/reference/radian.rescale.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate position of label with respect to vertex location within a circle — radian.rescale","title":"Calculate position of label with respect to vertex location within a circle — radian.rescale","text":"Useful graphs drawn using igraph reposition labels relative vertices vertices laid circle (common network plots). igraph interprets position within vertex.label.degree radians, necessary convert locations radian values. main role function.","code":""},{"path":"/reference/radian.rescale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate position of label with respect to vertex location within a circle — radian.rescale","text":"","code":"radian.rescale(x, start = 0, direction = 1)"},{"path":"/reference/radian.rescale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate position of label with respect to vertex location within a circle — radian.rescale","text":"x numeric vector positions around circle, typically sequentially numbered. start number giving offset 12 o'clock radians label locations. direction Either 1 clockwise numbering (based order x) -1 anti-clockwise.","code":""},{"path":"/reference/radian.rescale.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate position of label with respect to vertex location within a circle — radian.rescale","text":"https://gist.github.com/kjhealy/834774/a4e677401fd6e4c319135dabeaf9894393f9392c","code":""},{"path":"/reference/radian.rescale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate position of label with respect to vertex location within a circle — radian.rescale","text":"","code":"MBNMAtime:::radian.rescale(c(1:10), start=0, direction=1) #>  [1] 0.0000000 0.6981317 1.3962634 2.0943951 2.7925268 3.4906585 4.1887902 #>  [8] 4.8869219 5.5850536 0.0000000"},{"path":"/reference/rank.html","id":null,"dir":"Reference","previous_headings":"","what":"Set rank as a method — rank","title":"Set rank as a method — rank","text":"Set rank method","code":""},{"path":"/reference/rank.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set rank as a method — rank","text":"","code":"rank(x, ...)"},{"path":"/reference/rank.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set rank as a method — rank","text":"x object apply rank method ... Arguments passed methods","code":""},{"path":"/reference/rank.mb.predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Rank predictions at a specific time point — rank.mb.predict","title":"Rank predictions at a specific time point — rank.mb.predict","text":"Rank predictions specific time point","code":""},{"path":"/reference/rank.mb.predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rank predictions at a specific time point — rank.mb.predict","text":"","code":"# S3 method for mb.predict rank(   x,   time = max(x$summary[[1]]$time),   lower_better = FALSE,   treats = names(x$summary),   ... )"},{"path":"/reference/rank.mb.predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rank predictions at a specific time point — rank.mb.predict","text":"x object class(\"mb.predict\") contains predictions MBNMA model time number indicating time point predictions ranked. must one time points predictions x available. lower_better Indicates whether negative responses better (lower_better=TRUE) positive responses better (lower_better=FALSE) treats character vector treatment/class names responses predicted x default, rankings calculated treatments/classes x. ... Arguments passed methods","code":""},{"path":"/reference/rank.mb.predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rank predictions at a specific time point — rank.mb.predict","text":"Returns object class(\"mb.rank\") containing ranked predictions","code":""},{"path":"/reference/rank.mb.predict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rank predictions at a specific time point — rank.mb.predict","text":"","code":"# \\donttest{ # Create an mb.network object from a dataset network <- mb.network(osteopain) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Run an MBNMA model with an Emax time-course emax <- mb.run(network,   fun=temax(pool.emax=\"rel\", method.emax=\"common\",     pool.et50=\"abs\", method.et50=\"common\")) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 89 #>    Total graph size: 7703 #>  #> Initializing model #>   # Predict responses using a stochastic baseline (E0) and a distribution for the #network reference treatment preds <- predict(emax, E0=7,   ref.resp=list(emax=~rnorm(n, -0.5, 0.05))) #> Priors required for: mu.1 #> Success: Elements in prior match consistency time-course treatment effect parameters  # Rank predictions at latest predicted time-point rank(preds, lower_better=TRUE) #>  #> ======================================== #> Treatment rankings #> ========================================  #>  #> Predictions at time = 24 ranking #>  #> |Treatment |  Mean| Median|  2.5%| 97.5%| #> |:---------|-----:|------:|-----:|-----:| #> |Pl_0      | 27.62|     28| 26.00| 28.00| #> |Ce_100    | 21.83|     22| 18.00| 23.00| #> |Ce_200    | 13.80|     14| 11.00| 17.00| #> |Ce_400    | 10.89|     10|  7.00| 17.00| #> |Du_90     | 20.93|     22| 11.00| 25.00| #> |Et_10     | 26.33|     26| 24.00| 28.00| #> |Et_30     |  6.91|      7|  4.00|  9.00| #> |Et_5      | 26.30|     26| 24.00| 28.00| #> |Et_60     |  2.49|      2|  2.00|  3.00| #> |Et_90     |  2.53|      3|  2.00|  3.00| #> |Lu_100    | 16.18|     16| 12.00| 20.00| #> |Lu_200    | 16.81|     17| 12.00| 21.00| #> |Lu_400    | 10.13|     10|  8.00| 14.00| #> |Lu_NA     | 12.23|     11|  7.00| 20.00| #> |Na_1000   |  5.12|      5|  4.00|  7.00| #> |Na_1500   |  7.01|      7|  5.00|  9.00| #> |Na_250    | 28.98|     29| 29.00| 29.00| #> |Na_750    | 14.38|     14|  9.00| 20.00| #> |Ox_44     |  7.03|      6|  4.00| 18.03| #> |Ro_12     | 16.04|     16| 10.00| 22.00| #> |Ro_125    |  1.00|      1|  1.00|  1.00| #> |Ro_25     |  5.59|      5|  4.00|  9.00| #> |Tr_100    | 25.48|     25| 24.00| 27.00| #> |Tr_200    | 24.15|     24| 23.00| 26.00| #> |Tr_300    | 19.85|     20| 15.00| 23.00| #> |Tr_400    | 17.64|     18| 11.00| 22.00| #> |Va_10     | 18.73|     19| 12.00| 23.00| #> |Va_20     | 11.57|     11|  6.98| 19.00| #> |Va_5      | 17.44|     18| 10.00| 23.00| #>  #>    #### Rank predictions at 5 weeks follow-up ####  # First ensure responses are predicted at 5 weeks preds <- predict(emax, E0=7,   ref.resp=list(emax=~rnorm(n, -0.5, 0.05)),   times=c(0,5,10)) #> Priors required for: mu.1 #> Success: Elements in prior match consistency time-course treatment effect parameters  # Rank predictions at 5 weeks follow-up ranks <- rank(preds, lower_better=TRUE, time=5)  # Plot ranks plot(ranks)   # }"},{"path":"/reference/rank.mbnma.html","id":null,"dir":"Reference","previous_headings":"","what":"Rank parameters from a time-course MBNMA — rank.mbnma","title":"Rank parameters from a time-course MBNMA — rank.mbnma","text":"Ranks desired parameters saved time-course MBNMA model \"best\" \"worst\".","code":""},{"path":"/reference/rank.mbnma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rank parameters from a time-course MBNMA — rank.mbnma","text":"","code":"# S3 method for mbnma rank(   x,   params = \"auc\",   lower_better = FALSE,   treats = NULL,   int.range = NULL,   level = \"treatment\",   n.iter = x$BUGSoutput$n.sims,   ... )"},{"path":"/reference/rank.mbnma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rank parameters from a time-course MBNMA — rank.mbnma","text":"x object class \"mb.predict\" generated predict(\"mbnma\") params character vector containing model parameters monitored mbnma ranking desired (e.g. \"beta.1\", \"emax\"). Parameters must vary treatment ranking possible. Can include \"auc\" (see details). lower_better Indicates whether negative responses better (lower_better=TRUE) positive responses better (lower_better=FALSE) treats character vector treatment/class names (depending value level) numeric vector treatment/class codes (coded mbnma) indicate treatments/classes calculate rankings . left `NULL`` rankings calculated treatments/classes. int.range numeric vector two elements indicates range calculate AUC. Takes form c(lower bound, upper bound). left NULL (default) range zero maximum follow-time dataset. level character object indicate whether parameters ranked treatment level (\"treatment\") class level (\"class\"). n.iter number iterations calculate AUC (\"auc\" included params). Must positive integer. Default value used mbnma. ... Arguments sent integrate()","code":""},{"path":"/reference/rank.mbnma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rank parameters from a time-course MBNMA — rank.mbnma","text":"named list whose elements correspond parameters given params. element contains: summary.rank data frame containing mean, sd, quantiles ranks treatment given treats prob.matrix matrix proportions MCMC results treatment treats ranked position given parameter rank.matrix matrix ranks MCMC results treatment treats given parameter.","code":""},{"path":"/reference/rank.mbnma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rank parameters from a time-course MBNMA — rank.mbnma","text":"\"auc\" can included params rank treatments based Area Curve (AUC). accounts effect multiple time-course parameters simultaneously treatment response, impacted range time AUC calculated (int.range). requires integration int.range can take time run (particularly) spline functions uses trapezoid method rather adaptive quadrature). post-estimation functions, rank() performed models successfully converged. Note rankings can sensitive even small changes treatment effects therefore failure converge one parameter may substantial impact rankings.","code":""},{"path":"/reference/rank.mbnma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rank parameters from a time-course MBNMA — rank.mbnma","text":"","code":"# \\donttest{ # Create an mb.network object from a dataset network <- mb.network(alog_pcfb) #> Reference treatment is `placebo` #> Studies reporting change from baseline automatically identified from the data  # Run an MBNMA model with an Emax time-course emax <- mb.run(network,   fun=temax(pool.emax=\"rel\", method.emax=\"common\",             pool.et50=\"rel\", method.et50=\"random\"),   intercept=FALSE) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 233 #>    Unobserved stochastic nodes: 71 #>    Total graph size: 4363 #>  #> Initializing model #>   # Rank treatments by time-course parameter from the model with lower scores being better rank(emax, params=c(\"emax\", \"et50\"), lower_better=TRUE) #>  #> ======================================== #> Treatment rankings #> ========================================  #>  #> emax ranking #>  #> |Treatment | Mean| Median| 2.5%| 97.5%| #> |:---------|----:|------:|----:|-----:| #> |placebo   | 6.00|      6|    6|     6| #> |alog_6.25 | 4.87|      5|    4|     5| #> |alog_12.5 | 4.06|      4|    3|     5| #> |alog_25   | 2.99|      3|    2|     3| #> |alog_50   | 1.94|      2|    1|     2| #> |alog_100  | 1.15|      1|    1|     4| #>  #>  #> et50 ranking #>  #> |Treatment | Mean| Median| 2.5%| 97.5%| #> |:---------|----:|------:|----:|-----:| #> |placebo   | 1.00|      1|    1|     1| #> |alog_6.25 | 4.51|      5|    2|     6| #> |alog_12.5 | 2.85|      3|    2|     5| #> |alog_25   | 2.86|      3|    2|     5| #> |alog_50   | 4.08|      4|    2|     6| #> |alog_100  | 5.70|      6|    3|     6| #>  #>   # Rank treatments 1-3 by AUC rank(emax, params=\"auc\", treats=c(1:3), lower_better=TRUE,   int.range=c(0,20)) #>    |                                                                               |                                                                      |   0%   |                                                                               |                                                                      |   1%   |                                                                               |=                                                                     |   1%   |                                                                               |=                                                                     |   2%   |                                                                               |==                                                                    |   2%   |                                                                               |==                                                                    |   3%   |                                                                               |==                                                                    |   4%   |                                                                               |===                                                                   |   4%   |                                                                               |===                                                                   |   5%   |                                                                               |====                                                                  |   5%   |                                                                               |====                                                                  |   6%   |                                                                               |=====                                                                 |   6%   |                                                                               |=====                                                                 |   7%   |                                                                               |=====                                                                 |   8%   |                                                                               |======                                                                |   8%   |                                                                               |======                                                                |   9%   |                                                                               |=======                                                               |   9%   |                                                                               |=======                                                               |  10%   |                                                                               |=======                                                               |  11%   |                                                                               |========                                                              |  11%   |                                                                               |========                                                              |  12%   |                                                                               |=========                                                             |  12%   |                                                                               |=========                                                             |  13%   |                                                                               |=========                                                             |  14%   |                                                                               |==========                                                            |  14%   |                                                                               |==========                                                            |  15%   |                                                                               |===========                                                           |  15%   |                                                                               |===========                                                           |  16%   |                                                                               |============                                                          |  16%   |                                                                               |============                                                          |  17%   |                                                                               |============                                                          |  18%   |                                                                               |=============                                                         |  18%   |                                                                               |=============                                                         |  19%   |                                                                               |==============                                                        |  19%   |                                                                               |==============                                                        |  20%   |                                                                               |==============                                                        |  21%   |                                                                               |===============                                                       |  21%   |                                                                               |===============                                                       |  22%   |                                                                               |================                                                      |  22%   |                                                                               |================                                                      |  23%   |                                                                               |================                                                      |  24%   |                                                                               |=================                                                     |  24%   |                                                                               |=================                                                     |  25%   |                                                                               |==================                                                    |  25%   |                                                                               |==================                                                    |  26%   |                                                                               |===================                                                   |  26%   |                                                                               |===================                                                   |  27%   |                                                                               |===================                                                   |  28%   |                                                                               |====================                                                  |  28%   |                                                                               |====================                                                  |  29%   |                                                                               |=====================                                                 |  29%   |                                                                               |=====================                                                 |  30%   |                                                                               |=====================                                                 |  31%   |                                                                               |======================                                                |  31%   |                                                                               |======================                                                |  32%   |                                                                               |=======================                                               |  32%   |                                                                               |=======================                                               |  33%   |                                                                               |=======================                                               |  34%   |                                                                               |========================                                              |  34%   |                                                                               |========================                                              |  35%   |                                                                               |=========================                                             |  35%   |                                                                               |=========================                                             |  36%   |                                                                               |==========================                                            |  36%   |                                                                               |==========================                                            |  37%   |                                                                               |==========================                                            |  38%   |                                                                               |===========================                                           |  38%   |                                                                               |===========================                                           |  39%   |                                                                               |============================                                          |  39%   |                                                                               |============================                                          |  40%   |                                                                               |============================                                          |  41%   |                                                                               |=============================                                         |  41%   |                                                                               |=============================                                         |  42%   |                                                                               |==============================                                        |  42%   |                                                                               |==============================                                        |  43%   |                                                                               |==============================                                        |  44%   |                                                                               |===============================                                       |  44%   |                                                                               |===============================                                       |  45%   |                                                                               |================================                                      |  45%   |                                                                               |================================                                      |  46%   |                                                                               |=================================                                     |  46%   |                                                                               |=================================                                     |  47%   |                                                                               |=================================                                     |  48%   |                                                                               |==================================                                    |  48%   |                                                                               |==================================                                    |  49%   |                                                                               |===================================                                   |  49%   |                                                                               |===================================                                   |  50%   |                                                                               |===================================                                   |  51%   |                                                                               |====================================                                  |  51%   |                                                                               |====================================                                  |  52%   |                                                                               |=====================================                                 |  52%   |                                                                               |=====================================                                 |  53%   |                                                                               |=====================================                                 |  54%   |                                                                               |======================================                                |  54%   |                                                                               |======================================                                |  55%   |                                                                               |=======================================                               |  55%   |                                                                               |=======================================                               |  56%   |                                                                               |========================================                              |  56%   |                                                                               |========================================                              |  57%   |                                                                               |========================================                              |  58%   |                                                                               |=========================================                             |  58%   |                                                                               |=========================================                             |  59%   |                                                                               |==========================================                            |  59%   |                                                                               |==========================================                            |  60%   |                                                                               |==========================================                            |  61%   |                                                                               |===========================================                           |  61%   |                                                                               |===========================================                           |  62%   |                                                                               |============================================                          |  62%   |                                                                               |============================================                          |  63%   |                                                                               |============================================                          |  64%   |                                                                               |=============================================                         |  64%   |                                                                               |=============================================                         |  65%   |                                                                               |==============================================                        |  65%   |                                                                               |==============================================                        |  66%   |                                                                               |===============================================                       |  66%   |                                                                               |===============================================                       |  67%   |                                                                               |===============================================                       |  68%   |                                                                               |================================================                      |  68%   |                                                                               |================================================                      |  69%   |                                                                               |=================================================                     |  69%   |                                                                               |=================================================                     |  70%   |                                                                               |=================================================                     |  71%   |                                                                               |==================================================                    |  71%   |                                                                               |==================================================                    |  72%   |                                                                               |===================================================                   |  72%   |                                                                               |===================================================                   |  73%   |                                                                               |===================================================                   |  74%   |                                                                               |====================================================                  |  74%   |                                                                               |====================================================                  |  75%   |                                                                               |=====================================================                 |  75%   |                                                                               |=====================================================                 |  76%   |                                                                               |======================================================                |  76%   |                                                                               |======================================================                |  77%   |                                                                               |======================================================                |  78%   |                                                                               |=======================================================               |  78%   |                                                                               |=======================================================               |  79%   |                                                                               |========================================================              |  79%   |                                                                               |========================================================              |  80%   |                                                                               |========================================================              |  81%   |                                                                               |=========================================================             |  81%   |                                                                               |=========================================================             |  82%   |                                                                               |==========================================================            |  82%   |                                                                               |==========================================================            |  83%   |                                                                               |==========================================================            |  84%   |                                                                               |===========================================================           |  84%   |                                                                               |===========================================================           |  85%   |                                                                               |============================================================          |  85%   |                                                                               |============================================================          |  86%   |                                                                               |=============================================================         |  86%   |                                                                               |=============================================================         |  87%   |                                                                               |=============================================================         |  88%   |                                                                               |==============================================================        |  88%   |                                                                               |==============================================================        |  89%   |                                                                               |===============================================================       |  89%   |                                                                               |===============================================================       |  90%   |                                                                               |===============================================================       |  91%   |                                                                               |================================================================      |  91%   |                                                                               |================================================================      |  92%   |                                                                               |=================================================================     |  92%   |                                                                               |=================================================================     |  93%   |                                                                               |=================================================================     |  94%   |                                                                               |==================================================================    |  94%   |                                                                               |==================================================================    |  95%   |                                                                               |===================================================================   |  95%   |                                                                               |===================================================================   |  96%   |                                                                               |====================================================================  |  96%   |                                                                               |====================================================================  |  97%   |                                                                               |====================================================================  |  98%   |                                                                               |===================================================================== |  98%   |                                                                               |===================================================================== |  99%   |                                                                               |======================================================================|  99%   |                                                                               |======================================================================| 100% #>  #> ======================================== #> Treatment rankings #> ========================================  #>  #> auc ranking #>  #> |Treatment | Mean| Median| 2.5%| 97.5%| #> |:---------|----:|------:|----:|-----:| #> |placebo   | 3.00|      3|    3|     3| #> |alog_6.25 | 1.93|      2|    1|     2| #> |alog_12.5 | 1.07|      1|    1|     2| #>  #>  # }"},{"path":"/reference/rankauc.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates ranking probabilities for AUC from a time-course MBNMA — rankauc","title":"Calculates ranking probabilities for AUC from a time-course MBNMA — rankauc","text":"Calculates ranking probabilities AUC time-course MBNMA","code":""},{"path":"/reference/rankauc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates ranking probabilities for AUC from a time-course MBNMA — rankauc","text":"","code":"rankauc(   mbnma,   lower_better = FALSE,   treats = NULL,   level = \"treatments\",   int.range = c(0, max(mbnma$network$data.ab$time)),   n.iter = mbnma$BUGSoutput$n.sims,   subdivisions = 100,   ... )"},{"path":"/reference/rankauc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates ranking probabilities for AUC from a time-course MBNMA — rankauc","text":"mbnma S3 object class \"mbnma\" generated running time-course MBNMA model lower_better Indicates whether negative responses better (lower_better=TRUE) positive responses better (lower_better=FALSE) treats character vector treatment/class names (depending value level). left NULL`` rankings calculated treatments/classes. Note unlike rank.mbnma()` argument take numeric vector. level Can take either \"treatment\" make predictions treatments, \"class\" make predictions classes (case object must class effect model). int.range numeric vector two elements indicates range calculate AUC. Takes form c(lower bound, upper bound). left NULL (default) range zero maximum follow-time dataset. n.iter number iterations calculate AUC (\"auc\" included params). Must positive integer. Default value used mbnma. subdivisions number subdivisions integrate (see integrate) ... Arguments sent R2jags synthesis network reference treatment effect (using ref.synth())","code":""},{"path":"/reference/rankauc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculates ranking probabilities for AUC from a time-course MBNMA — rankauc","text":"named list whose elements correspond parameters given params. element contains: summary.rank data frame containing mean, sd, quantiles ranks treatment given treats prob.matrix matrix proportions MCMC results treatment treats ranked position given parameter rank.matrix matrix ranks MCMC results treatment treats given parameter.","code":""},{"path":"/reference/rankauc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculates ranking probabilities for AUC from a time-course MBNMA — rankauc","text":"\"auc\" can included params rank treatments based Area Curve (AUC). accounts effect multiple time-course parameters simultaneously treatment response, impacted range time AUC calculated (int.range). requires integration int.range can take time run (particularly) spline functions uses trapezoid method rather adaptive quadrature). post-estimation functions, rank() performed models successfully converged. Note rankings can sensitive even small changes treatment effects therefore failure converge one parameter may substantial impact rankings.","code":""},{"path":"/reference/ref.comparisons.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify unique comparisons relative to study reference treatment within a\nnetwork — ref.comparisons","title":"Identify unique comparisons relative to study reference treatment within a\nnetwork — ref.comparisons","text":"Identify unique contrasts relative study reference within network. Repetitions treatment comparison grouped together.","code":""},{"path":"/reference/ref.comparisons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify unique comparisons relative to study reference treatment within a\nnetwork — ref.comparisons","text":"","code":"ref.comparisons(data)"},{"path":"/reference/ref.comparisons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify unique comparisons relative to study reference treatment within a\nnetwork — ref.comparisons","text":"data data frame containing variables studyID treatment (numeric codes) indicate treatments used studies.","code":""},{"path":"/reference/ref.comparisons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify unique comparisons relative to study reference treatment within a\nnetwork — ref.comparisons","text":"data frame unique comparisons row represents different comparison. t1 t2 indicate treatment codes make comparison. nr indicates number times given comparison made within network. single observation study within dataset (.e. standard network meta-analysis) nr represent number studies compare treatments t1 t2. multiple observations study within dataset (MBNMAtime) nr represent number time points dataset treatments t1 t2 compared.","code":""},{"path":"/reference/ref.comparisons.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify unique comparisons relative to study reference treatment within a\nnetwork — ref.comparisons","text":"","code":"data <- data.frame(studyID=c(1,1,2,2,3,3,4,4,5,5,5),   treatment=c(1,2,1,3,2,3,3,4,1,2,4)   )  # Identify comparisons informed by direct and indirect evidence MBNMAtime:::ref.comparisons(data) #> # A tibble: 5 × 3 #> # Groups:   t1, t2 [5] #>      t1    t2    nr #>   <dbl> <dbl> <int> #> 1     1     2     2 #> 2     1     3     1 #> 3     1     4     1 #> 4     2     3     1 #> 5     3     4     1"},{"path":"/reference/ref.synth.html","id":null,"dir":"Reference","previous_headings":"","what":"Synthesise single arm studies with repeated observations of the same\ntreatment over time — ref.synth","title":"Synthesise single arm studies with repeated observations of the same\ntreatment over time — ref.synth","text":"Synthesises single arm studies repeated measures applying particular time-course function. Used predicting mean responses time-course MBNMA. parameterisation time course must used MBNMA.","code":""},{"path":"/reference/ref.synth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Synthesise single arm studies with repeated observations of the same\ntreatment over time — ref.synth","text":"","code":"ref.synth(   data.ab,   mbnma,   synth = \"random\",   link = mbnma$model.arg$link,   n.iter = mbnma$BUGSoutput$n.iter,   n.burnin = mbnma$BUGSoutput$n.burnin,   n.thin = mbnma$BUGSoutput$n.thin,   n.chains = mbnma$BUGSoutput$n.chains,   ... )"},{"path":"/reference/ref.synth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Synthesise single arm studies with repeated observations of the same\ntreatment over time — ref.synth","text":"data.ab data frame arm-level data \"long\" format containing columns: studyID Study identifiers time Numeric data indicating follow-times y Numeric data indicating mean response given observation se Numeric data indicating standard error given observation mbnma S3 object class \"mbnma\" generated running time-course MBNMA model synth character object can take value \"common\" \"random\" specifies type pooling use synthesis ref.resp. Using \"random\" rather \"common\" synth result wider 95\\% CrI predictions. link Can take either \"identity\" (default), \"log\" (modelling Ratios Means (Friedrich et al. 2011) ) \"smd\" (modelling Standardised Mean Differences - although also corresponds identity link function). n.iter number total iterations per chain (including burn ;     default: 2000) n.burnin length burn , .e. number iterations     discard beginning. Default n.iter/2, ,     discarding first half simulations. n.burnin 0,     jags() run 100 iterations adaption. n.thin thinning rate. Must positive integer.  Set     n.thin > 1 save memory computation time     n.iter large.  Default max(1, floor(n.chains *     (n.iter-n.burnin) / 1000)) thin     least 2000 simulations. n.chains number Markov chains (default: 3) ... Arguments sent R2jags synthesis network reference treatment effect (using ref.synth())","code":""},{"path":"/reference/ref.synth.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Synthesise single arm studies with repeated observations of the same\ntreatment over time — ref.synth","text":"list named elements corresponding time-course parameter within MBNMA model contain median posterior value network reference treatment response.","code":""},{"path":"/reference/ref.synth.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Synthesise single arm studies with repeated observations of the same\ntreatment over time — ref.synth","text":"data.ab can collection studies closely resemble population interest intended prediction, different used estimate MBNMA model, include single arms RCTs observational studies. data available, data used estimate MBNMA model can used selecting studies arms specify network reference treatment responses.","code":""},{"path":"/reference/ref.synth.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Synthesise single arm studies with repeated observations of the same\ntreatment over time — ref.synth","text":"","code":"# \\donttest{ # Create an mb.network object from a dataset network <- mb.network(osteopain) #> Reference treatment is `Pl_0` #> Studies reporting change from baseline automatically identified from the data  # Run an MBNMA model with an Emax time-course emax <- mb.run(network,   fun=temax(pool.emax=\"rel\", method.emax=\"common\",     pool.et50=\"abs\", method.et50=\"random\")) #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 417 #>    Unobserved stochastic nodes: 194 #>    Total graph size: 8210 #>  #> Initializing model #>   # Generate a set of studies with which to estimate the network reference treatment response paindata.ref <- osteopain[osteopain$treatname==\"Placebo_0\",]  # Estimate the network reference treatment effect using common effects meta-analysis ref.synth(data.ab=paindata.ref, mbnma=emax, synth=\"common\") #> Data frame must contain only data from reference treatment #> Studies reporting change from baseline automatically identified from ref.resp #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 113 #>    Unobserved stochastic nodes: 61 #>    Total graph size: 2261 #>  #> Initializing model #>  #> Inference for Bugs model at \"/tmp/RtmprYte33/file20665d2ab132\", fit using jags, #>  3 chains, each with 20000 iterations (first 10000 discarded), n.thin = 10 #>  n.sims = 3000 iterations saved #>          mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff #> mu.1      -2.105   0.079  -2.267  -2.158  -2.103  -2.053  -1.955 1.003   830 #> deviance -39.697  12.444 -61.414 -48.900 -40.494 -31.675 -13.045 1.002  1400 #>  #> For each parameter, n.eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor (at convergence, Rhat=1). #>  #> DIC info (using the rule, pD = var(deviance)/2) #> pD = 77.4 and DIC = 37.7 #> DIC is an estimate of expected predictive error (lower deviance is better).  # Estimate the network reference treatment effect using random effects meta-analysis ref.synth(data.ab=paindata.ref, mbnma=emax, synth=\"random\") #> Data frame must contain only data from reference treatment #> Studies reporting change from baseline automatically identified from ref.resp #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 113 #>    Unobserved stochastic nodes: 91 #>    Total graph size: 2388 #>  #> Initializing model #>  #> Inference for Bugs model at \"/tmp/RtmprYte33/file20665cc65d0c\", fit using jags, #>  3 chains, each with 20000 iterations (first 10000 discarded), n.thin = 10 #>  n.sims = 3000 iterations saved #>           mu.vect sd.vect     2.5%      25%      50%      75%    97.5%  Rhat #> mu.1       -1.647   0.143   -1.928   -1.741   -1.645   -1.556   -1.362 1.001 #> sd.mu.1     0.724   0.114    0.533    0.644    0.712    0.794    0.974 1.001 #> deviance -130.914  12.314 -152.481 -139.661 -131.816 -122.762 -105.232 1.001 #>          n.eff #> mu.1      3000 #> sd.mu.1   3000 #> deviance  3000 #>  #> For each parameter, n.eff is a crude measure of effective sample size, #> and Rhat is the potential scale reduction factor (at convergence, Rhat=1). #>  #> DIC info (using the rule, pD = var(deviance)/2) #> pD = 75.9 and DIC = -55.1 #> DIC is an estimate of expected predictive error (lower deviance is better). # }"},{"path":"/reference/ref.validate.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks the validity of ref.resp if given as data frame — ref.validate","title":"Checks the validity of ref.resp if given as data frame — ref.validate","text":"Ensures ref.resp takes correct form allow synthesis network reference treatment response data provided meta-analysis","code":""},{"path":"/reference/ref.validate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks the validity of ref.resp if given as data frame — ref.validate","text":"","code":"ref.validate(data.ab)"},{"path":"/reference/ref.validate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks the validity of ref.resp if given as data frame — ref.validate","text":"data.ab data frame arm-level data \"long\" format containing columns: studyID Study identifiers time Numeric data indicating follow-times y Numeric data indicating mean response given observation se Numeric data indicating standard error given observation","code":""},{"path":"/reference/remove.loops.html","id":null,"dir":"Reference","previous_headings":"","what":"Removes any loops from MBNMA model JAGS code that do not contain any\nexpressions — remove.loops","title":"Removes any loops from MBNMA model JAGS code that do not contain any\nexpressions — remove.loops","text":"Removes loops MBNMA model JAGS code contain expressions","code":""},{"path":"/reference/remove.loops.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Removes any loops from MBNMA model JAGS code that do not contain any\nexpressions — remove.loops","text":"","code":"remove.loops(model)"},{"path":"/reference/remove.loops.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Removes any loops from MBNMA model JAGS code that do not contain any\nexpressions — remove.loops","text":"model character object JAGS MBNMA model code","code":""},{"path":"/reference/remove.loops.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Removes any loops from MBNMA model JAGS code that do not contain any\nexpressions — remove.loops","text":"character vector JAGS MBNMA model code empty loops removed ","code":""},{"path":"/reference/replace.prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace original priors in an MBNMA model with new priors — replace.prior","title":"Replace original priors in an MBNMA model with new priors — replace.prior","text":"Identical replace.prior() MBNMAdose.","code":""},{"path":"/reference/replace.prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace original priors in an MBNMA model with new priors — replace.prior","text":"","code":"replace.prior(priors, model = NULL, mbnma = NULL)"},{"path":"/reference/replace.prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace original priors in an MBNMA model with new priors — replace.prior","text":"priors named list parameter values (without indices) replacement prior distribution values given strings using distributions specified JAGS syntax (see Plummer (2017) ). model character object JAGS MBNMA model code mbnma S3 object class c(\"mbnma\", \"rjags\") generated running time-course MBNMA model.","code":""},{"path":"/reference/replace.prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replace original priors in an MBNMA model with new priors — replace.prior","text":"character object JAGS MBNMA model code includes new priors place original priors","code":""},{"path":"/reference/replace.prior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Replace original priors in an MBNMA model with new priors — replace.prior","text":"function takes new priors, specified user, adds JAGS code MBNMA model. New priors replace old priors JAGS model. Values priors can include JAGS functions/distributions (e.g. censoring/truncation).","code":""},{"path":"/reference/summary.mb.network.html","id":null,"dir":"Reference","previous_headings":"","what":"Print summary mb.network information to the console — summary.mb.network","title":"Print summary mb.network information to the console — summary.mb.network","text":"Print summary mb.network information console","code":""},{"path":"/reference/summary.mb.network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print summary mb.network information to the console — summary.mb.network","text":"","code":"# S3 method for mb.network summary(object, ...)"},{"path":"/reference/summary.mb.network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print summary mb.network information to the console — summary.mb.network","text":"object object class mb.network. ... arguments passed methods","code":""},{"path":"/reference/summary.mb.predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Prints summary of mb.predict object — summary.mb.predict","title":"Prints summary of mb.predict object — summary.mb.predict","text":"Prints summary table mean MCMC iterations time point treatment","code":""},{"path":"/reference/summary.mb.predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prints summary of mb.predict object — summary.mb.predict","text":"","code":"# S3 method for mb.predict summary(object, ...)"},{"path":"/reference/summary.mb.predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prints summary of mb.predict object — summary.mb.predict","text":"object object class \"mb.predict\" ... arguments passed methods","code":""},{"path":"/reference/summary.mb.predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prints summary of mb.predict object — summary.mb.predict","text":"matrix containing times responses predicted (time) additional column treatment responses predicted. row represents mean MCMC predicted responses treatment particular time.","code":""},{"path":"/reference/summary.mb.predict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prints summary of mb.predict object — summary.mb.predict","text":"","code":"# \\donttest{ # Define network network <- mb.network(obesityBW_CFB, reference=\"plac\") #> Studies reporting change from baseline automatically identified from the data  # Run an MBNMA with a quadratic time-course function quad <- mb.run(network,   fun=tpoly(degree=2, pool.1=\"rel\", method.1=\"common\",     pool.2=\"rel\", method.2=\"common\"),   intercept=TRUE) #> Change from version 0.2.2 onwards: corparam=FALSE as default #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 648 #>    Unobserved stochastic nodes: 155 #>    Total graph size: 11523 #>  #> Initializing model #>   # Predict responses pred <- predict(quad, times=c(0:50), treats=c(1:5),   ref.resp = network$data.ab[network$data.ab$treatment==1,],   E0=10) #> Data frame must contain only data from reference treatment #> Studies reporting change from baseline automatically identified from ref.resp #> Compiling model graph #>    Resolving undeclared variables #>    Allocating nodes #> Graph information: #>    Observed stochastic nodes: 264 #>    Unobserved stochastic nodes: 2 #>    Total graph size: 4249 #>  #> Initializing model #>   # Generate summary of predictions summary(pred) #>       time      plac   amfe_75MG dexf_10MG dexf_30MG dexf_60MG #>  [1,]    0 10.000000 10.00000000 10.000000 10.000000 10.000000 #>  [2,]    1  9.910634  9.52637326  9.857947  9.499289  9.315481 #>  [3,]    2  9.822215  9.06414507  9.727670  9.033208  8.676923 #>  [4,]    3  9.734744  8.61331541  9.609169  8.601757  8.084327 #>  [5,]    4  9.648221  8.17388428  9.502444  8.204936  7.537693 #>  [6,]    5  9.562646  7.74585170  9.407495  7.842746  7.037021 #>  [7,]    6  9.478019  7.32921765  9.324322  7.515185  6.582311 #>  [8,]    7  9.394339  6.92398214  9.252926  7.222255  6.173562 #>  [9,]    8  9.311607  6.53014516  9.193305  6.963955  5.810775 #> [10,]    9  9.229823  6.14770673  9.145460  6.740285  5.493949 #> [11,]   10  9.148987  5.77666683  9.109392  6.551245  5.223086 #> [12,]   11  9.069098  5.41702547  9.085099  6.396835  4.998184 #> [13,]   12  8.990158  5.06878264  9.072583  6.277055  4.819243 #> [14,]   13  8.912165  4.73193836  9.071842  6.191906  4.686265 #> [15,]   14  8.835120  4.40649261  9.082878  6.141387  4.599248 #> [16,]   15  8.759023  4.09244540  9.105689  6.125497  4.558193 #> [17,]   16  8.683873  3.78979672  9.140277  6.144238  4.563100 #> [18,]   17  8.609671  3.49854658  9.186641  6.197610  4.613969 #> [19,]   18  8.536418  3.21869498  9.244781  6.285611  4.710799 #> [20,]   19  8.464111  2.95024192  9.314697  6.408242  4.853591 #> [21,]   20  8.392753  2.69318739  9.396388  6.565504  5.042345 #> [22,]   21  8.322343  2.44753141  9.489856  6.757395  5.277060 #> [23,]   22  8.252880  2.21327396  9.595100  6.983917  5.557737 #> [24,]   23  8.184365  1.99041504  9.712121  7.245069  5.884376 #> [25,]   24  8.116798  1.77895467  9.840917  7.540851  6.256977 #> [26,]   25  8.050179  1.57889283  9.981489  7.871264  6.675539 #> [27,]   26  7.984507  1.39022953 10.133837  8.236306  7.140063 #> [28,]   27  7.919783  1.21296476 10.297961  8.635978  7.650549 #> [29,]   28  7.856007  1.04709854 10.473862  9.070281  8.206997 #> [30,]   29  7.793179  0.89263085 10.661538  9.539214  8.809406 #> [31,]   30  7.731299  0.74956170 10.860991 10.042777  9.457777 #> [32,]   31  7.670366  0.61789108 11.072219 10.580970 10.152110 #> [33,]   32  7.610382  0.49761900 11.295224 11.153793 10.892404 #> [34,]   33  7.551345  0.38874546 11.530004 11.761247 11.678661 #> [35,]   34  7.493256  0.29127046 11.776561 12.403330 12.510879 #> [36,]   35  7.436114  0.20519400 12.034894 13.080044 13.389058 #> [37,]   36  7.379921  0.13051607 12.305003 13.791388 14.313200 #> [38,]   37  7.324675  0.06723668 12.586887 14.537362 15.283303 #> [39,]   38  7.270377  0.01535583 12.880548 15.317966 16.299368 #> [40,]   39  7.217027 -0.02512649 13.185985 16.133200 17.361395 #> [41,]   40  7.164624 -0.05421027 13.503198 16.983064 18.469383 #> [42,]   41  7.113170 -0.07189551 13.832187 17.867559 19.623333 #> [43,]   42  7.062663 -0.07818221 14.172952 18.786684 20.823245 #> [44,]   43  7.013104 -0.07307038 14.525494 19.740438 22.069119 #> [45,]   44  6.964493 -0.05656001 14.889811 20.728823 23.360954 #> [46,]   45  6.916829 -0.02865110 15.265904 21.751838 24.698751 #> [47,]   46  6.870114  0.01065635 15.653773 22.809484 26.082510 #> [48,]   47  6.824346  0.06136233 16.053419 23.901759 27.512231 #> [49,]   48  6.779526  0.12346685 16.464840 25.028665 28.987913 #> [50,]   49  6.735654  0.19696991 16.888038 26.190200 30.509557 #> [51,]   50  6.692729  0.28187151 17.323011 27.386366 32.077163 # }"},{"path":"/reference/summary.mbnma.html","id":null,"dir":"Reference","previous_headings":"","what":"Print summary MBNMA results to the console — summary.mbnma","title":"Print summary MBNMA results to the console — summary.mbnma","text":"Print summary MBNMA results console","code":""},{"path":"/reference/summary.mbnma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print summary MBNMA results to the console — summary.mbnma","text":"","code":"# S3 method for mbnma summary(object, ...)"},{"path":"/reference/summary.mbnma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print summary MBNMA results to the console — summary.mbnma","text":"object S3 object class(\"mbnma\") generated running time-course MBNMA model ... arguments passed knitr::kable","code":""},{"path":"/reference/summary.nodesplit.html","id":null,"dir":"Reference","previous_headings":"","what":"Takes node-split results and produces summary data frame — summary.nodesplit","title":"Takes node-split results and produces summary data frame — summary.nodesplit","text":"Takes node-split results produces summary data frame","code":""},{"path":"/reference/summary.nodesplit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Takes node-split results and produces summary data frame — summary.nodesplit","text":"","code":"# S3 method for nodesplit summary(object, ...)"},{"path":"/reference/summary.nodesplit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Takes node-split results and produces summary data frame — summary.nodesplit","text":"object object class \"nodesplit\" generated mb.nodeplit() ... arguments passed methods","code":""},{"path":"/reference/summary.nodesplit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Takes node-split results and produces summary data frame — summary.nodesplit","text":"data frame summary node-split results following variables: Comparison treatment comparison node-split performed Time.Param time-course parameter node-split performed Evidence evidence contribution given comparison (either \"Direct\" \"Indirect\") Median posterior median 2.5% lower 95% credible interval limit 97.5% upper 95% credible interval limit p.value Bayesian p-value overlap direct indirect evidence given comparison (therefore identical value direct indirect evidence within particular comparison time-course parameter)","code":""},{"path":"/reference/temax.html","id":null,"dir":"Reference","previous_headings":"","what":"Emax time-course function — temax","title":"Emax time-course function — temax","text":"** version 0.2.3: ensure positive posterior values, et50 hill parameters now modeled natural scale using half-normal prior rather symmetrical prior exponential scale improve model stability **","code":""},{"path":"/reference/temax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Emax time-course function — temax","text":"","code":"temax(   pool.emax = \"rel\",   method.emax = \"common\",   pool.et50 = \"rel\",   method.et50 = \"common\",   pool.hill = NULL,   method.hill = NULL,   p.expon = FALSE )"},{"path":"/reference/temax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Emax time-course function — temax","text":"pool.emax Pooling Emax parameter. Can take \"rel\" \"abs\" (see details). method.emax Method synthesis Emax parameter. Can take \"common, \"random\", assigned numeric value (see details). pool.et50 Pooling ET50 parameter. Can take \"rel\" \"abs\" (see details). method.et50 Method synthesis ET50 parameter. Can take \"common, \"random\", assigned numeric value (see details). pool.hill Pooling Hill parameter. Can take \"rel\" \"abs\" (see details). method.hill Method synthesis Hill parameter. Can take \"common, \"random\", assigned numeric value (see details). p.expon parameters can take positive values modeled exponential scale (TRUE) assigned prior restricts posterior positive values (FALSE)","code":""},{"path":"/reference/temax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Emax time-course function — temax","text":"object class(\"timefun\")","code":""},{"path":"/reference/temax.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Emax time-course function — temax","text":"Emax represents maximum response. ET50 represents time 50% maximum response achieved. can take positive values modeled exponential scale assigned symmetrical normal prior Alternatively can assigned normal prior truncated zero (half-normal) (default MBNMAtime version >=0.2.3). Hill Hill parameter, allows sigmoidal function. can take positive values modeled exponential scale assigned symmetrical normal prior Alternatively can assigned normal prior truncated zero (half-normal) (default MBNMAtime version >=0.2.3). Without Hill parameter: $$\\frac{E_{max}\\times{x}}{ET_{50}+x}$$ Hill parameter: $$\\frac{E_{max}\\times{x^{hill}}}{ET_{50}\\times{hill}+x^{hill}}$$","code":""},{"path":"/reference/temax.html","id":"time-course-parameters","dir":"Reference","previous_headings":"","what":"Time-course parameters","title":"Emax time-course function — temax","text":"Time-course parameters model must specified using pool method prefix. pool used define approach used pooling given time-course parameter can take : method used define model used meta-analysis given time-course parameter can take following values: relative effects modelled one time-course parameter, correlation automatically estimated using vague inverse-Wishart prior. prior can made slightly informative specifying scale matrix omega changing degrees freedom inverse-Wishart prior using priors argument mb.run().","code":""},{"path":"/reference/temax.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Emax time-course function — temax","text":"Lu G, Ades AE (2004). “Combination direct indirect evidence mixed treatment comparisons.” Stat Med, 23(20), 3105-24. ISSN 0277-6715 (Print) 0277-6715 (Linking), doi:10.1002/sim.1875 , https://pubmed.ncbi.nlm.nih.gov/15449338/.","code":""},{"path":"/reference/temax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Emax time-course function — temax","text":"","code":"# Model without a Hill parameter temax(pool.emax=\"rel\", method.emax=\"random\", pool.et50=\"abs\", method.et50=\"common\") #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> $name #> [1] \"emax\" #>  #> $fun #> ~(emax * time)/(et50 + time) #> <environment: 0x5624902165b0> #>  #> $f #> function (time, beta.1, beta.2, beta.3, p.expon)  #> { #>     if (p.expon == TRUE) { #>         y <- (beta.1 * (time^exp(beta.3)))/((exp(beta.2)^exp(beta.3)) +  #>             (time^exp(beta.3))) #>     } #>     else { #>         y <- (beta.1 * (time^beta.3))/((exp(beta.2)^beta.3) +  #>             (time^beta.3)) #>     } #>     return(y) #> } #> <bytecode: 0x56248a174c08> #> <environment: 0x5624902165b0> #>  #> $latex #> [1] \"$\\\\frac{\\\\beta_1 \\\\times x_m}{{\\\\beta_2} + x_m}$\" #>  #> $params #> [1] \"emax\" \"et50\" #>  #> $nparam #> [1] 2 #>  #> $jags #> [1] \"(beta.1[i,k] * time[i,m]) / (beta.2 + time[i,m])\" #>  #> $apool #>  emax  et50  #> \"rel\" \"abs\"  #>  #> $amethod #>     emax     et50  #> \"random\" \"common\"  #>  #> $bname #>     emax     et50  #> \"beta.1\" \"beta.2\"  #>  #> $bpool #>     emax     et50  #> \"pool.1\" \"pool.2\"  #>  #> $bmethod #>       emax       et50  #> \"method.1\" \"method.2\"  #>  #> $p.expon #> [1] FALSE #>  #> attr(,\"class\") #> [1] \"timefun\"  # Model including a Hill parameter and defaults for Emax and ET50 parameters temax(pool.hill=\"abs\", method.hill=\"common\") #> 'et50' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> 'hill' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> $name #> [1] \"emax\" #>  #> $fun #> ~(emax * (time^hill))/((et50^hill) + (time^hill)) #> <environment: 0x562499cd0600> #>  #> $f #> function (time, beta.1, beta.2, beta.3, p.expon)  #> { #>     if (p.expon == TRUE) { #>         y <- (beta.1 * (time^exp(beta.3)))/((exp(beta.2)^exp(beta.3)) +  #>             (time^exp(beta.3))) #>     } #>     else { #>         y <- (beta.1 * (time^beta.3))/((exp(beta.2)^beta.3) +  #>             (time^beta.3)) #>     } #>     return(y) #> } #> <bytecode: 0x56248a174c08> #> <environment: 0x562499cd0600> #>  #> $latex #> [1] \"$\\\\frac{\\\\beta_1 \\\\times x_m^{\\\\beta_3}}{{\\\\beta_2}^{\\\\beta_3} + x_m^{\\\\beta_3}}$\" #>  #> $params #> [1] \"emax\" \"et50\" \"hill\" #>  #> $nparam #> [1] 3 #>  #> $jags #> [1] \"(beta.1[i,k] * (time[i,m] ^ beta.3)) / ((beta.2[i,k] ^ beta.3) + (time[i,m] ^ beta.3))\" #>  #> $apool #>  emax  et50  hill  #> \"rel\" \"rel\" \"abs\"  #>  #> $amethod #>     emax     et50     hill  #> \"common\" \"common\" \"common\"  #>  #> $bname #>     emax     et50     hill  #> \"beta.1\" \"beta.2\" \"beta.3\"  #>  #> $bpool #>     emax     et50     hill  #> \"pool.1\" \"pool.2\" \"pool.3\"  #>  #> $bmethod #>       emax       et50       hill  #> \"method.1\" \"method.2\" \"method.3\"  #>  #> $p.expon #> [1] FALSE #>  #> attr(,\"class\") #> [1] \"timefun\""},{"path":"/reference/tfpoly.html","id":null,"dir":"Reference","previous_headings":"","what":"Fractional polynomial time-course function — tfpoly","title":"Fractional polynomial time-course function — tfpoly","text":"first described use Network Meta-Analysis Jansen et al. (2015) .","code":""},{"path":"/reference/tfpoly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fractional polynomial time-course function — tfpoly","text":"","code":"tfpoly(   degree = 1,   pool.1 = \"rel\",   method.1 = \"common\",   pool.2 = \"rel\",   method.2 = \"common\",   method.power1 = 0,   method.power2 = 0 )"},{"path":"/reference/tfpoly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fractional polynomial time-course function — tfpoly","text":"degree degree fractional polynomial defined  Royston Altman (1994) pool.1 Pooling 1st fractional polynomial coefficient. Can take \"rel\" \"abs\" (see details). method.1 Method synthesis 1st fractional polynomial coefficient. Can take \"common, \"random\", assigned numeric value (see details). pool.2 Pooling 2nd fractional polynomial coefficient. Can take \"rel\" \"abs\" (see details). method.2 Method synthesis 2nd fractional polynomial coefficient. Can take \"common, \"random\", assigned numeric value (see details). method.power1 Value 1st fractional polynomial power. Must take numeric value set -2, -1, -0.5, 0, 0.5, 1, 2, 3. pool parameter set \"abs\". method.power2 Value 2nd fractional polynomial power. Must take numeric value set -2, -1, -0.5, 0, 0.5, 1, 2, 3. pool parameter set \"abs\".","code":""},{"path":"/reference/tfpoly.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fractional polynomial time-course function — tfpoly","text":"object class(\"timefun\")","code":""},{"path":"/reference/tfpoly.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fractional polynomial time-course function — tfpoly","text":"\\(\\beta_1\\) represents 1st coefficient. \\(\\beta_2\\) represents 2nd coefficient. \\(p_1\\) represents 1st power \\(p_2\\) represents 2nd power polynomial degree=1: $${\\beta_1}x^{p_1}$$ polynomial degree=2: $${\\beta_1}x^{p_1}+{\\beta_2}x^{p_2}$$ \\(x^{(p)}\\) regular power except \\(p=0\\), \\(x^{(0)}=ln(x)\\). fractional polynomial power \\(p_m\\) repeats within function multiplied another \\(ln(x)\\).","code":""},{"path":"/reference/tfpoly.html","id":"time-course-parameters","dir":"Reference","previous_headings":"","what":"Time-course parameters","title":"Fractional polynomial time-course function — tfpoly","text":"Time-course parameters model must specified using pool method prefix. pool used define approach used pooling given time-course parameter can take : method used define model used meta-analysis given time-course parameter can take following values: relative effects modelled one time-course parameter, correlation automatically estimated using vague inverse-Wishart prior. prior can made slightly informative specifying scale matrix omega changing degrees freedom inverse-Wishart prior using priors argument mb.run().","code":""},{"path":"/reference/tfpoly.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fractional polynomial time-course function — tfpoly","text":"Jansen JP, Vieira MC, Cope S (2015). “Network meta-analysis longitudinal data using fractional polynomials.” Stat Med, 34(15), 2294-311. ISSN 1097-0258 (Electronic) 0277-6715 (Linking), doi:10.1002/sim.6492 , https://pubmed.ncbi.nlm.nih.gov/25877808/. Lu G, Ades AE (2004). “Combination direct indirect evidence mixed treatment comparisons.” Stat Med, 23(20), 3105-24. ISSN 0277-6715 (Print) 0277-6715 (Linking), doi:10.1002/sim.1875 , https://pubmed.ncbi.nlm.nih.gov/15449338/. Royston P, Altman D (1994). “Regression Using Fractional Polynomials Continuous Covariates: Parsimonious Parametric Modelling.” Journal Royal Statistical Society: Series C, 43(3), 429-467.","code":""},{"path":"/reference/tfpoly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fractional polynomial time-course function — tfpoly","text":"","code":"# 1st order fractional polynomial with random effects tfpoly(pool.1=\"rel\", method.1=\"random\") #> $name #> [1] \"fpoly\" #>  #> $fun #> ~beta.1 * ifelse(time > 0, ifelse(beta.2 == 0, log(time), time^beta.2),  #>     0) #> <environment: 0x5624988f4df0> #>  #> $f #> function (time, beta.1, beta.2)  #> { #>     if (time > 0) { #>         if (beta.2 == 0) { #>             y <- log(time) #>         } #>         else { #>             y <- time^beta.2 #>         } #>     } #>     else { #>         y <- 0 #>     } #>     return(beta.1 * y) #> } #> <bytecode: 0x56249ca102d0> #> <environment: 0x5624988f4df0> #>  #> $latex #> [1] \"TO BE WRITTEN\" #>  #> $params #> [1] \"beta.1\" \"power1\" #>  #> $nparam #> [1] 2 #>  #> $jags #> [1] \"beta.1[i,k] * ifelse(time[i,m]>0, ifelse(beta.2==0, log(time[i,m]), time[i,m]^beta.2), 0)\" #>  #> $apool #> beta.1 power1  #>  \"rel\"  \"abs\"  #>  #> $amethod #>   beta.1   power1  #> \"random\"      \"0\"  #>  #> $bname #>   beta.1   power1  #> \"beta.1\" \"beta.2\"  #>  #> $bpool #>   beta.1   power1  #> \"pool.1\" \"pool.2\"  #>  #> $bmethod #>     beta.1     power1  #> \"method.1\" \"method.2\"  #>  #> attr(,\"class\") #> [1] \"timefun\"  # 2nd order fractional polynomial # with a single absolute parameter estimated for the 2nd coefficient # 1st power equal to zero tfpoly(degree=2, pool.1=\"rel\", method.1=\"common\",   pool.2=\"abs\", method.2=\"random\",   method.power1=0) #> $name #> [1] \"fpoly\" #>  #> $fun #> ~beta.1 * ifelse(time > 0, ifelse(beta.3 == 0, log(time), time^beta.3),  #>     0) + (beta.2 * ifelse(beta.4 == beta.3, ifelse(time > 0,  #>     ifelse(beta.4 == 0, log(time)^2, (time^beta.4) * log(time)),  #>     0), ifelse(time > 0, ifelse(beta.4 == 0, log(time), time^beta.4),  #>     0))) #> <environment: 0x56249ac3ea90> #>  #> $f #> function (time, beta.1, beta.2, beta.3, beta.4)  #> { #>     if (time > 0) { #>         if (beta.3 == 0) { #>             y1 <- log(time) #>         } #>         else { #>             y1 <- time^beta.3 #>         } #>     } #>     else { #>         y1 <- 0 #>     } #>     y1 <- beta.1 * y1 #>     if (beta.4 == beta.3) { #>         if (time > 0) { #>             if (beta.4 == 0) { #>                 y2 <- log(time)^2 #>             } #>             else { #>                 y2 <- time^beta.4 * log(time) #>             } #>         } #>         else { #>             if (time > 0) { #>                 if (beta.4 == 0) { #>                   y2 <- log(time) #>                 } #>                 else { #>                   y2 <- time^beta.4 #>                 } #>             } #>         } #>     } #>     else { #>         y2 <- 0 #>     } #>     return(y1 + y2) #> } #> <bytecode: 0x56249a20ff08> #> <environment: 0x56249ac3ea90> #>  #> $latex #> [1] \"TO BE WRITTEN\" #>  #> $params #> [1] \"beta.1\" \"beta.2\" \"power1\" \"power2\" #>  #> $nparam #> [1] 4 #>  #> $jags #> [1] \"beta.1[i,k] * ifelse(time[i,m]>0, ifelse(beta.3==0, log(time[i,m]), time[i,m]^beta.3), 0) + (i.beta.2[i,k] * ifelse(beta.4==beta.3, ifelse(time[i,m]>0, ifelse(beta.4==0, log(time[i,m])^2, (time[i,m]^beta.4) * log(time[i,m])), 0), ifelse(time[i,m]>0, ifelse(beta.4==0, log(time[i,m]), time[i,m]^beta.4), 0)))\" #>  #> $apool #> beta.1 beta.2 power1 power2  #>  \"rel\"  \"abs\"  \"abs\"  \"abs\"  #>  #> $amethod #>   beta.1   beta.2   power1   power2  #> \"common\" \"random\"      \"0\"      \"0\"  #>  #> $bname #>   beta.1   beta.2   power1   power2  #> \"beta.1\" \"beta.2\" \"beta.3\" \"beta.4\"  #>  #> $bpool #>   beta.1   beta.2   power1   power2  #> \"pool.1\" \"pool.2\" \"pool.3\" \"pool.4\"  #>  #> $bmethod #>     beta.1     beta.2     power1     power2  #> \"method.1\" \"method.2\" \"method.3\" \"method.4\"  #>  #> attr(,\"class\") #> [1] \"timefun\""},{"path":"/reference/timeplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot raw responses over time by treatment or class — timeplot","title":"Plot raw responses over time by treatment or class — timeplot","text":"Plot raw responses time treatment class","code":""},{"path":"/reference/timeplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot raw responses over time by treatment or class — timeplot","text":"","code":"timeplot(network, level = \"treatment\", plotby = \"arm\", link = \"identity\", ...)"},{"path":"/reference/timeplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot raw responses over time by treatment or class — timeplot","text":"network object class \"mb.network\". level string indicating whether nodes/facets represent treatment class plot. Can used examine expected impact modelling class/agent effects. plotby character object can take either \"arm\" indicate raw responses plotted separately study arm, \"rel\" indicate within-study relative effects/treatment differences plotted. way time-course absolute effects relative effects can examined. link Can take either \"identity\" (default), \"log\" (modelling Ratios Means (Friedrich et al. 2011) ) \"smd\" (modelling Standardised Mean Differences - although also corresponds identity link function). ... Arguments sent ggplot()","code":""},{"path":"/reference/timeplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot raw responses over time by treatment or class — timeplot","text":"function returns object class(c(\"gg\", \"ggplot\"). Characteristics object can therefore amended plots generated ggplot().","code":""},{"path":"/reference/timeplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot raw responses over time by treatment or class — timeplot","text":"Plots can faceted either treatment (level=\"treatment\") class (level=\"class\") investigate similarity treatment responses within classes/agents. Points represent observed responses lines connect observations within study arm.","code":""},{"path":"/reference/timeplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot raw responses over time by treatment or class — timeplot","text":"","code":"# \\donttest{ # Make network goutnet <- mb.network(goutSUA_CFB) #> Reference treatment is `Plac` #> Studies reporting change from baseline automatically identified from the data  # Use timeplot to plot responses grouped by treatment timeplot(goutnet)   # Use timeplot ot plot resposes grouped by class timeplot(goutnet, level=\"class\")   # Plot matrix of relative effects timeplot(goutnet, level=\"class\", plotby=\"rel\")   # Plot using Standardised Mean Differences copdnet <- mb.network(copd) #> Reference treatment is `Placebo` #> Studies reporting change from baseline automatically identified from the data timeplot(copdnet, plotby=\"rel\", link=\"smd\")   # }"},{"path":"/reference/titp.html","id":null,"dir":"Reference","previous_headings":"","what":"Integrated Two-Component Prediction (ITP) function — titp","title":"Integrated Two-Component Prediction (ITP) function — titp","text":"Similar parameterisation Emax model non-asymptotic maximal effect (Emax). Proposed proposed Fu Manner (2010)","code":""},{"path":"/reference/titp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integrated Two-Component Prediction (ITP) function — titp","text":"","code":"titp(   pool.emax = \"rel\",   method.emax = \"common\",   pool.rate = \"rel\",   method.rate = \"common\",   p.expon = FALSE )"},{"path":"/reference/titp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integrated Two-Component Prediction (ITP) function — titp","text":"pool.emax Pooling exponential Emax parameter. Can take \"rel\" \"abs\" (see details). method.emax Method synthesis exponential Emax parameter. Can take \"common, \"random\", assigned numeric value (see details). pool.rate Pooling parameter controlling rate onset. Default NULL avoids including parameter (.e. fixes 1 treatments). Can take \"rel\" \"abs\" (see details). method.rate Method synthesis parameter controlling rate onset. Can take \"common, \"random\", assigned numeric value (see details). p.expon parameters can take positive values modeled exponential scale (TRUE) assigned prior restricts posterior positive values (FALSE)","code":""},{"path":"/reference/titp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Integrated Two-Component Prediction (ITP) function — titp","text":"object class(\"timefun\")","code":""},{"path":"/reference/titp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Integrated Two-Component Prediction (ITP) function — titp","text":"$${E_{max}}\\times\\frac{(1-exp(-{rate}\\times{x}))}{(1-exp(-{rate}\\times{max(x)}))}$$","code":""},{"path":"/reference/titp.html","id":"time-course-parameters","dir":"Reference","previous_headings":"","what":"Time-course parameters","title":"Integrated Two-Component Prediction (ITP) function — titp","text":"Time-course parameters model must specified using pool method prefix. pool used define approach used pooling given time-course parameter can take : method used define model used meta-analysis given time-course parameter can take following values:","code":""},{"path":"/reference/titp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Integrated Two-Component Prediction (ITP) function — titp","text":"Fu H, Manner D (2010). “Bayesian adaptive dose-finding studies delayed responses.” J Biopharm Stat, 20(5), 1055-1070. doi:10.1080/10543400903315740 . Lu G, Ades AE (2004). “Combination direct indirect evidence mixed treatment comparisons.” Stat Med, 23(20), 3105-24. ISSN 0277-6715 (Print) 0277-6715 (Linking), doi:10.1002/sim.1875 , https://pubmed.ncbi.nlm.nih.gov/15449338/.","code":""},{"path":"/reference/titp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Integrated Two-Component Prediction (ITP) function — titp","text":"","code":"titp(pool.emax=\"rel\", method.emax=\"random\") #> 'rate' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> $name #> [1] \"itp\" #>  #> $fun #> ~emax * (1 - exp(-rate * time))/(1 - exp(-rate * max(time))) #> <environment: 0x56248cebe228> #>  #> $f #> function (time, beta.1, beta.2)  #> { #>     y <- beta.1 * (1 - exp(-beta.2 * time))/(1 - exp(-beta.2 *  #>         max(time))) #>     return(y) #> } #> <bytecode: 0x562499351010> #> <environment: 0x56248cebe228> #>  #> $latex #> [1] \"\\beta_1 * (1-exp(-\\beta_2*x_m)) / (1-exp(-\\beta_2*max(x_m)))\" #>  #> $params #> [1] \"emax\" \"rate\" #>  #> $nparam #> [1] 2 #>  #> $jags #> [1] \"beta.1[i,k] * ((1-exp(-beta.2[i,k]*time[i,m])) / (1-exp(-beta.2[i,k]*maxtime)))\" #>  #> $apool #>  emax  rate  #> \"rel\" \"rel\"  #>  #> $amethod #>     emax     rate  #> \"random\" \"common\"  #>  #> $bname #>     emax     rate  #> \"beta.1\" \"beta.2\"  #>  #> $bpool #>     emax     rate  #> \"pool.1\" \"pool.2\"  #>  #> $bmethod #>       emax       rate  #> \"method.1\" \"method.2\"  #>  #> $p.expon #> [1] FALSE #>  #> attr(,\"class\") #> [1] \"timefun\" titp(pool.emax=\"abs\") #> 'rate' parameters must take positive values. #>  Default half-normal prior restricts posterior to positive values. #> $name #> [1] \"itp\" #>  #> $fun #> ~emax * (1 - exp(-rate * time))/(1 - exp(-rate * max(time))) #> <environment: 0x56248ccc7f50> #>  #> $f #> function (time, beta.1, beta.2)  #> { #>     y <- beta.1 * (1 - exp(-beta.2 * time))/(1 - exp(-beta.2 *  #>         max(time))) #>     return(y) #> } #> <bytecode: 0x562499351010> #> <environment: 0x56248ccc7f50> #>  #> $latex #> [1] \"\\beta_1 * (1-exp(-\\beta_2*x_m)) / (1-exp(-\\beta_2*max(x_m)))\" #>  #> $params #> [1] \"emax\" \"rate\" #>  #> $nparam #> [1] 2 #>  #> $jags #> [1] \"beta.1 * ((1-exp(-beta.2[i,k]*time[i,m])) / (1-exp(-beta.2[i,k]*maxtime)))\" #>  #> $apool #>  emax  rate  #> \"abs\" \"rel\"  #>  #> $amethod #>     emax     rate  #> \"common\" \"common\"  #>  #> $bname #>     emax     rate  #> \"beta.1\" \"beta.2\"  #>  #> $bpool #>     emax     rate  #> \"pool.1\" \"pool.2\"  #>  #> $bmethod #>       emax       rate  #> \"method.1\" \"method.2\"  #>  #> $p.expon #> [1] FALSE #>  #> attr(,\"class\") #> [1] \"timefun\""},{"path":"/reference/tloglin.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-linear (exponential) time-course function — tloglin","title":"Log-linear (exponential) time-course function — tloglin","text":"\\(rate\\times{log(x + 1)}\\)","code":""},{"path":"/reference/tloglin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-linear (exponential) time-course function — tloglin","text":"","code":"tloglin(pool.rate = \"rel\", method.rate = \"common\")"},{"path":"/reference/tloglin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-linear (exponential) time-course function — tloglin","text":"pool.rate Pooling rate parameter. Can take \"rel\" \"abs\" (see details). method.rate Method synthesis rate parameter. Can take \"common, \"random\", assigned numeric value (see details).","code":""},{"path":"/reference/tloglin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-linear (exponential) time-course function — tloglin","text":"object class(\"timefun\")","code":""},{"path":"/reference/tloglin.html","id":"time-course-parameters","dir":"Reference","previous_headings":"","what":"Time-course parameters","title":"Log-linear (exponential) time-course function — tloglin","text":"Time-course parameters model must specified using pool method prefix. pool used define approach used pooling given time-course parameter can take : method used define model used meta-analysis given time-course parameter can take following values:","code":""},{"path":"/reference/tloglin.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Log-linear (exponential) time-course function — tloglin","text":"Lu G, Ades AE (2004). “Combination direct indirect evidence mixed treatment comparisons.” Stat Med, 23(20), 3105-24. ISSN 0277-6715 (Print) 0277-6715 (Linking), doi:10.1002/sim.1875 , https://pubmed.ncbi.nlm.nih.gov/15449338/.","code":""},{"path":"/reference/tloglin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-linear (exponential) time-course function — tloglin","text":"","code":"tloglin(pool.rate=\"rel\", method.rate=\"random\") #> $name #> [1] \"loglin\" #>  #> $fun #> ~rate * log(time + 1) #> <environment: 0x562494d0c550> #>  #> $f #> function (time, beta.1)  #> { #>     y <- beta.1 * log(time + 1) #>     return(y) #> } #> <bytecode: 0x562490452568> #> <environment: 0x562494d0c550> #>  #> $latex #> [1] \"\\beta_1 * log(x_m + 1)\" #>  #> $params #> [1] \"rate\" #>  #> $nparam #> [1] 1 #>  #> $jags #> [1] \"beta.1[i,k] * log(time[i,m] + 1)\" #>  #> $apool #>  rate  #> \"rel\"  #>  #> $amethod #>     rate  #> \"random\"  #>  #> $bname #>     rate  #> \"beta.1\"  #>  #> $bpool #>     rate  #> \"pool.1\"  #>  #> $bmethod #>       rate  #> \"method.1\"  #>  #> attr(,\"class\") #> [1] \"timefun\" tloglin(pool.rate=\"abs\") #> $name #> [1] \"loglin\" #>  #> $fun #> ~rate * log(time + 1) #> <environment: 0x5624939f5990> #>  #> $f #> function (time, beta.1)  #> { #>     y <- beta.1 * log(time + 1) #>     return(y) #> } #> <bytecode: 0x562490452568> #> <environment: 0x5624939f5990> #>  #> $latex #> [1] \"\\beta_1 * log(x_m + 1)\" #>  #> $params #> [1] \"rate\" #>  #> $nparam #> [1] 1 #>  #> $jags #> [1] \"beta.1 * log(time[i,m] + 1)\" #>  #> $apool #>  rate  #> \"abs\"  #>  #> $amethod #>     rate  #> \"common\"  #>  #> $bname #>     rate  #> \"beta.1\"  #>  #> $bpool #>     rate  #> \"pool.1\"  #>  #> $bmethod #>       rate  #> \"method.1\"  #>  #> attr(,\"class\") #> [1] \"timefun\""},{"path":"/reference/tpoly.html","id":null,"dir":"Reference","previous_headings":"","what":"Polynomial time-course function — tpoly","title":"Polynomial time-course function — tpoly","text":"Polynomial time-course function","code":""},{"path":"/reference/tpoly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Polynomial time-course function — tpoly","text":"","code":"tpoly(   degree = 1,   pool.1 = \"rel\",   method.1 = \"common\",   pool.2 = \"rel\",   method.2 = \"common\",   pool.3 = \"rel\",   method.3 = \"common\",   pool.4 = \"rel\",   method.4 = \"common\" )"},{"path":"/reference/tpoly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Polynomial time-course function — tpoly","text":"degree degree polynomial - e.g. degree=1 linear, degree=2 quadratic, degree=3 cubic. pool.1 Pooling 1st polynomial coefficient. Can take \"rel\" \"abs\" (see details). method.1 Method synthesis 1st polynomial coefficient.Can take \"common, \"random\", assigned numeric value (see details). pool.2 Pooling 2nd polynomial coefficient. Can take \"rel\" \"abs\" (see details). method.2 Method synthesis 2nd polynomial coefficient. Can take \"common, \"random\", assigned numeric value (see details). pool.3 Pooling 3rd polynomial coefficient. Can take \"rel\" \"abs\" (see details). method.3 Method synthesis 3rd polynomial coefficient. Can take \"common, \"random\", assigned numeric value (see details). pool.4 Pooling 4th polynomial coefficient. Can take \"rel\" \"abs\" (see details). method.4 Method synthesis 4th polynomial coefficient. Can take \"common, \"random\", assigned numeric value (see details).","code":""},{"path":"/reference/tpoly.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Polynomial time-course function — tpoly","text":"object class(\"timefun\")","code":""},{"path":"/reference/tpoly.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Polynomial time-course function — tpoly","text":"\\(\\beta_1\\) represents 1st coefficient. \\(\\beta_2\\) represents 2nd coefficient. \\(\\beta_3\\) represents 3rd coefficient. \\(\\beta_4\\) represents 4th coefficient. Linear model: $$\\beta_1{x}$$ Quadratic model: $$\\beta_1{x} + \\beta_2{x^2}$$ Cubic model: $$\\beta_1{x} + \\beta_2{x^2} + \\beta_3{x^3}$$ Quartic model: $$\\beta_1{x} + \\beta_2{x^2} + \\beta_3{x^3} + \\beta_4{x^4}$$","code":""},{"path":"/reference/tpoly.html","id":"time-course-parameters","dir":"Reference","previous_headings":"","what":"Time-course parameters","title":"Polynomial time-course function — tpoly","text":"Time-course parameters model must specified using pool method prefix. pool used define approach used pooling given time-course parameter can take : method used define model used meta-analysis given time-course parameter can take following values: relative effects modelled one time-course parameter, correlation automatically estimated using vague inverse-Wishart prior. prior can made slightly informative specifying scale matrix omega changing degrees freedom inverse-Wishart prior using priors argument mb.run().","code":""},{"path":"/reference/tpoly.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Polynomial time-course function — tpoly","text":"Lu G, Ades AE (2004). “Combination direct indirect evidence mixed treatment comparisons.” Stat Med, 23(20), 3105-24. ISSN 0277-6715 (Print) 0277-6715 (Linking), doi:10.1002/sim.1875 , https://pubmed.ncbi.nlm.nih.gov/15449338/.","code":""},{"path":"/reference/tpoly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Polynomial time-course function — tpoly","text":"","code":"# Linear model with random effects tpoly(pool.1=\"rel\", method.1=\"random\") #> $name #> [1] \"poly\" #>  #> $fun #> ~beta.1 * time #> <environment: 0x56249982ae10> #>  #> $latex #> [1] \"beta_1 * x_m\" #>  #> $params #> [1] \"beta.1\" #>  #> $nparam #> [1] 1 #>  #> $jags #> [1] \"beta.1[i,k] * time[i,m]\" #>  #> $apool #> beta.1  #>  \"rel\"  #>  #> $amethod #>   beta.1  #> \"random\"  #>  #> $bname #>   beta.1  #> \"beta.1\"  #>  #> $bpool #>   beta.1  #> \"pool.1\"  #>  #> $bmethod #>     beta.1  #> \"method.1\"  #>  #> attr(,\"class\") #> [1] \"timefun\"  # Quadratic model with a single absolute parameter estimated for the 2nd coefficient tpoly(pool.1=\"rel\", method.1=\"common\", pool.2=\"abs\", method.2=\"random\") #> $name #> [1] \"poly\" #>  #> $fun #> ~beta.1 * time #> <environment: 0x56249afb15d0> #>  #> $latex #> [1] \"beta_1 * x_m\" #>  #> $params #> [1] \"beta.1\" #>  #> $nparam #> [1] 1 #>  #> $jags #> [1] \"beta.1[i,k] * time[i,m]\" #>  #> $apool #> beta.1  #>  \"rel\"  #>  #> $amethod #>   beta.1  #> \"common\"  #>  #> $bname #>   beta.1  #> \"beta.1\"  #>  #> $bpool #>   beta.1  #> \"pool.1\"  #>  #> $bmethod #>     beta.1  #> \"method.1\"  #>  #> attr(,\"class\") #> [1] \"timefun\""},{"path":"/reference/tspline.html","id":null,"dir":"Reference","previous_headings":"","what":"Spline time-course functions — tspline","title":"Spline time-course functions — tspline","text":"Used fit B-splines, natural cubic splines, piecewise linear splines(Perperoglu et al. 2019) .","code":""},{"path":"/reference/tspline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spline time-course functions — tspline","text":"","code":"tspline(   type = \"bs\",   knots = 1,   degree = 1,   pool.1 = \"rel\",   method.1 = \"common\",   pool.2 = \"rel\",   method.2 = \"common\",   pool.3 = \"rel\",   method.3 = \"common\",   pool.4 = \"rel\",   method.4 = \"common\" )"},{"path":"/reference/tspline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spline time-course functions — tspline","text":"type type spline. Can take \"bs\" (B-spline), \"ns\" (natural cubic spline) \"ls\" (piecewise linear spline) knots number/location spline internal knots. single number given indicates number knots (equally spaced across range time points). numeric vector given indicates location knots. degree degree piecewise B-spline polynomial - e.g. degree=1 linear, degree=2 quadratic, degree=3 cubic. pool.1 Pooling 1st coefficient. Can take \"rel\" \"abs\" (see details). method.1 Method synthesis 1st coefficient. Can take \"common, \"random\", assigned numeric value (see details). pool.2 Pooling 2nd coefficient. Can take \"rel\" \"abs\" (see details). method.2 Method synthesis 2nd coefficient. Can take \"common, \"random\", assigned numeric value (see details). pool.3 Pooling 3rd coefficient. Can take \"rel\" \"abs\" (see details). method.3 Method synthesis 3rd coefficient. Can take \"common, \"random\", assigned numeric value (see details). pool.4 Pooling 4th coefficient. Can take \"rel\" \"abs\" (see details). method.4 Method synthesis 4th coefficient. Can take \"common, \"random\", assigned numeric value (see details).","code":""},{"path":"/reference/tspline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spline time-course functions — tspline","text":"object class(\"timefun\")","code":""},{"path":"/reference/tspline.html","id":"time-course-parameters","dir":"Reference","previous_headings":"","what":"Time-course parameters","title":"Spline time-course functions — tspline","text":"Time-course parameters model must specified using pool method prefix. pool used define approach used pooling given time-course parameter can take : method used define model used meta-analysis given time-course parameter can take following values: relative effects modelled one time-course parameter, correlation automatically estimated using vague inverse-Wishart prior. prior can made slightly informative specifying scale matrix omega changing degrees freedom inverse-Wishart prior using priors argument mb.run().","code":""},{"path":"/reference/tspline.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Spline time-course functions — tspline","text":"Lu G, Ades AE (2004). “Combination direct indirect evidence mixed treatment comparisons.” Stat Med, 23(20), 3105-24. ISSN 0277-6715 (Print) 0277-6715 (Linking), doi:10.1002/sim.1875 , https://pubmed.ncbi.nlm.nih.gov/15449338/. Perperoglu , Sauerbrei W, Abrahamowicz M, Schmid M (2019). “review spline function procedures R.” BMC Medical Research Methodology, 19(46), 1-16. doi:10.1186/s12874-019-0666-3 .","code":""},{"path":"/reference/tspline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spline time-course functions — tspline","text":"","code":"# Second order B spline with 2 knots and random effects on the 2nd coefficient tspline(type=\"bs\", knots=2, degree=2,   pool.1=\"rel\", method.1=\"common\",   pool.2=\"rel\", method.2=\"random\") #> $name #> [1] \"bs\" #>  #> $fun #> ~beta.1 * spline.1 + beta.2 * spline.2 + beta.3 * spline.3 +  #>     beta.4 * spline.4 #> <environment: 0x56249bd7b658> #>  #> $latex #> [1] \"\\beta_1 * X[m,1] + \\beta_2 * X[m,2] + \\beta_3 * X[m,3] + \\beta_4 * X[m,4]\" #>  #> $params #> [1] \"beta.1\" \"beta.2\" \"beta.3\" \"beta.4\" #>  #> $nparam #> [1] 4 #>  #> $knots #> [1] 2 #>  #> $degree #> [1] 2 #>  #> $jags #> [1] \"beta.1[i,k] * spline[i,m,1] + beta.2[i,k] * spline[i,m,2] + beta.3[i,k] * spline[i,m,3] + beta.4[i,k] * spline[i,m,4]\" #>  #> $apool #> beta.1 beta.2 beta.3 beta.4  #>  \"rel\"  \"rel\"  \"rel\"  \"rel\"  #>  #> $amethod #>   beta.1   beta.2   beta.3   beta.4  #> \"common\" \"random\" \"common\" \"common\"  #>  #> $bname #>   beta.1   beta.2   beta.3   beta.4  #> \"beta.1\" \"beta.2\" \"beta.3\" \"beta.4\"  #>  #> $bpool #>   beta.1   beta.2   beta.3   beta.4  #> \"pool.1\" \"pool.2\" \"pool.3\" \"pool.4\"  #>  #> $bmethod #>     beta.1     beta.2     beta.3     beta.4  #> \"method.1\" \"method.2\" \"method.3\" \"method.4\"  #>  #> attr(,\"class\") #> [1] \"timefun\"  # Piecewise linear spline with knots at 0.1 and 0.5 quantiles # Single parameter independent of treatment estimated for 1st coefficient #with random effects tspline(type=\"ls\", knots=c(0.1,0.5),   pool.1=\"abs\", method.1=\"random\",   pool.2=\"rel\", method.2=\"common\") #> $name #> [1] \"ls\" #>  #> $fun #> ~beta.1 * spline.1 + beta.2 * spline.2 + beta.3 * spline.3 #> <environment: 0x562491d5bbb0> #>  #> $latex #> [1] \"\\beta_1 * X[m,1] + \\beta_2 * X[m,2] + \\beta_3 * X[m,3]\" #>  #> $params #> [1] \"beta.1\" \"beta.2\" \"beta.3\" #>  #> $nparam #> [1] 3 #>  #> $knots #> [1] 0.1 0.5 #>  #> $degree #> [1] 1 #>  #> $jags #> [1] \"i.beta.1[i,k] * spline[i,m,1] + beta.2[i,k] * spline[i,m,2] + beta.3[i,k] * spline[i,m,3]\" #>  #> $apool #> beta.1 beta.2 beta.3  #>  \"abs\"  \"rel\"  \"rel\"  #>  #> $amethod #>   beta.1   beta.2   beta.3  #> \"random\" \"common\" \"common\"  #>  #> $bname #>   beta.1   beta.2   beta.3  #> \"beta.1\" \"beta.2\" \"beta.3\"  #>  #> $bpool #>   beta.1   beta.2   beta.3  #> \"pool.1\" \"pool.2\" \"pool.3\"  #>  #> $bmethod #>     beta.1     beta.2     beta.3  #> \"method.1\" \"method.2\" \"method.3\"  #>  #> attr(,\"class\") #> [1] \"timefun\""},{"path":"/reference/tuser.html","id":null,"dir":"Reference","previous_headings":"","what":"User-defined time-course function — tuser","title":"User-defined time-course function — tuser","text":"User-defined time-course function","code":""},{"path":"/reference/tuser.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"User-defined time-course function — tuser","text":"","code":"tuser(   fun,   pool.1 = \"rel\",   method.1 = \"common\",   pool.2 = \"rel\",   method.2 = \"common\",   pool.3 = \"rel\",   method.3 = \"common\",   pool.4 = \"rel\",   method.4 = \"common\" )"},{"path":"/reference/tuser.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"User-defined time-course function — tuser","text":"fun formula specifying relationship including time one/several : beta.1, beta.2, beta.3, beta.4. pool.1 Pooling beta.1. Can take \"common, \"random\", assigned numeric value (see details). method.1 Method synthesis beta.1. Can take \"common \"random\" (see details). pool.2 Pooling beta.2. Can take \"common, \"random\", assigned numeric value (see details). method.2 Method synthesis beta.2. Can take \"commonor\"random\"` (see details). pool.3 Pooling beta.3. Can take \"common, \"random\", assigned numeric value (see details). method.3 Method synthesis beta.3. Can take \"commonor\"random\"` (see details). pool.4 Pooling beta.4. Can take \"common, \"random\", assigned numeric value (see details). method.4 Method synthesis beta.4. Can take \"common, \"random\", assigned numeric value (see details).","code":""},{"path":"/reference/tuser.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"User-defined time-course function — tuser","text":"object class(\"timefun\")","code":""},{"path":"/reference/tuser.html","id":"time-course-parameters","dir":"Reference","previous_headings":"","what":"Time-course parameters","title":"User-defined time-course function — tuser","text":"Time-course parameters model must specified using pool method prefix. pool used define approach used pooling given time-course parameter can take : method used define model used meta-analysis given time-course parameter can take following values: relative effects modelled one time-course parameter, correlation automatically estimated using vague inverse-Wishart prior. prior can made slightly informative specifying scale matrix omega changing degrees freedom inverse-Wishart prior using priors argument mb.run().","code":""},{"path":"/reference/tuser.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"User-defined time-course function — tuser","text":"Lu G, Ades AE (2004). “Combination direct indirect evidence mixed treatment comparisons.” Stat Med, 23(20), 3105-24. ISSN 0277-6715 (Print) 0277-6715 (Linking), doi:10.1002/sim.1875 , https://pubmed.ncbi.nlm.nih.gov/15449338/.","code":""},{"path":"/reference/tuser.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"User-defined time-course function — tuser","text":"","code":"timecourse <- ~ beta.1 * (1/(time+1)) + beta.2 * time^2 tuser(fun=timecourse,   pool.1=\"abs\", method.1=\"common\",   pool.2=\"rel\", method.2=\"common\") #> $name #> [1] \"user\" #>  #> $fun #> ~beta.1 * (1/(time + 1)) + beta.2 * time^2 #> <environment: 0x56249973a518> #>  #> $latex #> NULL #>  #> $params #> [1] \"beta.1\" \"beta.2\" #>  #> $nparam #> [1] 2 #>  #> $jags #> [1] \"beta.1 * (1/(time[i,m] + 1)) + beta.2[i,k] * time[i,m]^2\" #>  #> $apool #> beta.1 beta.2  #>  \"abs\"  \"rel\"  #>  #> $amethod #>   beta.1   beta.2  #> \"common\" \"common\"  #>  #> $bname #> [1] \"beta.1\" \"beta.2\" #>  #> $bpool #>   beta.1   beta.2  #> \"pool.1\" \"pool.2\"  #>  #> $bmethod #>     beta.1     beta.2  #> \"method.1\" \"method.2\"  #>  #> attr(,\"class\") #> [1] \"timefun\""},{"path":"/reference/write.beta.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds sections of JAGS code for an MBNMA model that correspond to beta\nparameters — write.beta","title":"Adds sections of JAGS code for an MBNMA model that correspond to beta\nparameters — write.beta","text":"Adds sections JAGS code MBNMA model correspond beta parameters","code":""},{"path":"/reference/write.beta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds sections of JAGS code for an MBNMA model that correspond to beta\nparameters — write.beta","text":"","code":"write.beta(model, timecourse, fun, UME, class.effect)"},{"path":"/reference/write.beta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds sections of JAGS code for an MBNMA model that correspond to beta\nparameters — write.beta","text":"model character object JAGS MBNMA model code timecourse character object representing time-course used MBNMA model fun object class \"timefun\" generated (see Details) using tloglin(), tpoly(), titp(), temax(), tfpoly(), tspline() tuser() UME Can take either TRUE FALSE (unrelated mean effects model time-course parameters respectively) can vector parameter name strings model UME. example: c(\"beta.1\", \"beta.2\"). class.effect list named strings determines time-course parameters model class effect effect (\"common\" \"random\"). example: list(emax=\"common\", et50=\"random\").","code":""},{"path":"/reference/write.beta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adds sections of JAGS code for an MBNMA model that correspond to beta\nparameters — write.beta","text":"character vector JAGS MBNMA model code includes beta parameter components model","code":""},{"path":"/reference/write.check.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks validity of arguments for mb.write — write.check","title":"Checks validity of arguments for mb.write — write.check","text":"Checks validity arguments mb.write","code":""},{"path":"/reference/write.check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks validity of arguments for mb.write — write.check","text":"","code":"write.check(   fun = tpoly(degree = 1),   positive.scale = TRUE,   intercept = NULL,   rho = 0,   covar = NULL,   omega = NULL,   link = \"identity\",   class.effect = list(),   UME = c() )"},{"path":"/reference/write.check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks validity of arguments for mb.write — write.check","text":"fun object class \"timefun\" generated (see Details) using tloglin(), tpoly(), titp(), temax(), tfpoly(), tspline() tuser() positive.scale boolean object indicates whether continuous mean responses (y) positive therefore whether baseline response given prior constrains positive (e.g. scales <0). intercept boolean object indicates whether intercept (written alpha model) included. left NULL (default), intercept included studies reporting absolute means, excluded studies reporting change baseline (indicated network$cfb). rho correlation coefficient modelling within-study correlation time points. default string representing prior distribution JAGS, indicating estimated data (e.g. rho=\"dunif(0,1)\"). rho also assigned numeric value (e.g. rho=0.7), fixes rho model value (e.g. use deterministic sensitivity analysis). set rho=0 (default) implies modelling correlation time points. covar character specifying covariance structure use modelling within-study correlation time-points. can done specifying one following: \"varadj\" - univariate likelihood variance adjustment assume constant correlation subsequent time points (Jansen et al. 2015) . default. \"CS\" - multivariate normal likelihood compound symmetry structure \"AR1\" - multivariate normal likelihood autoregressive AR1 structure omega DEPRACATED VERSION 0.2.3 ONWARDS (~uniform(-1,1) now used correlation parameters rather Wishart prior). scale matrix inverse-Wishart prior covariance matrix used model correlation time-course parameters (see Details time-course functions). omega must symmetric positive definite matrix dimensions equal number time-course parameters modelled using relative effects (pool=\"rel\"). left NULL (default) diagonal matrix elements equal 1 used. link Can take either \"identity\" (default), \"log\" (modelling Ratios Means (Friedrich et al. 2011) ) \"smd\" (modelling Standardised Mean Differences - although also corresponds identity link function). class.effect list named strings determines time-course parameters model class effect effect (\"common\" \"random\"). example: list(emax=\"common\", et50=\"random\"). UME Can take either TRUE FALSE (unrelated mean effects model time-course parameters respectively) can vector parameter name strings model UME. example: c(\"beta.1\", \"beta.2\").","code":""},{"path":"/reference/write.check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks validity of arguments for mb.write — write.check","text":"boolean object indicates whether arguments imply modelling correlation time points.","code":""},{"path":"/reference/write.check.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Checks validity of arguments for mb.write — write.check","text":"Used check arguments given mb.write valid. function return informative errors arguments mispecified return object indicates whether arguments imply modelling correlation time points passes.","code":""},{"path":"/reference/write.cor.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds correlation between time-course relative effects — write.cor","title":"Adds correlation between time-course relative effects — write.cor","text":"uses Wishart prior default modelling correlation","code":""},{"path":"/reference/write.cor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds correlation between time-course relative effects — write.cor","text":"","code":"write.cor(model, fun, omega = NULL, class.effect = list())"},{"path":"/reference/write.cor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds correlation between time-course relative effects — write.cor","text":"model character object JAGS MBNMA model code fun object class \"timefun\" generated (see Details) using tloglin(), tpoly(), titp(), temax(), tfpoly(), tspline() tuser() omega DEPRACATED VERSION 0.2.3 ONWARDS (~uniform(-1,1) now used correlation parameters rather Wishart prior). scale matrix inverse-Wishart prior covariance matrix used model correlation time-course parameters (see Details time-course functions). omega must symmetric positive definite matrix dimensions equal number time-course parameters modelled using relative effects (pool=\"rel\"). left NULL (default) diagonal matrix elements equal 1 used. class.effect list named strings determines time-course parameters model class effect effect (\"common\" \"random\"). example: list(emax=\"common\", et50=\"random\").","code":""},{"path":"/reference/write.likelihood.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds sections of JAGS code for an MBNMA model that correspond to the\nlikelihood — write.likelihood","title":"Adds sections of JAGS code for an MBNMA model that correspond to the\nlikelihood — write.likelihood","text":"Adds sections JAGS code MBNMA model correspond likelihood","code":""},{"path":"/reference/write.likelihood.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds sections of JAGS code for an MBNMA model that correspond to the\nlikelihood — write.likelihood","text":"","code":"write.likelihood(   model,   timecourse,   rho = 0,   covar = \"varadj\",   link = \"identity\",   fun )"},{"path":"/reference/write.likelihood.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds sections of JAGS code for an MBNMA model that correspond to the\nlikelihood — write.likelihood","text":"model character object JAGS MBNMA model code timecourse character object representing time-course used MBNMA model rho correlation coefficient modelling within-study correlation time points. default string representing prior distribution JAGS, indicating estimated data (e.g. rho=\"dunif(0,1)\"). rho also assigned numeric value (e.g. rho=0.7), fixes rho model value (e.g. use deterministic sensitivity analysis). set rho=0 (default) implies modelling correlation time points. covar character specifying covariance structure use modelling within-study correlation time-points. can done specifying one following: \"varadj\" - univariate likelihood variance adjustment assume constant correlation subsequent time points (Jansen et al. 2015) . default. \"CS\" - multivariate normal likelihood compound symmetry structure \"AR1\" - multivariate normal likelihood autoregressive AR1 structure link Can take either \"identity\" (default), \"log\" (modelling Ratios Means (Friedrich et al. 2011) ) \"smd\" (modelling Standardised Mean Differences - although also corresponds identity link function). fun object class \"timefun\" generated (see Details) using tloglin(), tpoly(), titp(), temax(), tfpoly(), tspline() tuser()","code":""},{"path":"/reference/write.likelihood.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adds sections of JAGS code for an MBNMA model that correspond to the\nlikelihood — write.likelihood","text":"character vector JAGS MBNMA model code includes likelihood components model","code":""},{"path":"/reference/write.model.html","id":null,"dir":"Reference","previous_headings":"","what":"Write the basic JAGS model code for MBNMA to which other lines of model\ncode can be added — write.model","title":"Write the basic JAGS model code for MBNMA to which other lines of model\ncode can be added — write.model","text":"Write basic JAGS model code MBNMA lines model code can added","code":""},{"path":"/reference/write.model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write the basic JAGS model code for MBNMA to which other lines of model\ncode can be added — write.model","text":"","code":"write.model()"},{"path":"/reference/write.model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write the basic JAGS model code for MBNMA to which other lines of model\ncode can be added — write.model","text":"character vector JAGS model code","code":""},{"path":"/reference/write.ref.synth.html","id":null,"dir":"Reference","previous_headings":"","what":"Write MBNMA time-course models JAGS code for synthesis of studies\ninvestigating reference treatment — write.ref.synth","title":"Write MBNMA time-course models JAGS code for synthesis of studies\ninvestigating reference treatment — write.ref.synth","text":"Writes JAGS code Bayesian time-course model model-based network meta-analysis (MBNMA) pools reference treatment effects different studies. model pools single study arms therefore pool relative effects.","code":""},{"path":"/reference/write.ref.synth.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write MBNMA time-course models JAGS code for synthesis of studies\ninvestigating reference treatment — write.ref.synth","text":"","code":"write.ref.synth(   fun = tpoly(degree = 1),   link = \"identity\",   positive.scale = TRUE,   intercept = TRUE,   rho = 0,   covar = \"varadj\",   mu.synth = \"random\",   priors = NULL )"},{"path":"/reference/write.ref.synth.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write MBNMA time-course models JAGS code for synthesis of studies\ninvestigating reference treatment — write.ref.synth","text":"fun object class \"timefun\" generated (see Details) using tloglin(), tpoly(), titp(), temax(), tfpoly(), tspline() tuser() link Can take either \"identity\" (default), \"log\" (modelling Ratios Means (Friedrich et al. 2011) ) \"smd\" (modelling Standardised Mean Differences - although also corresponds identity link function). positive.scale boolean object indicates whether continuous mean responses (y) positive therefore whether baseline response given prior constrains positive (e.g. scales <0). intercept boolean object indicates whether intercept (written alpha model) included. left NULL (default), intercept included studies reporting absolute means, excluded studies reporting change baseline (indicated network$cfb). rho correlation coefficient modelling within-study correlation time points. default string representing prior distribution JAGS, indicating estimated data (e.g. rho=\"dunif(0,1)\"). rho also assigned numeric value (e.g. rho=0.7), fixes rho model value (e.g. use deterministic sensitivity analysis). set rho=0 (default) implies modelling correlation time points. covar character specifying covariance structure use modelling within-study correlation time-points. can done specifying one following: \"varadj\" - univariate likelihood variance adjustment assume constant correlation subsequent time points (Jansen et al. 2015) . default. \"CS\" - multivariate normal likelihood compound symmetry structure \"AR1\" - multivariate normal likelihood autoregressive AR1 structure mu.synth string takes value fixed random, indicating type synthesis model use priors named list parameter values (without indices) replacement prior distribution values given strings using distributions specified JAGS syntax (see Plummer (2017) ).","code":""},{"path":"/reference/write.ref.synth.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write MBNMA time-course models JAGS code for synthesis of studies\ninvestigating reference treatment — write.ref.synth","text":"character object JAGS MBNMA model code includes beta parameter components model","code":""},{"path":"/reference/write.ref.synth.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write MBNMA time-course models JAGS code for synthesis of studies\ninvestigating reference treatment — write.ref.synth","text":"","code":"# Write a log-linear time-course MBNMA synthesis model with: # Common effects for synthesis of mu # Modelled as ratio of means model <- write.ref.synth(fun=tloglin(pool.rate=\"rel\", method.rate=\"common\"),   mu.synth=\"common\", link=\"log\")  cat(model) # Concatenates model representations making code more easily readable #> model{ \t\t\t# Begin Model Code dummy2 <- treat dummy1 <- NT rho2 <- rho*rho for(i in 1:NS){ # Run through all NS trials alpha[i] ~ dnorm(0,0.0001) for (k in 1:narm[i]){ # Run through all arms within a study for (m in 1:fups[i]) {\t# Run through all observations within a study log(theta[i,k,m]) <- exp(alpha[i]) + mu.1 * log(time[i,m] + 1) y[i,k,m] ~ dnorm(theta[i,k,m], prec[i,k,m]) prec[i,k,m] <- pow(se[i,k,m], -2) resdev[i,k,m] <- pow((y[i,k,m] - theta[i,k,m]),2) * prec[i,k,m] # residual deviance for normal likelihood dev[i,k,m] <- -2* (log(pow((prec[i,k,m]/(2*3.14159)),0.5) * exp(-0.5*(pow((y[i,k,m]-theta[i,k,m]),2)*prec[i,k,m])))) # deviance for normal likelihood }  resarmdev[i,k] <- sum(resdev[i,k,1:fups[i]]) armdev[i,k] <- sum(dev[i,k,1:fups[i]]) }  resstudydev[i] <- sum(resarmdev[i, 1:narm[i]]) studydev[i] <- sum(armdev[i, 1:narm[i]])  }     totresdev <- sum(resstudydev[]) totdev <- sum(studydev[])  mu.1 ~ dnorm(0,0.0001) rho <- 0 # Model ends }"},{"path":"/reference/write.timecourse.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds sections of JAGS code for an MBNMA model that correspond to alpha\nparameters — write.timecourse","title":"Adds sections of JAGS code for an MBNMA model that correspond to alpha\nparameters — write.timecourse","text":"Adds sections JAGS code MBNMA model correspond alpha parameters","code":""},{"path":"/reference/write.timecourse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds sections of JAGS code for an MBNMA model that correspond to alpha\nparameters — write.timecourse","text":"","code":"write.timecourse(model, fun, intercept, positive.scale)"},{"path":"/reference/write.timecourse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds sections of JAGS code for an MBNMA model that correspond to alpha\nparameters — write.timecourse","text":"model character string representing MBNMA model JAGS code fun object class \"timefun\" generated (see Details) using tloglin(), tpoly(), titp(), temax(), tfpoly(), tspline() tuser() intercept boolean object indicates whether intercept (written alpha model) included. left NULL (default), intercept included studies reporting absolute means, excluded studies reporting change baseline (indicated network$cfb). positive.scale boolean object indicates whether continuous mean responses (y) positive therefore whether baseline response given prior constrains positive (e.g. scales <0). timecourse character object contains JAGS code time-course component model","code":""},{"path":"/reference/write.timecourse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adds sections of JAGS code for an MBNMA model that correspond to alpha\nparameters — write.timecourse","text":"list named elements: model character vector JAGS MBNMA model code includes alpha parameter components model timecourse character object contains JAGS code time-course component model, alpha indexed correctly","code":""},{"path":[]},{"path":"/news/index.html","id":"additionschanges-0-2-3","dir":"Changelog","previous_headings":"","what":"Additions/changes","title":"MBNMAtime 0.2.3","text":"Truncated priors used default priors time-course parameters can take positive values (e.g. et50) functions texp() removed - titp() stable parameterisation function","code":""},{"path":[]},{"path":"/news/index.html","id":"major-0-2-3","dir":"Changelog","previous_headings":"Bug fixes","what":"Major","title":"MBNMAtime 0.2.3","text":"Error fixed preventing natural splines functioning, causing removal CRAN","code":""},{"path":[]},{"path":[]},{"path":"/news/index.html","id":"additionschanges-0-2-2","dir":"Changelog","previous_headings":"","what":"Additions/changes","title":"MBNMAtime 0.2.2","text":"Can now specify numeric values time-course parameters method argument. Can useful discrete values estimated (e.g. fractional polynomial powers, Hill parameter). Fractional polynomial powers tfpoly() can take numeric values set defined Jansen 2015. Integrated Two-Component Prediction (ITP) function (titp()) added get.relative() can used combine two MBNMA models allow different time-course functions fitted different set treatments (see examples vignette) New priors restrict posterior positive values necessary can easily incorporated. binplot() can used plot results NMAs conducted multiple time bins. can particularly useful explore time-course functions might appropriate, check validity MBNMA predictions. mb.nodesplit() can performed specific time-points, addition time-course parameter corparam set FALSE default","code":""},{"path":[]},{"path":"/news/index.html","id":"minor-0-2-2","dir":"Changelog","previous_headings":"Bug fixes","what":"Minor","title":"MBNMAtime 0.2.2","text":"Error overlay.nma argument plot.mb.predict() fixed","code":""},{"path":"/news/index.html","id":"mbnmatime-021","dir":"Changelog","previous_headings":"","what":"MBNMAtime 0.2.1","title":"MBNMAtime 0.2.1","text":"CRAN release: 2021-09-13","code":""},{"path":"/news/index.html","id":"additionschanges-0-2-1","dir":"Changelog","previous_headings":"","what":"Additions/changes","title":"MBNMAtime 0.2.1","text":"get.relative() function can used calculate relative effects/mean differences treatments/classes cumrank() added cumulative ranking plots. Also calculates SUCRA values treatment time-course parameter specified follow-times (even treatments compared within study) Studies reporting change baseline absolute means can now specified mb.network(), automatically inferred data (studies time=0 assumed report change baseline) Model intercept (response time=0) now conditional change baseline study texp() now implements 2-parameter exponential function (though simpler 1-parameter model remains default)","code":""},{"path":[]},{"path":"/news/index.html","id":"major-0-2-1","dir":"Changelog","previous_headings":"Bug fixes","what":"Major","title":"MBNMAtime 0.2.1","text":"Error predict() properly incorporating absolute time-course parameters fixed","code":""},{"path":"/news/index.html","id":"minor-0-2-1","dir":"Changelog","previous_headings":"Bug fixes","what":"Minor","title":"MBNMAtime 0.2.1","text":"Error model.file input length fixed mb.run()","code":""},{"path":"/news/index.html","id":"mbnmatime-020","dir":"Changelog","previous_headings":"","what":"MBNMAtime 0.2.0","title":"MBNMAtime 0.2.0","text":"CRAN release: 2021-04-26","code":""},{"path":"/news/index.html","id":"additionschanges-0-2-0","dir":"Changelog","previous_headings":"","what":"Additions/changes","title":"MBNMAtime 0.2.0","text":"Added variance adjustment (covar=\"varadj\") correlation time-points - now default mb.run() Added log linear time-course function (tloglin()) Added spline functions (piecewise linear splines, B-splines, restricted cubic splines, natural splines) Added overlay.nma option predict() allow plotting “lumped” NMA results MBNMA predictions Modelling can now incorporate Standardised Mean Differences (link=\"smd\") Ratios Means (link=\"log\") allow modelling studies different scales lower_better argument used instead decreasing rankings Time-course functions given mb.run() now given class(\"timefun\") time-course parameters specified within functions Predictions predict() can now ranked Forest plots now also plot posterior densities using ggdist::stat_halfeye() Neater outputs using print() summary() Wishart prior used model correlations within-study baseline effects different time-course parameters, addition relative effects different time-course parameters.","code":""},{"path":[]},{"path":"/news/index.html","id":"major-0-2-0","dir":"Changelog","previous_headings":"Bug fixes","what":"Major","title":"MBNMAtime 0.2.0","text":"Corrected calculation Bayesian p-value mb.nodesplit()","code":""},{"path":"/news/index.html","id":"mbnmatime-013","dir":"Changelog","previous_headings":"","what":"MBNMAtime 0.1.3","title":"MBNMAtime 0.1.3","text":"CRAN release: 2020-03-04","code":""},{"path":"/news/index.html","id":"additionschanges-0-1-3","dir":"Changelog","previous_headings":"","what":"Additions/changes","title":"MBNMAtime 0.1.3","text":"Added citation file plot.mb.network() now uses layout argument takes igraph layout function instead layout_in_circle (logical argument). allows igraph layout plotted rather just circle (e.g. igraph::as_star()) Objects returned plot.mb.network now specific igraph attributes assigned , can easily changed user. user.fun now takes formula argument (example ~ (beta.1 * dose) + (beta.2 * dose^2)) rather string. mb.network objects now stored within lists mb class objects easy reference data format","code":""},{"path":[]},{"path":"/news/index.html","id":"major-0-1-3","dir":"Changelog","previous_headings":"Bug fixes","what":"Major","title":"MBNMAtime 0.1.3","text":"Exponential function models working previously dose-response function rewritten runs model correctly. Ensured comparisons cycled correctly mb.nodesplit Ensured timeplot raw responses can plotted either arm (plotby=\"arm\") relative (plotby=\"rel\") effects.","code":""},{"path":"/news/index.html","id":"mbnmatime-012","dir":"Changelog","previous_headings":"","what":"MBNMAtime 0.1.2","title":"MBNMAtime 0.1.2","text":"CRAN release: 2019-10-28","code":""},{"path":"/news/index.html","id":"first-release-of-package-0-1-2","dir":"Changelog","previous_headings":"","what":"First release of package","title":"MBNMAtime 0.1.2","text":"Welcome MBNMAtime. Ready release world. hope can service ! dose-response MBNMA, also check sister package, MBNMAdose.","code":""}]
